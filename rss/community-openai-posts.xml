<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 02 Apr 2024 12:33:18 GMT</lastBuildDate>
    <item>
      <title>微调是否教导系统角色？</title>
      <link>https://community.openai.com/t/does-fine-tuning-teach-the-system-role/583005#post_6</link>
      <description><![CDATA[嘿@abd2128，你设法解决这个问题了吗？如果是，您能分享一下您的方法吗？]]></description>
      <guid>https://community.openai.com/t/does-fine-tuning-teach-the-system-role/583005#post_6</guid>
      <pubDate>Tue, 02 Apr 2024 12:24:50 GMT</pubDate>
    </item>
    <item>
      <title>功能请求：基于内存的推理</title>
      <link>https://community.openai.com/t/feature-request-memory-informed-inference/705256#post_2</link>
      <description><![CDATA[示例：
Ai 正在通过 Pyautogui 和键盘模块玩 Pokemon、接收屏幕截图并执行命令
最近的图像位于命名屏幕“AAA”
文本历史数组：
- 将光标移动到位置（43,25）
- 按“A”
- 按“A”
- 当光标位于“A”字母上方时“按 A”


下一个屏幕现在显示“AAAA”
问题在于每个推理都可以访问聊天历史记录，但缺乏先前推理的内部上下文、想法或目标。虽然可以要求人工智能明确说明其推理和目标，但仅依靠文本是一种低语境的信息传达方法。如果遗漏任何细节，后续的推论可能难以作为代理进行连贯且有效的行动。
有点让我想起一个没有记忆的人用日记来传递自己的信息；或者每次你按回车键时，一个全新的人工智能就会从以太中出现，只给出聊天历史记录（文本和图像），并被告知“弄清楚它”哈哈]]></description>
      <guid>https://community.openai.com/t/feature-request-memory-informed-inference/705256#post_2</guid>
      <pubDate>Tue, 02 Apr 2024 12:19:30 GMT</pubDate>
    </item>
    <item>
      <title>在 GPT4-Vision 响应中设定基调和风格</title>
      <link>https://community.openai.com/t/setting-a-tone-and-style-in-gpt4-vision-responses/705250#post_2</link>
      <description><![CDATA[是的，目前最好的方法是在提示中描述所需的样式和/或提供示例。]]></description>
      <guid>https://community.openai.com/t/setting-a-tone-and-style-in-gpt4-vision-responses/705250#post_2</guid>
      <pubDate>Tue, 02 Apr 2024 12:09:59 GMT</pubDate>
    </item>
    <item>
      <title>将视觉与 Assistant API 集成</title>
      <link>https://community.openai.com/t/integrating-vision-with-assistant-api/699059#post_7</link>
      <description><![CDATA[是的，整个存储库会让人难以承受，这就是我分享 PR 的原因。如果您查看该 PR 上的“文件已更改”，可能会更容易理解。]]></description>
      <guid>https://community.openai.com/t/integrating-vision-with-assistant-api/699059#post_7</guid>
      <pubDate>Tue, 02 Apr 2024 12:03:52 GMT</pubDate>
    </item>
    <item>
      <title>辅助功能响应检索错误</title>
      <link>https://community.openai.com/t/assistant-function-response-retrive-error/705268#post_1</link>
      <description><![CDATA[您好，我正在使用助手来分析数据集中的对象。我正在使用函数从数据库获取数据集。但检索此数据时存在问题。例如，函数返回 1000 个对象的数据集，甚至对于“数据集中有多少个对象？”之类的简单问题。助理返回错误答案。检索到的对象的数量取决于模型。但最接近的结果是使用模型 gpt-4-turbo-preview 回答“300”。检索有一些限制吗？代码解释器和检索参数均已打开。]]></description>
      <guid>https://community.openai.com/t/assistant-function-response-retrive-error/705268#post_1</guid>
      <pubDate>Tue, 02 Apr 2024 12:00:41 GMT</pubDate>
    </item>
    <item>
      <title>您已达到 GPT-4、WTH 的当前使用上限</title>
      <link>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-wth/598606?page=3#post_64</link>
      <description><![CDATA[不过，您确实会收到无限的消息 - 只是不是无限的 GPT-4。
所以我不确定你认为这证明了什么。]]></description>
      <guid>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-wth/598606?page=3#post_64</guid>
      <pubDate>Tue, 02 Apr 2024 11:58:42 GMT</pubDate>
    </item>
    <item>
      <title>错误代码：404-错误代码：404 - {'error': {'message': '模型`gpt-4-vision-preview`不存在或您无权访问它</title>
      <link>https://community.openai.com/t/error-code-404-error-code-404-error-message-the-model-gpt-4-vision-preview-does-not-exist-or-you-do-not-have-access-to-it/705257#post_1</link>
      <description><![CDATA[错误代码：404 - {&#39;error&#39;: {&#39;message&#39;: &#39;模型 gpt-4-vision-preview 不存在或您无权访问它。&#39;, &#39;类型&#39;：&#39;invalid_request_error&#39;，&#39;参数&#39;：无，&#39;代码&#39;：&#39;model_not_found&#39;}}
代码-
PROMPT_MESSAGES = [
{
“角色”：“用户”，
“内容”：[
{“type”：“text”，“text”：“这张图片中有什么？”}，
 *map(lambda x: {&quot;image&quot;: x, &quot;resize&quot;: 468}, base64Frames[0::50]),
    ],
},

]
参数 = {
“模型”：“gpt-4-vision-preview”，
“消息”：PROMPT_MESSAGES，
“max_tokens”：200，
}
结果 = client.chat.completions.create(**params)
打印（结果.choices[0].message.content）]]></description>
      <guid>https://community.openai.com/t/error-code-404-error-code-404-error-message-the-model-gpt-4-vision-preview-does-not-exist-or-you-do-not-have-access-to-it/705257#post_1</guid>
      <pubDate>Tue, 02 Apr 2024 11:54:36 GMT</pubDate>
    </item>
    <item>
      <title>功能请求：基于内存的推理</title>
      <link>https://community.openai.com/t/feature-request-memory-informed-inference/705256#post_1</link>
      <description><![CDATA[Rn，我注意到代理的一个问题是推理的不连续性，这意味着除了聊天历史记录之外，所有内部上下文在推理结束时都会丢失。
为了看起来连续，推理使用了截至该点的聊天历史记录，以使其看起来连续，但这意味着每次您点击输入/发送请求时，后续的下一个推理实际上都是新的、单独的推理；因此，如果代理执行命令，下一个推断现在可能无法“为什么”或能够从提供的聊天历史记录（文本和图像）推断出关键细节，除非明确说明大声推理，即使如此，这也有点hacky并且经常失去细微差别。
如果有一种架构级别的方法来获取推理之间的重要上下文，即保存的先前激活或类似（“Larimar”）内存通知推理的内容，那就太好了 – 也许 RLHFd 使用内存单元来有效奖励存储、维护和使用重要的背景来完成目标和目标随着时间的推移进行各种推论的任务。如果可能的话，这可能比训练大型 SSM 更容易。
或者它可能是一个基于状态的系统，例如类似于大型 Mamba、Jamba 拱门的 SSM。
如果我们有基于记忆的推论，或先前的激活，或 SSM，我们将走在通往更加流畅和连贯的智能体的良好道路上，因为它们将能够“记住”过去的推论或有目标、“想法” &#39;，随着时间的推移，密集的上下文。
编辑：通过记忆，我的意思是基于非文本的解决方案，因为文本不是很紧凑，如果遗漏了任何细节，那么下一个推论仍然不知道“为什么”或关键细节。因此，需要最好保留密集上下文的东西。 &gt;&lt;’]]></description>
      <guid>https://community.openai.com/t/feature-request-memory-informed-inference/705256#post_1</guid>
      <pubDate>Tue, 02 Apr 2024 11:53:59 GMT</pubDate>
    </item>
    <item>
      <title>API 与使用 ChatGPT 作为助手的人（网站管理员、程序员、SEO 专家......）的 20 美元/月订阅</title>
      <link>https://community.openai.com/t/api-vs-20-month-subscription-for-those-who-use-chatgpt-as-an-assistant-webmasters-programmers-seo-specialists/695940#post_21</link>
      <description><![CDATA[非常感谢大家，我决定不使用 API 主要是出于成本原因。你真的帮了大忙。
关于公司，用同样的钱你可以获得两个付费版本，例如。 CHGPT 4.0 和 Claude 3.0，我看了 Perplexity 测试的视频（这对于自我搜索来说真的很酷，即使是免费版本 - 我的经验），当真正的 CHGPT 4.0 给出正确答案时，他们的 CHGPT 4.0 给出了错误的答案。
你自己检查过吗？它们的工作原理真的一样吗？
谢谢]]></description>
      <guid>https://community.openai.com/t/api-vs-20-month-subscription-for-those-who-use-chatgpt-as-an-assistant-webmasters-programmers-seo-specialists/695940#post_21</guid>
      <pubDate>Tue, 02 Apr 2024 11:53:12 GMT</pubDate>
    </item>
    </channel>
</rss>