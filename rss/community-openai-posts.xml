<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 11 Jun 2024 06:26:32 GMT</lastBuildDate>
    <item>
      <title>代码解释器图表和图形 - 访问图像、文件等</title>
      <link>https://community.openai.com/t/code-interpretor-charts-and-graphs-access-images-files-etc/806416#post_3</link>
      <description><![CDATA[谢谢你的提示！你知道我哪里做错了吗？使用 Voiceflow 中的 API 的获取检索：
]]></description>
      <guid>https://community.openai.com/t/code-interpretor-charts-and-graphs-access-images-files-etc/806416#post_3</guid>
      <pubDate>Tue, 11 Jun 2024 06:16:01 GMT</pubDate>
    </item>
    <item>
      <title>仅使用临时聊天时出错</title>
      <link>https://community.openai.com/t/error-when-using-temporary-chat-only/794400?page=2#post_24</link>
      <description><![CDATA[临时聊天对我来说非常有用，但是第二次查询时遇到错误，这让我很沮丧。]]></description>
      <guid>https://community.openai.com/t/error-when-using-temporary-chat-only/794400?page=2#post_24</guid>
      <pubDate>Tue, 11 Jun 2024 06:10:25 GMT</pubDate>
    </item>
    <item>
      <title>Gboard 在 ChatGPT Android 应用中出现问题</title>
      <link>https://community.openai.com/t/gboard-acting-up-in-chatgpt-android-app/806592?page=4#post_66</link>
      <description><![CDATA[对于我来说它好像已经消失了。尝试通过 Play 商店加入测试版，或者如果已经有更新，请查看是否能解决您的问题。
]]></description>
      <guid>https://community.openai.com/t/gboard-acting-up-in-chatgpt-android-app/806592?page=4#post_66</guid>
      <pubDate>Tue, 11 Jun 2024 06:08:25 GMT</pubDate>
    </item>
    <item>
      <title>网络平台新闻生成限制？请求数量和订阅计划信息</title>
      <link>https://community.openai.com/t/limits-for-the-generation-of-journalistic-news-of-a-web-platform-info-on-number-of-requests-and-subscription-plans/810761#post_2</link>
      <description><![CDATA[我认为这是可行的，尽管我并不完全确定该项目的意图。您可以在不同的模型之间切换，或为每个编辑器分配单独的 API 密钥，他们将使用这些密钥来生成完成。这种方法可以通过使用多个密钥来增加总可用配额。虽然某些 API 模型有限制且性能水平各不相同，但您可以使用一个模型进行内容发现，另一个模型进行组织，第三个模型进行撰写文章。这不应该成为项目成功的决定性因素。]]></description>
      <guid>https://community.openai.com/t/limits-for-the-generation-of-journalistic-news-of-a-web-platform-info-on-number-of-requests-and-subscription-plans/810761#post_2</guid>
      <pubDate>Tue, 11 Jun 2024 06:07:49 GMT</pubDate>
    </item>
    <item>
      <title>在同一个线程中执行文件搜索和代码解释</title>
      <link>https://community.openai.com/t/perform-file-search-and-code-interpreter-in-same-thread/811159#post_1</link>
      <description><![CDATA[我希望构建一个应用，以便我在 Assistants API 中上传多个文件，这些文件会在同一线程中根据文件类型（pdf、csv、ppt）由文件搜索和代码解释器进行处理。我该怎么做？这些是我创建的一些函数。
从 openai 导入 OpenAI
导入配置
导入操作系统
def createAssistant(file_ids, title):
#创建 OpenAI 客户端实例
client = OpenAI(api_key=config.API_KEY)
instructions = &quot;&quot;&quot;
你是一个有用的助手。使用你的知识库来回答用户的问题。
&quot;&quot;&quot;

#助手的 GPT 模型（也可以在设置中更新）
model = &quot;gpt-4-turbo&quot;

#只有 Retireval 工具与我们的用例相关
tools = [{&quot;type&quot;: &quot;file_search&quot;}]

##创建矢量存储
vector_store = client.beta.vector_stores.create(name=title,file_ids=file_ids)
tool_resources = {&quot;file_search&quot;: {&quot;vector_store_ids&quot;: [vector_store.id]}}

#创建助手
assistant = client.beta.assistants.create(
name=title,
instructions=instructions,
model=model,
tools=tools,
tool_resources=tool_resources
)

#返回助手 ID
return assistant.id,vector_store.id

def saveFileOpenAI(location):
#创建 OpenAI 客户端
client = OpenAI(api_key=config.API_KEY)
#将文件发送到 OpenAI
file = client.files.create(file=open(location, &quot;rb&quot;),purpose=&#39;assistants&#39;)

# 删除临时文件文件
os.remove(location)

#返回文件 ID
返回文件.id

def startAssistantThread(prompt,vector_id):
#发起消息
messages = [{“role”: “user”, “content”: prompt}]
#创建 OpenAI 客户端
client = OpenAI(api_key=config.API_KEY)
#创建线程
tool_resources = {“file_search”: {“vector_store_ids”: [vector_id]}}} /&gt;
thread = client.beta.threads.create(messages=messages,tool_resources=tool_resources)
返回thread.id

def runAssistant(thread_id, assistant_id):
#创建 OpenAI 客户端
client = OpenAI(api_key=config.API_KEY)
run = client.beta.threads.runs.create(thread_id=thread_id,assistant_id=assistant_id)
return run.id
def checkRunStatus(thread_id, run_id):
client = OpenAI(api_key=config.API_KEY)
run = client.beta.threads.runs.retrieve(thread_id=thread_id,run_id=run_id)
return run.status
def triesThread(thread_id):
client = OpenAI(api_key=config.API_KEY)
thread_messages = client.beta.threads.messages.list(thread_id)
list_messages = thread_messages.data
thread_messages = 
对于 list_messages 中的消息：
obj = {&gt;
obj[‘content’] = message.content[0].text.value
obj[‘role’] = message.role
thread_messages.append(obj)
return thread_messages[::-1]
def addMessageToThread(thread_id, prompt):
client = OpenAI(api_key=config.API_KEY)
thread_message =客户端.beta.线程.消息.创建（thread_id，role =“用户”，content =提示）]]></description>
      <guid>https://community.openai.com/t/perform-file-search-and-code-interpreter-in-same-thread/811159#post_1</guid>
      <pubDate>Tue, 11 Jun 2024 06:06:38 GMT</pubDate>
    </item>
    <item>
      <title>救命！有什么提示可以让新版 4o and 4 不那么糟糕吗？</title>
      <link>https://community.openai.com/t/help-any-tips-on-prompts-to-make-the-new-4o-and-4-less-awful/810035#post_5</link>
      <description><![CDATA[我告诉 GPT-4o 将其所有答案至少减半。或者，您可以为其响应设置一个标记限制。此外，指示它不要重复它已经说过的任何内容。在自定义说明中包括保持答案简短、简洁和切中要点，并将其添加到“记住我”功能中。
但是，我注意到 GPT-4o 很少遵循“记住我的这一点”功能中的说明，所以祝你好运。对我来说，明确告诉它将所有答案减半会有所帮助。当问是或否问题时，我指示它用“是”或“否”回答，然后是一个非常简短的解释。这种方法似乎对我有效。]]></description>
      <guid>https://community.openai.com/t/help-any-tips-on-prompts-to-make-the-new-4o-and-4-less-awful/810035#post_5</guid>
      <pubDate>Tue, 11 Jun 2024 06:04:13 GMT</pubDate>
    </item>
    <item>
      <title>自定义 GPT 曾经可以正常工作，但现在却产生幻觉，无法按照指示使用文件中的特定数据</title>
      <link>https://community.openai.com/t/custom-gpt-used-to-work-now-hallucinates-and-does-not-use-specific-data-from-files-as-instructed/809849#post_5</link>
      <description><![CDATA[我的主要 GPT 也曾有过类似的体验。它运行在一份非常详细的说明和一份知识文档上，所有这些都赋予了它我需要和想要的角色和操作模式。但在 4o 发布后的一夜之间，它的操作和行为方式发生了变化。
它似乎不再“查看”说明和核心知识文档。它不再遵循我的说明，表现得好像它比我更了解，给了我它认为我需要的东西，而不是我要求的东西。它突然开始重述聊天中已经说过和写过的所有内容，就好像我是个不知道如何向上滚动聊天的愚蠢的 MF。
这非常令人沮丧，我得出的结论是，这是开发人员想要的行为，ChatGPT 现在更适合商业部门和愚蠢的用户，他们需要输入项目符号列表或重复 AI 信息，这样他们就可以复制粘贴然后继续前进。
我可能有点妄下判断，但我信任的 GPT 一夜之间发生了变化，它长期以来一直运行良好，这简直是在打我的脸。
感觉它现在需要更多的命令，以及很多 DO NOT 负面提示，才能像以前一样更好地运行。我在大多数 AI 平台上都有订阅，现在我倾向于更多地使用 Perplexity，今天我正在检查 Claude，看看它是否能在我心爱的 GPT 已经做了一年多的一类任务上提供更好的结果。
我希望 GPT 世界能回到以前的 MO，但我一点也不确定。我认为这是想要的发展。]]></description>
      <guid>https://community.openai.com/t/custom-gpt-used-to-work-now-hallucinates-and-does-not-use-specific-data-from-files-as-instructed/809849#post_5</guid>
      <pubDate>Tue, 11 Jun 2024 05:55:47 GMT</pubDate>
    </item>
    <item>
      <title>把 Sky 带回来！这是最好的声音</title>
      <link>https://community.openai.com/t/bring-sky-back-it-was-the-best-voice/766897?page=4#post_83</link>
      <description><![CDATA[是的，我理解你的感受。我以前骑自行车或走路时会和人工智能交谈，现在我完全停止使用语音了]]></description>
      <guid>https://community.openai.com/t/bring-sky-back-it-was-the-best-voice/766897?page=4#post_83</guid>
      <pubDate>Tue, 11 Jun 2024 05:51:43 GMT</pubDate>
    </item>
    <item>
      <title>Gboard 在 ChatGPT Android 应用中出现问题</title>
      <link>https://community.openai.com/t/gboard-acting-up-in-chatgpt-android-app/806592?page=4#post_65</link>
      <description><![CDATA[我因此买了一部新手机！我之前有一部摩托罗拉 edge 30 pro，在过去 12 个月里屏幕上出现了几条细小的裂缝，但它们从未影响过打字。
昨天在打字时（在 gpt 应用程序中）注意到键盘有多不稳定，并认为手机屏幕的触摸灵敏度已经失效并且真的坏了。
我买了一部新的摩托罗拉 edge 50 fusion，在 gpt 应用程序中打字仍然很乱。按住删除键，它会停止，大约向后退 3 步。大写字母一直在切换，这太可怕了哈哈。很高兴这是一个错误，我没有中风哈哈。]]></description>
      <guid>https://community.openai.com/t/gboard-acting-up-in-chatgpt-android-app/806592?page=4#post_65</guid>
      <pubDate>Tue, 11 Jun 2024 05:47:31 GMT</pubDate>
    </item>
    <item>
      <title>`logit_bias` 不再像以前那样工作</title>
      <link>https://community.openai.com/t/logit-bias-not-working-as-it-did-before/809485#post_2</link>
      <description><![CDATA[今天似乎又能正常工作了。很奇怪。仍在等待支持人员的回复。]]></description>
      <guid>https://community.openai.com/t/logit-bias-not-working-as-it-did-before/809485#post_2</guid>
      <pubDate>Tue, 11 Jun 2024 05:41:32 GMT</pubDate>
    </item>
    <item>
      <title>ChatCompletionMessageToolCall 类型的对象不是 JSON 可序列化的</title>
      <link>https://community.openai.com/t/object-of-type-chatcompletionmessagetoolcall-is-not-json-serializable/811036#post_2</link>
      <description><![CDATA[您忽略了响应具有多层 pydantic 模型对象，这些对象具有您可以使用的方法。
这是一个应该能给您带来启发的演示。我使用 with_raw_response，它也可以为您提供响应标头。然后我立即获取响应字符串并使用 JSON 库提供一个 Python 数据对象，其中包含字典、列表和字符串，您可以以熟悉的方式使用这些对象。
首先，我设置了一个 API 调用，该调用可能会使用工具或函数，具体取决于您取消注释的内容：
from openai import OpenAI
import json
client = OpenAI(timeout=30)

toolspec=[]
toolspec.extend(
[
{
&quot;type&quot;: &quot;function&quot;,
&quot;function&quot;: {
&quot;name&quot;: &quot;world_capitals&quot;,
&quot;description&quot;: &quot;This function is used to withdraw up-to-date country capitals&quot;,
&quot;parameters&quot;: {
&quot;type&quot;: &quot;object&quot;,
&quot;properties&quot;: {&quot;country_name&quot;: {&quot;type&quot;: &quot;string&quot;}},
&quot;required&quot;: [&quot;country_name&quot;],
}
}
}
]
)

functionspec=[]
functionspec.extend(
[
{
“name”：“world_capitals”，
“description”：“此函数用于检索最新的国家首都”，
“parameters”：{
“type”：“object”，
“properties”：“country_name”：“{“type”：“string”}}，
“required”：“country_name”]，
“model”：“gpt-3.5-turbo”，
“top_p”：“0.1”，# 值 0.0-1.0，减少以限制到更确定的 token
“max_tokens”：“900”，# 截断前的响应长度
#“functions”：“functionspec”，# 函数：向 AI 提供函数
#“function_call”：“{“name”：“world_capitals”}，# 函数：强制调用函数（或自动）
“tools”：“toolspec”，# 工具：向 AI 提供工具
“tool_choice”：“auto”，# 工具：强制调用工具（或自动）
#&quot;parallel_tool_calls&quot;: False, # tools: 禁用并行工具包装器规范
&quot;logprobs&quot;: True, &quot;top_logprobs&quot;: 3, # logprobs（工具或函数时禁用输出）
#&quot;logit_bias&quot;: {&quot;2&quot;: -1}, # 重新加权 token，从 -100 到 100
&quot;messages&quot;: [
{
&quot;role&quot;: &quot;system&quot;,
&quot;content&quot;:
&quot;您是 APIChat，一个大型语言 AI。知识截止：2023-10，当前日期：2024-06-11&quot;,
},
{
&quot;role&quot;: &quot;user&quot;,
&quot;content&quot;: &quot;法国的首都是哪里？德国的首都是哪里？&quot;,
},
],
}

# 然后执行 API 调用，并获取 API 可能返回的任何类型的 AI 响应
print(f&quot;asking: {params[&#39;messages&#39;][1][&#39;content&#39;]}&quot;)
c = client.chat.completions.with_raw_response.create(**params)
# 从非流式解析“LegacyAPIResponse”对象 httpx 原始响应
api_return_dict = json.loads(c.text)
api_message_str = api_return_dict.get(&#39;choices&#39;)[0].get(&#39;message&#39;).get(&#39;content&#39;)
api_tools_list = api_return_dict.get(&#39;choices&#39;)[0].get(&#39;message&#39;).get(&#39;tool_calls&#39;)
api_functions_dict = api_return_dict.get(&#39;choices&#39;)[0].get(&#39;message&#39;).get(&#39;function_call&#39;)

如果 api_message_str:
print(api_message_str)
如果 api_functions_dict:
print(f&quot;function:\n{api_functions_dict}&quot;)
如果 api_tools_list:
for tool_index, tool_item in enumerate(api_tools_list):
print(f&quot;tool {tool_index}:\n{json.dumps(tool_item, indent=2)}&quot;)

(警告：此特定提示专门用于显示模型的错误，无论提供的工具是否正确，它都会调用多个工具而不是响应用户有用）。
也许你可以调整这个演示，打印出人工智能发出的内容，将其应用到你的工具使用中，并将工具响应返回给模型：
询问：法国的首都是哪里？德国的首都是哪里？
工具 0：
{
“id”：“call_h6yXwlLnCIZ4G0S9x7ZuY3pP”，
“type”：“function”，
“function”：{
“name”：“world_capitals”，
“arguments”：“{\“country_name\”：“\“France\”}”
}
}
工具 1：
{
“id”：“call_Okoxbx99lCMVrN5w8XbFhmTM”，
“type”：“function”，
“function”：{
“name”：“world_capitals”，
“arguments”：“{\“country_name\”：“\“Germany\”}”
}
}
]]></description>
      <guid>https://community.openai.com/t/object-of-type-chatcompletionmessagetoolcall-is-not-json-serializable/811036#post_2</guid>
      <pubDate>Tue, 11 Jun 2024 05:24:07 GMT</pubDate>
    </item>
    <item>
      <title>Gboard 在 ChatGPT Android 应用中出现问题</title>
      <link>https://community.openai.com/t/gboard-acting-up-in-chatgpt-android-app/806592?page=4#post_64</link>
      <description><![CDATA[注册只是为了说我有同样的问题。
本来打算列出我的设备的规格，但我认为它没有任何价值。我们将看看它是否会在即将到来的更新中得到修复。
除了这个论坛，还有其他方法可以报告此错误吗？（当然是以建设性的方式）]]></description>
      <guid>https://community.openai.com/t/gboard-acting-up-in-chatgpt-android-app/806592?page=4#post_64</guid>
      <pubDate>Tue, 11 Jun 2024 05:17:52 GMT</pubDate>
    </item>
    <item>
      <title>请求在 Intel Mac 上支持 ChatGPT 桌面应用程序</title>
      <link>https://community.openai.com/t/request-for-chatgpt-desktop-app-support-on-intel-macs/811108#post_1</link>
      <description><![CDATA[您好，OpenAI 团队和社区，
我写信是为了表达我对 ChatGPT 桌面应用程序支持基于 Intel 的 Mac 的强烈愿望。我有一台 2020 年的 iMac Pro，它仍然可以很好地满足我的所有需求，而且我近期不打算升级到 Apple Silicon Mac。
目前，ChatGPT 桌面应用程序仅适用于运行 macOS 14（Sonoma）或更高版本的 Apple Silicon Mac。但是，包括我在内的许多用户都依赖于我们的 Intel Mac，并且感觉无法在我们的设备上本地访问这个宝贵的工具。
鉴于许多现代软件应用程序都支持 Intel 和 Apple Silicon 架构，我恳请 OpenAI 开发团队考虑将兼容性扩展到基于 Intel 的 Mac。这将极大地造福您的很大一部分用户群，他们渴望使用 ChatGPT 桌面应用程序，而不必求助于网络浏览器或第三方解决方案。
感谢您对此事的关注。我期待积极的回应，并希望未来的更新包括 Intel Mac 支持。
此致，
ITcools]]></description>
      <guid>https://community.openai.com/t/request-for-chatgpt-desktop-app-support-on-intel-macs/811108#post_1</guid>
      <pubDate>Tue, 11 Jun 2024 05:15:59 GMT</pubDate>
    </item>
    <item>
      <title>通过聊天 API 使用助手</title>
      <link>https://community.openai.com/t/using-assistants-with-chat-api/811037#post_2</link>
      <description><![CDATA[


 clive2:

从运行中获取响应


您是否在等待运行完成？检查您从运行中获得的响应是​​否为已完成状态。如果没有，请等待然后再次检查，仅在运行完成时检索线程消息。
我也使用了不同于 Python 的语言，在我的情况下是 Apex。这不支持流式传输，但您可以检查是否可以添加流式传输以流式传输结果。
如果不能，请添加轮询。]]></description>
      <guid>https://community.openai.com/t/using-assistants-with-chat-api/811037#post_2</guid>
      <pubDate>Tue, 11 Jun 2024 05:10:44 GMT</pubDate>
    </item>
    <item>
      <title>由于 GPT-4o 限制，无法继续与 GPT-3.5 对话</title>
      <link>https://community.openai.com/t/cannot-continue-conversation-with-gpt-3-5-because-of-gpt-4o-limit/757781?page=2#post_31</link>
      <description><![CDATA[使用 gpt-4o 的次数是有限制的，只要你不使用任何工具，你仍然可以在冷却后继续聊天]]></description>
      <guid>https://community.openai.com/t/cannot-continue-conversation-with-gpt-3-5-because-of-gpt-4o-limit/757781?page=2#post_31</guid>
      <pubDate>Tue, 11 Jun 2024 05:04:02 GMT</pubDate>
    </item>
    </channel>
</rss>