<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 02 May 2024 06:24:55 GMT</lastBuildDate>
    <item>
      <title>Chat GPT 不再创建图像，引用“内容指南”</title>
      <link>https://community.openai.com/t/chat-gpt-is-no-longer-creating-images-quoting-the-content-guidelines/646645#post_10</link>
      <description><![CDATA[大家好请订阅我的频道 A.K 2 Game world 搜索我的账号，找到它，账号是@C2Abdullah订阅了，听说没有版本的chatGPT可以画图，心情不好]]></description>
      <guid>https://community.openai.com/t/chat-gpt-is-no-longer-creating-images-quoting-the-content-guidelines/646645#post_10</guid>
      <pubDate>Thu, 02 May 2024 06:24:41 GMT</pubDate>
    </item>
    <item>
      <title>功能请求：基于文件夹的 ChatGPT 对话组织</title>
      <link>https://community.openai.com/t/feature-request-folder-based-organization-for-chatgpt-conversations/672115#post_17</link>
      <description><![CDATA[我主要使用 ChatGPT 来提高工作效率并学习新技能。如果我想参考以前的聊天记录，我真的觉得翻阅它们很令人沮丧。我真的很想将与特定主题相关的聊天组织到集合/文件夹中。]]></description>
      <guid>https://community.openai.com/t/feature-request-folder-based-organization-for-chatgpt-conversations/672115#post_17</guid>
      <pubDate>Thu, 02 May 2024 06:12:11 GMT</pubDate>
    </item>
    <item>
      <title>定制训练的 GPT 3.5 Turbo 模型的再训练</title>
      <link>https://community.openai.com/t/retraining-of-custom-trained-gpt-3-5-turbo-model/661447#post_13</link>
      <description><![CDATA[嗨@jr.2509，
我在更多数量的标签上尝试了相同的方法。但我的观察是：

在第一基础模型训练中，它在第 1 组数据上提供了良好的准确性。
在重新训练上述模型时，第 1 组的准确率下降了 15% 到 20%，而第 2 组的准确率却很高。

问：


是因为，我们在再训练期间提供了不平衡的数据作为输入吗？即，在重新训练期间，第 1 组标签的数据较少，第 2 组标签的数据较多。


我们是否可以存储/保留第一个训练的开放式 AI Gpt 模型的权重，并且可以仅对第 2 组数据进行重新训练，而不是传递第 1 组和第 2 组数据进行重新训练，而不是采用这种混合方法？


因为初始组的再训练中准确性下降。
我们需要保持准确性。在我们的例子中，这种再训练将是迭代的。]]></description>
      <guid>https://community.openai.com/t/retraining-of-custom-trained-gpt-3-5-turbo-model/661447#post_13</guid>
      <pubDate>Thu, 02 May 2024 05:52:48 GMT</pubDate>
    </item>
    <item>
      <title>使用 Assistants v2 API / gpt-4-turbo 使幻觉急剧增加</title>
      <link>https://community.openai.com/t/dramatic-rise-in-hallucinations-with-assistants-v2-api-gpt-4-turbo/732256#post_4</link>
      <description><![CDATA[在 V1 模型中，我也经历了从上周到本周 5 月 1 日的行为变化。相同的程序，相同的预设提示，相同的内容。此前，系统会返回一个响应，其中包含与分析师进行的企业财报电话问答的简明摘要。现在，系统首先声明“作为人工智能，我没有接听电话或访问实时数据的能力。不过，我可以指导您如何根据您概述的要求分析财报电话会议。以下是构建分析的方法：”，然后它为我提供了分析调用的步骤列表，这基本上是 JSON 消息提示的反省，但是，它后面是实际的问答摘要。]]></description>
      <guid>https://community.openai.com/t/dramatic-rise-in-hallucinations-with-assistants-v2-api-gpt-4-turbo/732256#post_4</guid>
      <pubDate>Thu, 02 May 2024 05:17:02 GMT</pubDate>
    </item>
    <item>
      <title>我的经验：ChatGPT 数学真的很烂</title>
      <link>https://community.openai.com/t/my-experience-chatgpt-really-sucks-at-math/733652#post_1</link>
      <description><![CDATA[我不在乎基准测试怎么说。我从第一天起就用数学问题测试 chatGPT，我可以自信地说它（并且一直）在数学方面非常糟糕。
自从 ChatGPT 首次发布以来，我每天都会问几十个数学问题，即使是最简单的高级数学问题，我也不记得有一个正确答案。更糟糕的是，无论提示多么详细，它都不遵循说明。因此不可能通过这些步骤来获得正确的答案。
我提出的问题是研究生水平的问题，真正测试模型的数学智能。它们不是积分解之类的问题，与训练中（可能）使用的问题相比，唯一的区别是变量的命名。它们是特定的最优控制问题或简短的数学推导等问题。
我知道这些模型（目前）的设计初衷并不是擅长任何事实，但令人难以置信的是，chatGPT 在所有数学基准测试中似乎都名列前茅，但在实践中却表现得很糟糕。自从 Gemini 1.5 向公众发布以来，我一直在对它进行同样的测试：它在 99% 的情况下击败了 chatGPT；如果没有，可以直接告诉它哪里出了错误以及如何修复。
你有类似的经历吗？如果没有，您能否分享一下 ChatGPT 正确回答的问题类型？]]></description>
      <guid>https://community.openai.com/t/my-experience-chatgpt-really-sucks-at-math/733652#post_1</guid>
      <pubDate>Thu, 02 May 2024 05:11:20 GMT</pubDate>
    </item>
    </channel>
</rss>