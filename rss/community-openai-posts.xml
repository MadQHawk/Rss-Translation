<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sun, 31 Mar 2024 06:20:55 GMT</lastBuildDate>
    <item>
      <title>嵌入的工作</title>
      <link>https://community.openai.com/t/the-working-of-the-embeddings/234308#post_6</link>
      <description><![CDATA[


 Joyasree78：
&lt;块引用&gt;
Open AI 的嵌入是一个黑匣子，没有太多可用的文档。我用以下三个内容在 Cohere 和 Open AI 嵌入之间做了一些测试。我发现 Cohere 可以让我更好地控制相似度得分。很高兴听到对此的其他意见。可能是我没有正确使用 Open AI 嵌入。我拥有的三个文本是
Romwe 女式大码短袖袈裟深 V 腰带褶皱迷你派对紧身连衣裙
95% 涤纶，5% 氨纶
领带闭合
高弹材质，柔软度好，穿着舒适
这款派对紧身连衣裙采用裹身 V 领、蝙蝠袖、腰部自系带和褶饰细节
聚会、鸡尾酒会、晚会、舞会、夜生活、俱乐部和工作的好选择
弹性材质完美贴合您的身材，贴身剪裁营造出诱人的轮廓
下单前请参考图片中的尺寸测量

Romwe 女式大码休闲抽绳扭结前镂空 V 领短袖夏季性感修身连衣裙
100％涤纶
套穿闭合
高弹力，柔软舒适
女式剪裁抽绳 V 领高腰迷你连衣裙
聚会、鸡尾酒会、俱乐部、约会、工作、度假、休闲和正装的好选择
将这件正装搭配高跟鞋和额外的珠宝，打造别致的外观
下单前请参考图片中的尺寸测量

COOFANDY 男士肌肉剪裁纽扣正装衬衫长袖
50% 棉，48% 涤纶，2% 氨纶
进口
纽扣开合
机洗
【防皱】高品质梭织面料，轻盈透气，防皱正装衬衫，外观干净，让您的身体全天保持干爽舒适。
【柔软棉质面料】这款长袖衬衫穿着轻便舒适。弹性面料完美贴合所有体型，不受任何限制地在任何方向提供更大的活动能力，让您享受运动服级别的舒适度和活动能力。
【时尚设计】男式衬衫总是有多种类型。经典的纯色/格子图案永远不会出错。修身时尚正装衬衫，经典翻领、纽扣开合、长袖和金属撞色纽扣让您更加帅气迷人。
【场合】您可以将这款长袖纽扣衬衫与斜纹棉布裤/牛仔裤搭配，打造休闲日常穿着，或将弹力衬衫与正装裤搭配，打造优雅外观。这款智能衬衫是男士衣柜中的必备单品，适合所有季节，适合办公室、商务、约会、夜间外出、俱乐部、旅行和休闲日常穿着。
【衣物护理】可机洗。 ❤这款格子衬衫的面料与纯色的不同，更有弹性。请参阅产品描述中的以下尺码表，选择最适合您的尺寸

然后，我使用 Cohere 和 Open AI 将它们嵌入并存储在 Supbase 中。然后，当我对问题“列出男士修身长袖衬衫”进行余弦相似度计算时。我得到以下结果
开放人工智能嵌入
第一个文本 - 0.874352702871908
第二个文本 - 0.874352702871908
第三个文本 - 0.866211994130881
一致性嵌入
第一个文本 - 0.753884081524262
第二个文本 - 0.762143687765075
第三个文本 - 0.822315609664169
我的阈值是 0.79，因此通过 Cohere，我得到了正确的检索


Cohere 精确的相似性控制胜过 OpenAI 嵌入。例如，Cohere 的阈值为 0.79，可提供更准确的结果，正如我在 上的比较所证明的那样。]]></description>
      <guid>https://community.openai.com/t/the-working-of-the-embeddings/234308#post_6</guid>
      <pubDate>Sun, 31 Mar 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>有人有使用 GPT3.5 Turbo 进行 RAG 重新排名的经验吗？</title>
      <link>https://community.openai.com/t/anybody-had-experience-with-rag-reranking-with-gpt3-5-turbo/608804#post_14</link>
      <description><![CDATA[嗯，这总比没有好……但我宁愿在检索部分更早地使用重新排名。比方说，我不会通过标准的 3 个最接近的候选者 (k=3)，而是将 k-n 增加到 10，然后使用 LLM 重新排列这些块，之后只将得分最高的 3 个块带入生成部分。与纯粹基于嵌入的检索相比，LLM 支持的检索可以返回更多相关文档。如果没有评分高于 7 或 8 的块（如果您嵌入一年级儿童书籍并提出有关网络安全的问题，就会出现这种情况），那么我不会将这些块传递给生成部分，而是将其传递给生成部分。我宁愿发送一个输出，表明该问题没有相关的基础内容。这将是更可靠的方法，可以显着减轻幻觉。]]></description>
      <guid>https://community.openai.com/t/anybody-had-experience-with-rag-reranking-with-gpt3-5-turbo/608804#post_14</guid>
      <pubDate>Sun, 31 Mar 2024 06:07:25 GMT</pubDate>
    </item>
    <item>
      <title>被迫切换到 Amazon Bedrock 获取图像。 Dalle-3 每分钟请求数限制是荒谬的</title>
      <link>https://community.openai.com/t/forced-to-switch-to-amazon-bedrock-for-images-dalle-3-requests-per-minute-limits-are-absurd/702829#post_4</link>
      <description><![CDATA[是的，这有点极其愚蠢。
我给 Anthropic 5 美元，我基本上没有利率限制，并且可以在一分钟内清空我的帐户。也就是说，直到昨天，他们现在复制了这个深色图案。现在，米斯特拉尔只是一个民主竞争对手。
我对 DALL-E 的限制范围为 2 分钟至 6 分钟，基于“通话”，而不是成本或计算。向 OpenAI 发送 200 美元的人只得到其中的 14%？笨蛋。
唯一明显的动机是现在将更多现金存入 OpenAI 银行账户。他们甚至通过电子邮件提供诱惑优惠，让人们立即购买积分。是否期望关闭几个月内唯一的好型号？当服务质量被绕开时锁定以防止逃跑？将微软对Azure的“投资”变成现金的唯一方法是什么？]]></description>
      <guid>https://community.openai.com/t/forced-to-switch-to-amazon-bedrock-for-images-dalle-3-requests-per-minute-limits-are-absurd/702829#post_4</guid>
      <pubDate>Sun, 31 Mar 2024 06:06:23 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OPenAI api 比较 2 个图像的相似度</title>
      <link>https://community.openai.com/t/how-to-compare-2-image-simialrity-using-openai-api/700891#post_6</link>
      <description><![CDATA[嗨@arunantonyholmes，
当然，如果你向 GPT-4 Vision 询问余弦相似度，它不会给你。为此，您应该使用 Jupyter Notebook 和一些 Python。但正如 @pondin6666 建议的那样，你可能得不到你想要的东西（我仍然不明白什么）是用例 - 您到底想要测量相似性 - 颜色、形状或其他任何内容），然后您可能需要首先制作一个提示模板，以便视觉模型会以文本形式返回标准化响应（例如：people= True，sunshine = False，Bicicles = False，等等），然后嵌入两个图像的响应并使用余弦相似度。但有很多潜在的方法。如果我们知道您的用例到底是什么，也许我们可以给您提供更好的建议。]]></description>
      <guid>https://community.openai.com/t/how-to-compare-2-image-simialrity-using-openai-api/700891#post_6</guid>
      <pubDate>Sun, 31 Mar 2024 05:56:18 GMT</pubDate>
    </item>
    <item>
      <title>自定义 GPT 知识与外部操作</title>
      <link>https://community.openai.com/t/custom-gpt-knowledge-versus-external-actions/702827#post_3</link>
      <description><![CDATA[感谢 PaulBellow 的建议！
我同意部分问题可能与注意力有关，因为当我仅使用较小的文件配置自定义 GPT 时，我没有遇到此问题。我计划在不久的将来尝试将知识文件分解成更小的块，看看是否效果更好。
但是，我怀疑这里可能还有其他原因。事实上，自定义 GPT 可以正确回答有关较大知识文件的问题，但前提是我看到加载旋转器显示“搜索知识”。在第一次提示自定义 GPT 时，这种情况似乎永远不会发生。因此，我的假设是自定义 GPT 的工作原理如下：

OpenAI 将知识库的内容总结为紧凑的形式，并在第一次提示时将其作为上下文提供给模型（不是真正的 RAG）
如果用户明确要求更多信息，那么它会使用 RAG 管道从文件中提取更详细的知识并提供更准确的答案
对于大多数用户来说，这可能是一个很好的折衷方案，但对于我们正在尝试做的事情来说，这是一种很差的用户体验。

我想知道的是：如果我通过 API 作为操作提供自己的检索函数，自定义 GPT 是否每次都会一致地使用它，或者我会遇到相同类型的问题吗？]]></description>
      <guid>https://community.openai.com/t/custom-gpt-knowledge-versus-external-actions/702827#post_3</guid>
      <pubDate>Sun, 31 Mar 2024 05:54:53 GMT</pubDate>
    </item>
    <item>
      <title>如何将对话历史记录传回 API</title>
      <link>https://community.openai.com/t/how-to-pass-conversation-history-back-to-the-api/697083#post_13</link>
      <description><![CDATA[也许添加指令或指导作为系统指令的一部分可以帮助指导 GPT-3.5 模型的行为，特别是避免仅仅重复问题并确保它更好地理解上下文。我总是使用 contentAvoidanceDirective 。
系统指令=“”“
你是一个有用的助手。根据提供的聊天记录，
请将最终用户的问题改写为一个独立的问题。
确保将讨论的背景纳入您的回复中
无需逐字重复问题。
“”“
消息 = [
{“角色”：“系统”，“内容”：系统指令}，
{“role”: “user”, “content”: “夏天太阳什么时候升起？”},
{“role”: “assistant”, “content”: “通常早上 6 点左右。”},
{“角色”：“用户”，“内容”：“下一季怎么样？”}
]
完成 = client.chat.completions.create(
型号=“gpt-3.5-turbo”，
消息=消息，
）
或
这是我如何将其添加到提示中的另一个示例：
contentAvoidanceDirective =“请根据聊天记录重新表述最后一个问题，不要逐字重复。”
FinalMessage =“下一季怎么样？” # 这是需要重新措辞的最终消息的示例。
已清理的内容=“”“
夏天太阳什么时候出来？

通常是早上 6 点左右。
“”“

将指令与最终消息和清理后的内容组合
user_input = f&quot;{contentAvoidanceDirective}\n\n聊天历史记录：\n{cleanedContent}\n当前问题：\n{finalMessage}&quot;
消息 = [
{“role”: “system”, “content”: “你是一个有用的助手，需要根据对话的上下文进行交互。”},
{“角色”：“用户”，“内容”：user_input}
]
完成 = client.chat.completions.create(
型号=“gpt-3.5-turbo”，
消息=消息，
）]]></description>
      <guid>https://community.openai.com/t/how-to-pass-conversation-history-back-to-the-api/697083#post_13</guid>
      <pubDate>Sun, 31 Mar 2024 05:49:11 GMT</pubDate>
    </item>
    <item>
      <title>自定义 GPT 知识与外部操作</title>
      <link>https://community.openai.com/t/custom-gpt-knowledge-versus-external-actions/702827#post_2</link>
      <description><![CDATA[因大提示而失去注意力是众所周知的情况。
您是否尝试过将大文件分解为较小的文件？
我听说他们正在研究更大背景下的注意力，因此最终应该会有所改善。]]></description>
      <guid>https://community.openai.com/t/custom-gpt-knowledge-versus-external-actions/702827#post_2</guid>
      <pubDate>Sun, 31 Mar 2024 05:23:52 GMT</pubDate>
    </item>
    <item>
      <title>如何应对“懒惰”的GPT 4</title>
      <link>https://community.openai.com/t/how-to-deal-with-lazy-gpt-4/689286?page=6#post_116</link>
      <description><![CDATA[我已经等了一年多了（从聊 GPT 3 到现在聊 GPT 4）。当 chatGPT 和 OpenAI 自由地使用我的数据和其他人的数据用于他们的研究目的时，我不会再向他们捐赠任何资金。]]></description>
      <guid>https://community.openai.com/t/how-to-deal-with-lazy-gpt-4/689286?page=6#post_116</guid>
      <pubDate>Sun, 31 Mar 2024 05:21:25 GMT</pubDate>
    </item>
    <item>
      <title>最近 API 文本补全质量再次大幅下降</title>
      <link>https://community.openai.com/t/another-huge-decline-lately-in-api-text-completions-quality/702613#post_4</link>
      <description><![CDATA[当然，您会期望一致性和质量。这就是提高人工智能输出的重点，也是所有通用人工智能提供商所努力的目标。问题是，ChatGPT /API 已经出现大规模退化和惰性输出，特别是对于错综复杂的提示。我一直在使用许多 AGI 提供商（包括 chatGPT/API）进行提示、写作、编码、设计等，而这个 OpenAI 已经出现了巨大的下降，特别是在 2023 年末到 2024 年以及到现在（2024 年 3 月）。]]></description>
      <guid>https://community.openai.com/t/another-huge-decline-lately-in-api-text-completions-quality/702613#post_4</guid>
      <pubDate>Sun, 31 Mar 2024 05:18:22 GMT</pubDate>
    </item>
    </channel>
</rss>