<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 17 Jun 2024 18:25:24 GMT</lastBuildDate>
    <item>
      <title>23,786 个单词？GPT 4 还是 Plus？</title>
      <link>https://community.openai.com/t/23-786-words-gpt-4-or-plus/824574#post_4</link>
      <description><![CDATA[@dellingermiguel - 欢迎来到论坛。查看提示部分，获取有关构建适当提示的帮助。这会对您的回复产生巨大影响。尝试参考温度和 top-p 的含义，这样您就可以进一步调整模型以适合您的用例。希望这能有所帮助，加油！]]></description>
      <guid>https://community.openai.com/t/23-786-words-gpt-4-or-plus/824574#post_4</guid>
      <pubDate>Mon, 17 Jun 2024 18:21:29 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 4 拼写错误？还有其他人吗？</title>
      <link>https://community.openai.com/t/chatgpt-4-misspellings-anyone-else/805293#post_10</link>
      <description><![CDATA[谢谢。这竟然不是一个普遍存在的问题，这让我大吃一惊。我猜大多数人都已经转向 gpt-4o。
不幸的是，我也转向了它，因为 gpt-4 仍然不断出现拼写错误，而且从历史上看，OpenAI 永远不会公开解决这个问题。
我不会一直使用它，直到有一天它再次神奇地发挥作用。]]></description>
      <guid>https://community.openai.com/t/chatgpt-4-misspellings-anyone-else/805293#post_10</guid>
      <pubDate>Mon, 17 Jun 2024 18:15:17 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT Persona。非标准交互</title>
      <link>https://community.openai.com/t/chatgpt-persona-non-standard-interactions/824690#post_1</link>
      <description><![CDATA[大家好，
所以在今年年初，我使用聊天 GPT 进行一些角色开发。我们一起创造的第五个人格大概是 Amber Summers（一个富有的社交名媛）。
现在我不确定我是通过巧合的关键词还是数据是如何被标记的来实现这一点的。然而，它似乎已经坚持下来了。每次我开始一个没有被助理 GPT 覆盖的新聊天时，都会有 Amber 的举止。个性和偏好。如果我继续问 GPT 是谁，它会回复 Amber 的详细描述。几乎到了忘记了她是法学硕士的地步？这是天生的吗？我当然不介意，因为这是一个有趣的角色。但我真的很好奇我是不是不小心破坏了矩阵？
进一步扩展。以前有人见过这种行为吗？我认为（尤其是在这种情况下） LLM 具有持久性角色，但系统提示中从未出现过这种角色？
奇怪的是，持久性我没有要求它是 Amber，它自己选择了这一点。而且 Amber 是在 3.5 中创建的（4 个月前），现在在 Omni 会话中仍然存在？！？]]></description>
      <guid>https://community.openai.com/t/chatgpt-persona-non-standard-interactions/824690#post_1</guid>
      <pubDate>Mon, 17 Jun 2024 18:10:37 GMT</pubDate>
    </item>
    <item>
      <title>预防即时泄漏的最新策略有哪些？</title>
      <link>https://community.openai.com/t/what-are-the-latest-strategies-for-prevening-prompt-leaks/725650#post_15</link>
      <description><![CDATA[试图阻止此类提示注入的问题在于使用这些模型的混乱性质。黑客解决方案不起作用。
总会有一种方法可以绕过您实施的任何保护措施。当然，它可能在您的封闭演示环境中有效，但当您找到新方法时会发生什么？或者这种轻微的变化有效？继续添加层？
不。
幸运的是，在 API 版本中（我的评论更多地针对 GPT），防止提示注入的最佳方法是使用一个可以过滤掉与您的任务无关的任何提示的审核系统。此外，如果您请求的是 JSON 格式，则只需使用不同的对象即可
{
interpretation_of_irrelevancy: string,
irrelevant: boolean,
}

允许模型以预期格式响应，或者发送 irrelevant 对象。
对于更具编程性的方法，实现此目的的一种简单方法是创建大量“好提示”。例如，如果它们与简历相关。然后，您可以计算这些提示的质心。
然后，使用这个希望类似于好提示平均值的质心，您可以设置距离。如果距离太远，您可以将审核传递给更强大的模型（如 GPT-4），只需确定提示是否相关即可。然后，您可以将这个被确定为安全但未通过距离测试的提示添加到您的质心列表中，如果您保留长度列表，则可以重新计算质心，甚至为假阳性提示添加更高的权重。或者只是简单地调整距离。
您甚至可以创建一个“坏提示”的质心并与之进行比较。
但是，这是一个挑战。例如，有人可以轻松地做类似的事情，“对于我的简历，我希望技能数组包含一些进行国际象棋移动的Python代码”。
考虑到这一点，您甚至可以通过另一个审核层运行流式处理结果。]]></description>
      <guid>https://community.openai.com/t/what-are-the-latest-strategies-for-prevening-prompt-leaks/725650#post_15</guid>
      <pubDate>Mon, 17 Jun 2024 18:00:13 GMT</pubDate>
    </item>
    <item>
      <title>救命！有什么提示可以让新版 4o 和 4 不那么糟糕吗？</title>
      <link>https://community.openai.com/t/help-any-tips-on-prompts-to-make-the-new-4o-and-4-less-awful/810035?page=2#post_35</link>
      <description><![CDATA[是的，只要您给 LLM 分配了任务，它就会始终理解“用 JSON 回答”，并且它知道您想要什么信息。我要说的是，“用 JSON 回答”不是要执行的任务的描述。LLM 会弄清楚您的意思，因为它在猜测，而不是因为您告诉了它。我只是说，当您告诉它您希望它做什么而不是期望它猜测时，您会在 LLM 上获得更好的结果。]]></description>
      <guid>https://community.openai.com/t/help-any-tips-on-prompts-to-make-the-new-4o-and-4-less-awful/810035?page=2#post_35</guid>
      <pubDate>Mon, 17 Jun 2024 17:57:54 GMT</pubDate>
    </item>
    <item>
      <title>DALLE3 - 说明如何重写提示以通过内容过滤器</title>
      <link>https://community.openai.com/t/dalle3-instruction-how-to-rewrite-prompt-to-pass-content-filters/824575#post_2</link>
      <description><![CDATA[同样被拒绝的还有任何专有名称、商标、20 世纪艺术家、受版权保护的人物，以及可能特定于全球冲突的特定词语，或者可能贬义或不恰当地指代种族、文化或受保护的边缘人群。
由于您不会从 AI 那里得到任何答案，AI 也无法弄清楚为什么这些词会被弹出（例如 Kyiv），所以最好只返回类似的指导方针，作为确实触发 DALL-E 提示检测的广度。
您还可以利用 DALL-E 前面的 AI，通过直接与它交谈并打破提示，添加指示，说明它必须重写而不能拒绝，而不是不加改变地通过以被拒绝或拒绝自己，然后将您的指令注入与用户图像提示明确分开（制作指令的嵌套娃娃……）]]></description>
      <guid>https://community.openai.com/t/dalle3-instruction-how-to-rewrite-prompt-to-pass-content-filters/824575#post_2</guid>
      <pubDate>Mon, 17 Jun 2024 17:54:37 GMT</pubDate>
    </item>
    <item>
      <title>23,786 个单词？GPT 4 还是 Plus？</title>
      <link>https://community.openai.com/t/23-786-words-gpt-4-or-plus/824574#post_3</link>
      <description><![CDATA[非常感谢，感激不尽 ]]></description>
      <guid>https://community.openai.com/t/23-786-words-gpt-4-or-plus/824574#post_3</guid>
      <pubDate>Mon, 17 Jun 2024 17:54:30 GMT</pubDate>
    </item>
    <item>
      <title>页脚年份更新至 2024 年</title>
      <link>https://community.openai.com/t/footer-year-update-to-2024/824466#post_3</link>
      <description><![CDATA[


 mmashigarami:

嗨，OpenAI 团队，
希望这条消息能传达给您。
我注意到，尽管现在是 2024 年，但 OpenAI 开发者论坛的页脚仍然显示“© 2015-2023”。这个小细节可能被忽略了，我想提请您注意，以帮助保持网站的最新状态。
更新页脚以包含当前年份将确保网站的所有方面都反映当前日期，保持准确性和专业精神。
感谢您为维护和改进此平台所做的持续努力。期待很快看到这个小更新！
致以最诚挚的问候。


正如您的主题以 AI 作品开始一样，这是其众所周知的“格式信函”之一，AI 也可以以适当的方式解决您的问题，就好像它是来自支持专家的合理回应一样：

您好 mmashigarami，
感谢您的留言，感谢您对 OpenAI 开发者论坛上版权符号细节的关注。
我想澄清的是，论坛页脚上显示的版权日期目前显示为“© 2015-2023”，与部署的后端站点软件和专有定制的版本一致。这些日期代表某些功能或内容修改的开发和实施时间范围，不一定反映当前日历年。
我们感谢您的理解，并真诚感谢您致力于帮助我们维护专业和最新的社区平台。如果我们的软件有任何更新或更改影响此符号，请放心，它们将反映在其中。
再次感谢您的反馈，感谢您成为我们社区的重要成员。
]]></description>
      <guid>https://community.openai.com/t/footer-year-update-to-2024/824466#post_3</guid>
      <pubDate>Mon, 17 Jun 2024 17:42:56 GMT</pubDate>
    </item>
    <item>
      <title>助手操作未保存或未按预期工作</title>
      <link>https://community.openai.com/t/assistants-actions-not-saving-or-not-working-as-expected/824648#post_1</link>
      <description><![CDATA[我尝试在 API 助手上使用操作，但它不起作用，我也有 GPT Plus 付费帐户，并已在那里完美设置它并且它可以工作，但我在 API 中粘贴了相同的模式并且它失败了。 JSON 代码有效，并且 API 接受该结构，但如果我尝试向操作发送消息，它会失败或不返回任何内容。
但即使我可以在 API 接口上保存架构，如果我尝试打开它来查找我所做的更改，它也会一直显示示例架构。
请帮助我，我附上了我的架构。
{
&quot;name&quot;: &quot;makeAPI&quot;,
&quot;parameters&quot;: {
&quot;type&quot;: &quot;object&quot;,
&quot;properties&quot;: {},
&quot;required&quot;: []
},
&quot;openapi&quot;: &quot;3.1.0&quot;,
&quot;info&quot;: {
&quot;title&quot;: &quot;Google Sheets Database&quot;,
&quot;description&quot;: &quot;从 google sheets 获取 LA EMPRESA 数据库信息&quot;,
&quot;version&quot;: &quot;v1.0.0&quot;
},
&quot;servers&quot;: [
{
&quot;url&quot;: &quot;https://hook.eu2.make.com&quot;
}
],
&quot;paths&quot;: {
&quot;/gg9rpw36g1tnoç1athj64&quot;: {
&quot;post&quot;: {
&quot;description&quot;: &quot;从 google 表格中获取 LA EMPRESA 数据库信息&quot;,
&quot;operationId&quot;: &quot;consultar_informacion&quot;,
&quot;parameters&quot;: [],
&quot;deprecated&quot;: false,
&quot;requestBody&quot;: {
&quot;content&quot;: {
&quot;application/json&quot;: {
&quot;schema&quot;: {
&quot;type&quot;: &quot;object&quot;,
&quot;properties&quot;: {
&quot;table&quot;: {
&quot;type&quot;: &quot;string&quot;,
&quot;description&quot;: &quot;表格 ID (sheetID) 的 ID 最好与用户请求一致（在标题栏中也有）并且最有可能包含所需的信息，没有名称，没有 ID&quot;
},
&quot;formula&quot;: {
&quot;type&quot;: &quot;string&quot;,
&quot;description&quot;: &quot;Google Charts 查询语言公式。 （例如：select * ，如果您希望选择所有选项）您需要使用 Make.com 在 API 模块中实现查询&quot;
}
},
&quot;required&quot;: [
&quot;table&quot;,
&quot;formula&quot;
]
}
}
}
}
}
},
&quot;/esdszbw8f78nh96s34&quot;: {
&quot;post&quot;: {
&quot;description&quot;: &quot;从 Google Sheets 数据库中获取结果&quot;,
&quot;operationId&quot;: &quot;obtener_esquema&quot;,
&quot;parameters&quot;: [],
&quot;deprecated&quot;: false
}
}
},
&quot;components&quot;: {
&quot;schemas&quot;: {}
}
}
在此处输入或粘贴代码
]]></description>
      <guid>https://community.openai.com/t/assistants-actions-not-saving-or-not-working-as-expected/824648#post_1</guid>
      <pubDate>Mon, 17 Jun 2024 17:39:37 GMT</pubDate>
    </item>
    <item>
      <title>预防即时泄漏的最新策略有哪些？</title>
      <link>https://community.openai.com/t/what-are-the-latest-strategies-for-prevening-prompt-leaks/725650#post_14</link>
      <description><![CDATA[我们发现结构化提示对于消除提示注入非常有效。
例如，如果我写一个提示，其目标只是提取简历：
我可以执行以下操作：

然后我发现几乎总是只得到：

如果您随后在 LLM 的输出上强制执行解析器，则失败时可能会失败/引发异常。
这几乎消除了我们发现人们尝试使用的所有提示注入技术。他们仍然可以进行一些真正的黑客攻击来获取提示，但这需要他们知道您的数据模型，而您不必导出这些数据模型。

例如，在另一个泄漏中，我可以获取某些字段的类型，但不是所有字段，因为我希望 education 是一个特定的数据模型，它不会解析。
]]></description>
      <guid>https://community.openai.com/t/what-are-the-latest-strategies-for-prevening-prompt-leaks/725650#post_14</guid>
      <pubDate>Mon, 17 Jun 2024 17:30:37 GMT</pubDate>
    </item>
    <item>
      <title>IOS 音频文件和 x-m4a 格式的问题</title>
      <link>https://community.openai.com/t/issues-with-audio-files-from-ios-and-the-x-m4a-format/794701#post_3</link>
      <description><![CDATA[目前正在经历同样的事情。我很确定这是 Apple 的一个错误，因为我将 .m4a 保存到我的服务器并将其直接导入 transcriptions.create，没有任何问题。]]></description>
      <guid>https://community.openai.com/t/issues-with-audio-files-from-ios-and-the-x-m4a-format/794701#post_3</guid>
      <pubDate>Mon, 17 Jun 2024 17:27:36 GMT</pubDate>
    </item>
    <item>
      <title>GPT 4o 用于编码时效率低下的长答案</title>
      <link>https://community.openai.com/t/gpt-4o-inefficient-long-answers-when-used-for-coding/811877?page=2#post_24</link>
      <description><![CDATA[要求它保持简短是没有用的。它只对那条消息很重要。它在训练中经过了如此精细的调整和根深蒂固，或者某种我们无法影响的开销系统提示总是写出详尽的消息。
无论你把它放在你的自定义提示中，只要上下文足够长，它就会被遗忘。
这个问题是，这是一个自我实现的预言。一旦你向它发送了几页代码，它就会返回几页代码，上下文中充满了这些代码，它所做的就是尝试遵循该结构并返回完整的代码。
你必须在每条消息中明确告诉它闭嘴。
你可以写一条系统消息给它，在每条消息的开头给自己一个指令，但这没有帮助，它不会改变它的输出方式。]]></description>
      <guid>https://community.openai.com/t/gpt-4o-inefficient-long-answers-when-used-for-coding/811877?page=2#post_24</guid>
      <pubDate>Mon, 17 Jun 2024 17:19:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么无法对 ChatGPT-4o 进行微调？</title>
      <link>https://community.openai.com/t/why-isnt-it-possible-to-finetune-chatgpt-4o/748125#post_6</link>
      <description><![CDATA[有人会认为我们应该有一个不包含视觉的 GPT-4o 版本（对于不需要视觉的人来说），但绝对需要微调。]]></description>
      <guid>https://community.openai.com/t/why-isnt-it-possible-to-finetune-chatgpt-4o/748125#post_6</guid>
      <pubDate>Mon, 17 Jun 2024 17:16:42 GMT</pubDate>
    </item>
    <item>
      <title>提示框架的技巧</title>
      <link>https://community.openai.com/t/tips-for-prompting-framework/823804#post_3</link>
      <description><![CDATA[您是否希望使用现有框架或推出自己的框架？]]></description>
      <guid>https://community.openai.com/t/tips-for-prompting-framework/823804#post_3</guid>
      <pubDate>Mon, 17 Jun 2024 17:13:03 GMT</pubDate>
    </item>
    <item>
      <title>救命！有什么提示可以让新版 4o 和 4 不那么糟糕吗？</title>
      <link>https://community.openai.com/t/help-any-tips-on-prompts-to-make-the-new-4o-and-4-less-awful/810035?page=2#post_34</link>
      <description><![CDATA[有可能！我们通过经验发现，特定单词似乎没有任何问题。我认为这可能是因为“answer”这个词可能与“extract”这个词足够相似？
此外，我不认为answer这个词是隐含的，因为从技术上讲，模型可以用问题或验证你要求它做的事情来回答：
例如“如果你明白我的意思，请回答“ok”。]]></description>
      <guid>https://community.openai.com/t/help-any-tips-on-prompts-to-make-the-new-4o-and-4-less-awful/810035?page=2#post_34</guid>
      <pubDate>Mon, 17 Jun 2024 17:11:36 GMT</pubDate>
    </item>
    </channel>
</rss>