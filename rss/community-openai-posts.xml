<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sun, 07 Apr 2024 15:19:43 GMT</lastBuildDate>
    <item>
      <title>最好将所有内容都包含在第一个提示中，还是将第一个提示和 eval 提示分开？</title>
      <link>https://community.openai.com/t/better-to-include-everything-in-the-first-prompt-or-split-between-first-and-an-eval-prompt/709989#post_2</link>
      <description><![CDATA[我会继续将其分为两个步骤，因为这样可以进行更有针对性的评估和增强。
关于第二个问题：



 eivu：
&lt;块引用&gt;
就这个问题而言，如果我将其分成两个单独的迭代，那么我应该在第一个迭代中包含什么内容，在第二个“评估”迭代中包含什么内容？


您能与我们分享您当前的提示吗？听起来您已经有了一个两步模型，我们可以将其用作起点并进行审查以进行潜在的进一步优化。]]></description>
      <guid>https://community.openai.com/t/better-to-include-everything-in-the-first-prompt-or-split-between-first-and-an-eval-prompt/709989#post_2</guid>
      <pubDate>Sun, 07 Apr 2024 15:17:02 GMT</pubDate>
    </item>
    <item>
      <title>角色：client.chat.completions.create 中的助理</title>
      <link>https://community.openai.com/t/role-assistant-in-client-chat-completions-create/709144#post_7</link>
      <description><![CDATA[


 nisant031：
&lt;块引用&gt;
这是因为模型不记得之前是否问过同样的问题吗？他们将从头开始计算一切？


是的。



 nisant031：
&lt;块引用&gt;
对于一个简单的问题问两次，我是否会得到类似但不相同的答复？


输出中注入了一定程度的随机性 - 您可以使用温度和 top_p 参数来控制它。
如果您前往完成游乐场 (https://platform.openai.com/playground/complete)，您可以切换概率：

这显示了令牌被预测的可能性。请注意，所有可能的令牌概率（数十万个选项）加起来都是 1。
较高的温度会使概率分布“平坦化”，因此更不可能的标记有更高的机会被选择。将其设置为零（将在后端更改为一个非常小的数字）以防止低概率上升到顶部。
top_p 定义了从中选择令牌的桶有多大。 1 (100%) 允许假设选择所有令牌。 0.1 只允许选择前 10% 之一。如果将其设置为 0，则仅选择最有可能的标记。
如果将温度或 top_p 设置为 0，则更有可能获得确定性结果。不能保证（可能是由于舍入误差或其他原因，可能是宇宙射线，可能是错误，谁知道），但通常非常接近。]]></description>
      <guid>https://community.openai.com/t/role-assistant-in-client-chat-completions-create/709144#post_7</guid>
      <pubDate>Sun, 07 Apr 2024 15:03:13 GMT</pubDate>
    </item>
    <item>
      <title>OpenAlignment，一家 OpenAI 需要创建的公司/非营利组织</title>
      <link>https://community.openai.com/t/openalignment-a-company-nonprofit-openai-needs-to-create/708957#post_5</link>
      <description><![CDATA[


_j：
&lt;块引用&gt;
奥特曼返回后上个月，Sutskever 与 OpenAI 合作，董事会大部分成员辞职，Sutskever 在公司的未来似乎充满不确定性。


是的，这个关键要点就在这里。从那时起，几乎没有提及任何联盟或伊利亚。
但即使什么都没有改变，也没有解散，这个联盟还是原来的形式，范围还不够广泛。
再次感谢您的回复，但我觉得您浏览了我的帖子，您的收获是“人们希望 OpenAI 能够解决对齐问题”，当然，这是事实，但这只是我正在尝试的一方面建立。
需要有一个像 OpenAI 本身一样突出的外部协调组织，它需要解决人工智能给社会带来的问题，而不仅仅是调整他们最强大的 LLM 模型以确保安全......（尽管每个人工智能公司都应该拥有一个超级对齐团队。)


预测：提醒世界注意新的人工智能技术，例如 Sora。 OpenAI 发布 Sora 并不是为了让世界习惯这项技术的存在。伟大的。但还有很多东西需要“整个世界”进行教育和寻找。


风险管理和缓解：组织需要开始针对各种技术进行政策讨论的对话。不知道大家有没有注意到，美国政府在立法层面有些两极分化，反应迟缓。直面问题并提出可能的立法建议，以避免负面后果。 （示例： 每个制造商都应该为其应用创建一份 SDS，列出其可能产生的任何负面影响。）


协作：该组织应该是一种技术中心，多家公司和政策制定者共同努力解决某些问题。谷歌、微软、Anthropic 应该合作，共同研究如何确保公众免受其正在开发的产品的侵害。如果他们只有在发生不可逆转的事情时才决定这样做，他们将失去公众的信任。 他们需要抢先一步，总有一天，手指会开始寻找一个实体来为发生的任何负面变化负责。这将会发生。


技术乐观：除了所有负面影响之外，OpenAlignment 还应该努力消除有关 AI 的错误信息，并帮助通过实际用例向世界展示其好处。就像 OpenAI 与 Sora 所做的一样，成为一个邀请公众使用和试验新技术的实体，以弥合技术创造者与他们希望将其引入的世界之间的差距。 


当然，还要继续原来的“超级对齐小组”的工作，该小组也将忙得不可开交。但我的提议比该小组的范围要大得多。


我们需要一个致力于使人工智能技术与社会保持一致的组织，而不仅仅是协调各个模型的内部运作。所有最大的参与者都需要为此做出贡献，不仅是金钱，还包括人力资本。]]></description>
      <guid>https://community.openai.com/t/openalignment-a-company-nonprofit-openai-needs-to-create/708957#post_5</guid>
      <pubDate>Sun, 07 Apr 2024 14:58:05 GMT</pubDate>
    </item>
    <item>
      <title>4Turbo 模式的 API 不提供干净的 JSON</title>
      <link>https://community.openai.com/t/api-with-4turbo-modal-not-providing-a-clean-json/710027#post_1</link>
      <description><![CDATA[你好，
也许这里有人可以帮忙
我有一个与 GPT 4 配合良好的提示，并以 JSON 格式返回响应，但现在当我测试 4 Turbo 模式时，它无法按预期工作。
请求中有以下内容：“``json”
这会“搞乱”我的系统，因为它需要 JSON 格式的响应。]]></description>
      <guid>https://community.openai.com/t/api-with-4turbo-modal-not-providing-a-clean-json/710027#post_1</guid>
      <pubDate>Sun, 07 Apr 2024 14:46:08 GMT</pubDate>
    </item>
    <item>
      <title>角色：client.chat.completions.create 中的助理</title>
      <link>https://community.openai.com/t/role-assistant-in-client-chat-completions-create/709144#post_6</link>
      <description><![CDATA[谢谢。这很有帮助。
对于一个简单的问题问两次，我是否会得到类似但不相同的答复？
第一次：

第二次响应：
要查找值不超过 10 的斐波那契数列，我们可以编写一个 Python 代码片段来生成该数列。这是代码：
def 斐波那契(n):
    fib_系列 = [0, 1]
    而 fib_series[-1] + fib_series[-2] &lt;= n：
        fib_series.append(fib_series[-1] + fib_series[-2])
    返回 fib_series

fibonacci_series = 斐波那契(10)
打印（斐波那契数列）

当您运行此代码时，它将输出最多为 10 的斐波那契数列。
====================
尽管响应相似，但准确率不到 10%。
这是因为模型不记得以前是否曾问过同样的问题吗？他们将从头开始计算一切？]]></description>
      <guid>https://community.openai.com/t/role-assistant-in-client-chat-completions-create/709144#post_6</guid>
      <pubDate>Sun, 07 Apr 2024 14:23:37 GMT</pubDate>
    </item>
    <item>
      <title>[Python] 需要编码帮助。 NPC对话历史不能超过800个代币</title>
      <link>https://community.openai.com/t/python-need-coding-help-npc-conversation-history-cant-pass-800-tokens/710007#post_1</link>
      <description><![CDATA[您好，chatGPT API 相当新，我一直在 chatGPT 上工作，以便在我的游戏中进行真实的 NPC 对话。该代码是用 Python 编写的，应该记住我们之前讨论过的内容。
它有效……直到令牌总数达到 800~，然后如果我不删除之前的消息，AI 会完全重置，并且不记得任何东西。相当于 2~3 条消息。
如果我不将“max_tokens_limit”设置为 800，功能块看起来像这样，在最后几行附近。对话不断重置。
“gpt-3.5-turbo-16k”应该有一个“16385”令牌限制，但是，对话每 2~3 个提示就会重置，大约达到 800~ 使用的令牌。
有人知道我做错了什么吗？
client = OpenAI(api_key=&quot;sk----------------&quot;)

消息 = [
    {&quot;角色&quot;: &quot;系统&quot;, &quot;内容&quot;: systemRoleMssg},
    {“角色”：“用户”，“内容”：userInitilizingMssg}
]

最大令牌限制 = 16385

def sendMssgToChatGPT(text_MSG):##在此处插入提示
    # 如果消息列表不存在则初始化
    如果“消息”不在 globals() 中：
        全球消息
        消息 = []
    
    # 附加用户消息
    messages.append({&quot;角色&quot;: &quot;用户&quot;, &quot;内容&quot;: text_MSG})

    # 生成补全
    完成 = client.chat.completions.create(
        型号=“gpt-3.5-turbo-16k”，
        消息=消息，
        最大令牌数=300
    
    ）
    
    # 获取模型响应
    model_response =completion.choices[0].message.content
    
    # NPC 或 chatGPT 是这么说的：
    打印（模型响应）

    # 附加助手响应
    messages.append({&quot;角色&quot;: &quot;助理&quot;, &quot;内容&quot;: model_response})

    # 计算token总数
    Total_tokens = sum(len(message[&quot;content&quot;].split()) 如果消息中有“内容”，则消息中的消息为 0）

    # 如果达到令牌限制，则删除旧消息
    同时total_tokens &gt; (max_tokens_limit): ##如果我不更改 max_tokens_limit = 800，chatGPT 在达到 800 后刷新，尽管令牌不断增加
        已删除的消息 = messages.pop(1)
        Total_tokens -= len(removed_message[&quot;content&quot;].split()) 如果“content”在removed_message中，则为0
]]></description>
      <guid>https://community.openai.com/t/python-need-coding-help-npc-conversation-history-cant-pass-800-tokens/710007#post_1</guid>
      <pubDate>Sun, 07 Apr 2024 14:17:08 GMT</pubDate>
    </item>
    <item>
      <title>如何获取 JSON 格式的 API 响应</title>
      <link>https://community.openai.com/t/how-to-get-api-response-in-json-format/605909#post_8</link>
      <description><![CDATA[您可能会考虑的一个缓慢但 100% 可靠的解决方案是在助手中启用“代码解释器”并指示助手将结果写入 JSON 文件。然后就可以获取助手创建的这个JSON文件的内容了。]]></description>
      <guid>https://community.openai.com/t/how-to-get-api-response-in-json-format/605909#post_8</guid>
      <pubDate>Sun, 07 Apr 2024 14:04:00 GMT</pubDate>
    </item>
    </channel>
</rss>