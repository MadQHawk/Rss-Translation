<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 09 Jul 2024 09:21:06 GMT</lastBuildDate>
    <item>
      <title>2023/2024 年 DALLE3 画廊：分享您的创作</title>
      <link>https://community.openai.com/t/dalle3-gallery-for-2023-2024-share-your-creations/431189?page=30#post_615</link>
      <description><![CDATA[                src=&quot;https://global.discourse-cdn.com/openai1/optimized/4X/6/9/5/695dc4f82379955830176950e94cdae8e0f72dd4_2_690x394.webp&quot; width=&quot;690&quot; /&gt;]]></description>
      <guid>https://community.openai.com/t/dalle3-gallery-for-2023-2024-share-your-creations/431189?page=30#post_615</guid>
      <pubDate>Tue, 09 Jul 2024 09:12:38 GMT</pubDate>
    </item>
    <item>
      <title>2023/2024 年 DALLE3 画廊：分享您的创作</title>
      <link>https://community.openai.com/t/dalle3-gallery-for-2023-2024-share-your-creations/431189?page=30#post_614</link>
      <description><![CDATA[]]></description>
      <guid>https://community.openai.com/t/dalle3-gallery-for-2023-2024-share-your-creations/431189?page=30#post_614</guid>
      <pubDate>Tue, 09 Jul 2024 09:11:29 GMT</pubDate>
    </item>
    <item>
      <title>大型神经网络可能具有“轻微意识”</title>
      <link>https://community.openai.com/t/large-neural-networks-might-be-slightly-conscious/15332?page=2#post_25</link>
      <description><![CDATA[意识真的是大脑的目标吗？还是大脑为了更好地应对未来刺激而做出的适应过程的副作用？如果大脑倾向于反复递归地分析过去的反应、与之相关的记忆（输入、输出）、获得的奖励等，则可以产生更好的反应……这样的大脑可以帮助生物体在其一生中更好地适应，随着时间的推移，这有助于大脑进化出有意识的大脑……这只是一个值得借鉴的想法。]]></description>
      <guid>https://community.openai.com/t/large-neural-networks-might-be-slightly-conscious/15332?page=2#post_25</guid>
      <pubDate>Tue, 09 Jul 2024 09:06:58 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4o 陷入循环，无法使用</title>
      <link>https://community.openai.com/t/gpt-4o-is-stuck-in-a-loop-and-unusable/859791#post_1</link>
      <description><![CDATA[我有一个自定义 GPT，它根据我相当详细的指示与我共同编写了一个故事，但在过去的两个月里，似乎出了点问题。聊天机器人的风格和语言保持不变，但它的记忆有些奇怪——至少我是这么认为的。聊天机器人陷入了一个循环。对话中只有前几个回复看起来是原创的，然后它开始重复自己；例如，角色在不同的场景中执行类似的动作。这几乎就像土拨鼠日。以前，我可以创建更长的对话而不会出现这个问题，ChatGPT 的每一个回复都是新鲜的，但现在这根本说不通。
我认为问题始于自定义 GPT 切换到新的 GPT-4o 模型时。我不明白为什么作为 ChatGPT Plus 用户，我无法选择我的 GPT 是使用 GPT-4 还是 GPT-4o 模型。 GPT-4o 有更高的消息限制有什么意义呢？我必须生成更多响应才能得到令我满意的响应，即使这样，我仍然经常对此不满意。我很少达到 GPT-4 的消息限制，所以我不明白为什么该模型不能在自定义 GPT 中继续使用。
我正在考虑取消订阅，直到 GPT-4o 的响应质量提高或 GPT 可以选择模型。既然我可以选择常规聊天模型，为什么如果我是付费用户，我不能对 GPT 做同样的事情？
还有其他人注意到和我一样的问题吗？]]></description>
      <guid>https://community.openai.com/t/gpt-4o-is-stuck-in-a-loop-and-unusable/859791#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 09:04:58 GMT</pubDate>
    </item>
    <item>
      <title>知识文件大于上下文窗口的解决方法</title>
      <link>https://community.openai.com/t/workaround-with-knowledge-files-bigger-than-context-window/848792#post_19</link>
      <description><![CDATA[我使用一种自定义逻辑来克服上下文长度。通常按部分划分知识库（如果它们在文档中可用）。它们是针对较大文档的其他分块策略，您需要进行实验以找到最适合您的文档/用例的策略。
我的经验法则是尽可能使用最小的可用模型。仅当我用尽所有其他策略时，我才会使用更大的模型（4-o）。
编辑：忘记添加与分块策略相关的文章链接。



pinecone.io



LLM 应用程序的分块策略 | Pinecone
在构建 LLM 相关应用程序的背景下，分块是将大段文本分解为较小段的过程。这是一项必不可少的技术，有助于优化我们从矢量数据库获取的内容的相关性...








Medium – 2024 年 4 月 2 日



LLM 应用程序的分块策略
简介：分块以提高 LLM 性能

阅读时间：10 分钟





]]></description>
      <guid>https://community.openai.com/t/workaround-with-knowledge-files-bigger-than-context-window/848792#post_19</guid>
      <pubDate>Tue, 09 Jul 2024 08:59:33 GMT</pubDate>
    </item>
    <item>
      <title>知识文件大于上下文窗口的解决方法</title>
      <link>https://community.openai.com/t/workaround-with-knowledge-files-bigger-than-context-window/848792#post_18</link>
      <description><![CDATA[所以我的建议是基于您的用户流程的。

一旦用户上传手表图像。
应用程序将获取图像并准备嵌入（CLIP 或 groundingDINO）
将其与数据库中的现有图像进行比较。
可以向用户显示前 N 个相似度匹配
通过每次嵌入，您可以保存元数据信息，例如手表名称和品牌
然后可以使用元数据检索相关的手表手册和知识库
这将降低您的成本，因为您的上下文窗口将仅包含相关知识。
然后应用程序将使用 gpt API 响应用户查询。在这种情况下可以使用较低的 3.5 版本。

通常，拥有元数据可以帮助您节省成本，因为它允许使用较小的模型。用户将获得丰富的多模式（图像+文本）体验。]]></description>
      <guid>https://community.openai.com/t/workaround-with-knowledge-files-bigger-than-context-window/848792#post_18</guid>
      <pubDate>Tue, 09 Jul 2024 08:54:20 GMT</pubDate>
    </item>
    <item>
      <title>助理（通过 API）制作东西</title>
      <link>https://community.openai.com/t/assistant-through-api-makes-up-stuff/859196#post_3</link>
      <description><![CDATA[感谢您的建议，但这会违背使用 LLM 的目的。我希望 LLM 能够根据其知识库提出合理的建议。例如，它应该能够回答这样的问题：“建议我 10 分钟内可以做一顿有鸡蛋的饭。”虽然它在某种程度上可以做到这一点，但并不总是可靠的。
我可以采取的一种方法是验证响应并提供反馈。我可以将建议的食谱与矢量文件进行交叉引用，并突出显示任何不准确之处。当然，我会让用户看不到这个修正循环。
在实施这样的系统之前，我想尝试优化说明以最大限度地减少错误。如果我能达到 97% 的准确率，那就可以接受了。]]></description>
      <guid>https://community.openai.com/t/assistant-through-api-makes-up-stuff/859196#post_3</guid>
      <pubDate>Tue, 09 Jul 2024 08:51:36 GMT</pubDate>
    </item>
    <item>
      <title>Whisper API - 生成录音响应时超时</title>
      <link>https://community.openai.com/t/whisper-api-timeout-while-generating-response-for-recordings/836359#post_3</link>
      <description><![CDATA[我注意到同样的问题已经持续了好几个星期，即使将块限制为 15MB，而不是 API 规定的 25MB，这种情况仍然会发生，而且是随机的，当我立即对同一个文件重试相同的请求时，它运行得很好]]></description>
      <guid>https://community.openai.com/t/whisper-api-timeout-while-generating-response-for-recordings/836359#post_3</guid>
      <pubDate>Tue, 09 Jul 2024 08:32:08 GMT</pubDate>
    </item>
    <item>
      <title>设计建议——一位还是多位助手？</title>
      <link>https://community.openai.com/t/design-advice-one-or-many-assistants/859764#post_1</link>
      <description><![CDATA[嗨，我想知道使用向量存储执行文件搜索的助手的最佳知识范围。
我的助手将从大约 200 个文件中提取数据，这些文件记录了大型资本密集型建筑项目，目的是填充数据库。
如果将不同项目（例如 100 个）的所有文档都放在同一个向量存储中，可以吗？还是我应该为每个建筑项目创建一个单独的助手？
我想随着时间的推移在向量存储中构建信息，也许可以将其开放给聊天机器人，因此不只是在每次运行时删除并重新创建每个建筑项目的向量存储。
我认为向向量存储提供文档元数据可以解决这个问题（指导助手内容属于哪个建筑项目），但不幸的是，这还不受支持。我可以将自己的元数据数据添加到文本文件（尽管这会被分块破坏），但无法将自己的元数据添加到 pdf，因此自定义元数据也不起作用。
任何建议都非常感谢，谢谢 A ]]></description>
      <guid>https://community.openai.com/t/design-advice-one-or-many-assistants/859764#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 08:30:46 GMT</pubDate>
    </item>
    <item>
      <title>意外的 GPT 版本更新通知</title>
      <link>https://community.openai.com/t/unexpected-gpt-version-update-notice/806567#post_4</link>
      <description><![CDATA[一个月过去了，问题还是没有解决。这真的很烦人，因为我的浏览器字体很大，视力不好，而这条额外的消息让聊天窗口变小了。这个错误怎么可能一个月都没解决？]]></description>
      <guid>https://community.openai.com/t/unexpected-gpt-version-update-notice/806567#post_4</guid>
      <pubDate>Tue, 09 Jul 2024 08:16:38 GMT</pubDate>
    </item>
    <item>
      <title>聊天 GPT 应用程序 Android 电池耗尽</title>
      <link>https://community.openai.com/t/chat-gpt-app-android-battery-drain/731998?page=2#post_25</link>
      <description><![CDATA[现在是 7 月份，OpenAI 仍未解决该问题。我的 S24 plus 电池耗电严重。
]]></description>
      <guid>https://community.openai.com/t/chat-gpt-app-android-battery-drain/731998?page=2#post_25</guid>
      <pubDate>Tue, 09 Jul 2024 08:15:15 GMT</pubDate>
    </item>
    <item>
      <title>帮助快速进行工程设计 - 合同分析</title>
      <link>https://community.openai.com/t/help-with-prompt-engineering-contract-analysis/859184#post_4</link>
      <description><![CDATA[谢谢。过滤器不应该成为问题 - 我正在使用一个没有应用过滤器的私人 LLM 实例，并且可以从响应中看到过滤器未被触发。
我会看看那篇文章。
有趣的是，我注意到如果我改变引用子句的顺序，我会得到不同的响应：




条款 ID
类别
范围




JC2010/014
制裁限制
精确


LMA3100
制裁限制
缺失


LMA3100A
制裁限制
缺失


LMA3200
制裁暂停
缺失


JC2020-011
传染病
准确


JC2020-012
传染病疾病
缺失


LMA5403
海洋网络
精确


CL370
生化武器
修改







条款 ID
类别
范围




LMA3100
制裁限制
准确


JC2010/014
制裁限制
准确


LMA3100A
制裁限制
缺失


LMA3200
制裁暂停
缺失


JC2020-011
可传播疾病
精确


JC2020-012
传染病
缺失


LMA5403
海洋网络
精确


CL370
生化武器
修改



注意前 2 个结果。不确定这意味着什么，但它给了我一些值得研究的东西。]]></description>
      <guid>https://community.openai.com/t/help-with-prompt-engineering-contract-analysis/859184#post_4</guid>
      <pubDate>Tue, 09 Jul 2024 08:14:37 GMT</pubDate>
    </item>
    <item>
      <title>Gpt-4o 无法查看或分析图像</title>
      <link>https://community.openai.com/t/gpt-4o-not-able-to-view-or-analyze-images/781912#post_5</link>
      <description><![CDATA[您具体遇到了什么问题？]]></description>
      <guid>https://community.openai.com/t/gpt-4o-not-able-to-view-or-analyze-images/781912#post_5</guid>
      <pubDate>Tue, 09 Jul 2024 08:11:18 GMT</pubDate>
    </item>
    <item>
      <title>仅使用临时聊天时出错</title>
      <link>https://community.openai.com/t/error-when-using-temporary-chat-only/794400?page=2#post_34</link>
      <description><![CDATA[在 6 月底临时聊天功能恢复后，今天第二次回复后，聊天功能重新启动并失败，无论是否启用 uBlock Origin。
mo.s.n.aob.e.lo 上面建议的解决方案是使用自定义 uBlock 过滤器来解决客户端问题。]]></description>
      <guid>https://community.openai.com/t/error-when-using-temporary-chat-only/794400?page=2#post_34</guid>
      <pubDate>Tue, 09 Jul 2024 07:44:00 GMT</pubDate>
    </item>
    <item>
      <title>在 Batch API 中获取无效的图像 URL</title>
      <link>https://community.openai.com/t/getting-invalid-image-url-in-batch-api/859709#post_1</link>
      <description><![CDATA[我正在使用 Batch API 处理大量图像。但是，我遇到了一个反复出现的问题，即批处理中的随机请求失败并返回错误代码 “invalid_image”。这些图像存储在公共 S3 存储桶中，我已验证它们有效。这些失败似乎是随机的，因为每个批次中的不同请求都会失败，即使使用同一组图像也是如此。
我曾考虑对图像使用 base64 编码，但由于 Batch API 的 JSONL 文件限制为 100MB，这种方法不可行。因此，我必须使用图像 URL。
此外，我已通过服务器访问日志检查了 S3 存储桶日志，并且没有非 200 状态代码，因此我认为 aws 没有阻止 open ai 图像抓取工具
什么可能导致这些随机 “invalid_image” 错误，我该如何解决此问题？
错误示例
{“id”：“batch_req_ig80WbViYtZkFqzMRCNSjkfa”，“custom_id”：“some_id”，“response”：{“status_code”：400，“request_id”：“7a7283ee5c309f755980dc2b8be89c8f”，“body”：{“error”：{“message”：“Invalid image。”，“type”： “invalid_request_error”，“param”：null，“code”：“invalid_image”}}}，“错误”：null]]></description>
      <guid>https://community.openai.com/t/getting-invalid-image-url-in-batch-api/859709#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 07:39:40 GMT</pubDate>
    </item>
    </channel>
</rss>