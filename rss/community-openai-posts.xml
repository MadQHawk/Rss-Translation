<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Wed, 03 Jul 2024 12:36:28 GMT</lastBuildDate>
    <item>
      <title>OpenAI Playground 到底允许我们在助手部分使用多少 RAM？</title>
      <link>https://community.openai.com/t/exactly-how-much-ram-does-openai-playground-allow-us-to-use-in-the-assistant-section/852062#post_4</link>
      <description><![CDATA[
最大文件大小为 512 MB。每个文件包含的标记数不得超过 5,000,000 个（附加文件时自动计算）。
– 文档
]]></description>
      <guid>https://community.openai.com/t/exactly-how-much-ram-does-openai-playground-allow-us-to-use-in-the-assistant-section/852062#post_4</guid>
      <pubDate>Wed, 03 Jul 2024 12:36:08 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI Playground 到底允许我们在助手部分使用多少 RAM？</title>
      <link>https://community.openai.com/t/exactly-how-much-ram-does-openai-playground-allow-us-to-use-in-the-assistant-section/852062#post_3</link>
      <description><![CDATA[我正在使用助手的 API，该 API 会为我运行 Python 代码。我想用它分析一个 1GB 的 JSON 文件，但 Python 解释器中显示的可用 RAM 只有 1GB。当我尝试加载 JSON 文件时，助手会抛出错误。]]></description>
      <guid>https://community.openai.com/t/exactly-how-much-ram-does-openai-playground-allow-us-to-use-in-the-assistant-section/852062#post_3</guid>
      <pubDate>Wed, 03 Jul 2024 12:31:33 GMT</pubDate>
    </item>
    <item>
      <title>Gpt-4o 无法正确读取 pdf 文件中的多页内容</title>
      <link>https://community.openai.com/t/gpt-4o-can-t-read-multiple-pages-correctly-in-pdf-file/852226#post_1</link>
      <description><![CDATA[Gpt-4o 无法正确读取多页
我想从 pdf 文件中收集报告章节的所有标题，但只有在内容很少（大部分在单页内）时才有效。
当内容继续到下一页时，它不会读取其余内容。
我尝试了助手和嵌入方法，但它只读取了内容部分的单页。提示信息是否太笼统？还是我应该询问更详细的方式？ （以下代码是我尝试使用嵌入方法的，我使用了更简单和更流行的文本文件，因为我的工作中使用了原始文件，而且它不是英文的）
# code
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
import sys
import json
from IPython.display import显示

load_dotenv()

def show_json(obj):
display(json.loads(obj.model_dump_json()))

file_path = &quot;./ins/harry_potter_and_the_goblet_of_fire.pdf&quot;
loader = PyPDFLoader(file_path)
docs = loader.load()

print(&quot;########### docs 已成功加载 ###########&quot;)
print(len(docs))

llm = ChatOpenAI(model=&quot;gpt-4o&quot;)

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

retriever = vectorstore.as_retriever()

system_prompt=(
“您是问答任务的助手。”
“请使用以下检索到的上下文来回答问题。如果您不知道答案，请说您不知道。”
“。 &quot;
&quot;\n\n&quot;
&quot;{context}&quot;
)

prompt = ChatPromptTemplate.from_messages(
[
(&quot;system&quot;, system_prompt),
(&quot;human&quot;, &quot;{input}&quot;),
]
)

question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

result = rag_chain.invoke({&quot;input&quot;: &quot;告诉我书中目录部分的所有章节&quot;})

print(result[&quot;context&quot;])
print(result[&quot;answer&quot;])

sys.stdout = open(&#39;./result/sample_results.txt&#39;,&#39;w&#39;)
print(result)
print(&quot;################################################&quot;)
for rst in result[&quot;context&quot;]:
print(rst.page_content)
print()
print(result[&quot;answer&quot;])

# result[&quot;answer&quot;]
1. 黑魔标记 (第 117 页)
2. 魔法部大混乱 (第 145 页)
3. 霍格沃茨特快列车 (第 158 页)
4. 三强争霸赛 (第 171 页)
5. 疯眼汉穆迪 (第 193 页)
6. 不可饶恕咒 (第 209 页)
7. 布斯巴顿和德姆斯特朗 (第 228 页)
8. 火焰杯 (第 248 页)
9. 四位勇士 (第 272 页)
10. 大脚怪归来 (第 509 页)
11. 克劳奇先生的疯狂 (第 535 页)
12. 梦境 (第564)
13. 冥想盆（第 581 页）
14. 第三个任务（第 605 页）
15. 血肉与骨头（第 636 页）
16. 食死徒（第 644 页）
17. 先验咒语（第 659 页）
18. 吐真剂（第 670 页）
19. 分道扬镳（第 692 页）
20. 开始（第 716 页）
21. 称量魔杖（第 228 页）
22. 匈牙利树蜂（第 313 页）
23. 第一个任务（第 337 页）
24. 家养小精灵解放阵线（第 363 页）
25. 意外任务（第 385 页）
26. 圣诞舞会（第 403 页）
27. 丽塔斯基特的勺子（第 433 页）
28. 鸡蛋和眼睛（第 458 页）
29. 第二项任务（第 479 页）
]]></description>
      <guid>https://community.openai.com/t/gpt-4o-can-t-read-multiple-pages-correctly-in-pdf-file/852226#post_1</guid>
      <pubDate>Wed, 03 Jul 2024 12:29:20 GMT</pubDate>
    </item>
    <item>
      <title>在 Batch API 中设置温度值</title>
      <link>https://community.openai.com/t/setting-temperature-value-in-batch-api/852217#post_2</link>
      <description><![CDATA[欢迎加入社区！
当然，您可以像在 API 调用中通常包含参数一样指定温度，即，只需在您的案例中在 max_token 参数之前或之后添加“温度”即可。
温度值本身完全取决于您的需求。]]></description>
      <guid>https://community.openai.com/t/setting-temperature-value-in-batch-api/852217#post_2</guid>
      <pubDate>Wed, 03 Jul 2024 12:25:17 GMT</pubDate>
    </item>
    <item>
      <title>将 CSV 或 .py 文件直接传递给聊天完成模型</title>
      <link>https://community.openai.com/t/passing-csv-or-py-files-directly-to-chat-completion-models/852047#post_2</link>
      <description><![CDATA[欢迎 @aadityaporwal234，
截至目前，您无法直接将文件发送到聊天完成端点。但是，您可以从这些文件中发送模型回答查询所需的相关内容。
使用函数调用，您可以让模型访问系统上的文件并让其检索相关内容。]]></description>
      <guid>https://community.openai.com/t/passing-csv-or-py-files-directly-to-chat-completion-models/852047#post_2</guid>
      <pubDate>Wed, 03 Jul 2024 12:24:32 GMT</pubDate>
    </item>
    <item>
      <title>在 Batch API 中设置温度值</title>
      <link>https://community.openai.com/t/setting-temperature-value-in-batch-api/852217#post_1</link>
      <description><![CDATA[大家好，
我正在为我的批处理 API 请求准备 .jsonl 文件。
在此过程中，我想知道是否有任何方法可以在每个请求中设置温度值。
以下是批处理 API 文档中的一个示例：
{“custom_id”：“request-1”，“method”：“POST”，“url”：“/v1/chat/completions”，“body”：{“model”：“gpt-3.5-turbo-0125”，“messages”：[{“role”：“system”，“content”：“你是一个乐于助人的助手。”}，{“role”：“user”，“content”：“Hello world！”}]，“max_tokens”：1000} } 
是否有办法在 .jsonl 文件中添加有关应为处理设置哪个温度值的信息我的请求？
提前感谢您的帮助！]]></description>
      <guid>https://community.openai.com/t/setting-temperature-value-in-batch-api/852217#post_1</guid>
      <pubDate>Wed, 03 Jul 2024 12:22:48 GMT</pubDate>
    </item>
    <item>
      <title>您已达到 GPT-4 的当前使用上限，请在下午 2:04 后重试</title>
      <link>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628?page=18#post_366</link>
      <description><![CDATA[我今天尝试使用它来优化一个角度服务 - 过程进行了四分之三，我已经用完了。对于任何“现实世界”的应用程序来说，这都不是一个实用的使用水平，我将取消订阅并返回免费版本，据我所知，免费版本似乎与付费版本基本相同。我本打算在工作日使用 chatGPT 作为副驾驶，但我几乎没有用上一个小时 - 不值 20 美元。我要去试试 Claude。]]></description>
      <guid>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628?page=18#post_366</guid>
      <pubDate>Wed, 03 Jul 2024 12:21:58 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI Playground 到底允许我们在助手部分使用多少 RAM？</title>
      <link>https://community.openai.com/t/exactly-how-much-ram-does-openai-playground-allow-us-to-use-in-the-assistant-section/852062#post_2</link>
      <description><![CDATA[助手的检索和推理在 OpenAI 的基础设施上进行。因此，考虑到其数据中心的计算能力，内存耗尽的可能性很小。
建议等待流式传输完成，然后查看日志。]]></description>
      <guid>https://community.openai.com/t/exactly-how-much-ram-does-openai-playground-allow-us-to-use-in-the-assistant-section/852062#post_2</guid>
      <pubDate>Wed, 03 Jul 2024 12:20:24 GMT</pubDate>
    </item>
    <item>
      <title>批处理 API custom_id 不支持 UUID？</title>
      <link>https://community.openai.com/t/batch-api-custom-id-does-not-support-uuid/742152#post_8</link>
      <description><![CDATA[我刚刚遇到了类似的问题。
在发送大量批次之前，我发送了一个小批次（约 30 个请求），其中包含聊天完成，其 custom_id 模式为 {number}_{number}_{number} - 是的，带有下划线。使用小批次，它工作得很好。
由于一切正常，我发送了一个大批次（约 25k 个请求），由于计费限制，我不得不取消 - 它停止在 7k。
对于此批次，所有 custom_id 均为空 - 即使是那些与测试批次的请求匹配的。响应都是有效的，就像我请求的那样，但我现在无法将它们与输入匹配。
我不知道这是由于取消还是这取决于其他原因。如果有人有见解，那就太好了]]></description>
      <guid>https://community.openai.com/t/batch-api-custom-id-does-not-support-uuid/742152#post_8</guid>
      <pubDate>Wed, 03 Jul 2024 12:07:25 GMT</pubDate>
    </item>
    <item>
      <title>公开请求 NSFW 支持：使用案例 + 举手支持！</title>
      <link>https://community.openai.com/t/open-plea-for-nsfw-support-use-case-raise-your-hand-to-support/850872#post_14</link>
      <description><![CDATA[这本该是个秘密。。•]]></description>
      <guid>https://community.openai.com/t/open-plea-for-nsfw-support-use-case-raise-your-hand-to-support/850872#post_14</guid>
      <pubDate>Wed, 03 Jul 2024 12:06:06 GMT</pubDate>
    </item>
    <item>
      <title>聊天完成 API - 缺少 max_tokens 默认值</title>
      <link>https://community.openai.com/t/chat-completions-api-max-tokens-default-value-is-missing/852146#post_2</link>
      <description><![CDATA[很有趣。感谢 @dilshat 的反馈。
根据之前的文档，在聊天完成端点上，默认情况下，max_tokens 从模型的上下文长度中获取可用的 token 上下文长度，最大值为 4096，据我所知。这对于视觉模型来说有所不同，默认情况下，视觉模型将 max_tokens 设置为 256 个 token。]]></description>
      <guid>https://community.openai.com/t/chat-completions-api-max-tokens-default-value-is-missing/852146#post_2</guid>
      <pubDate>Wed, 03 Jul 2024 12:05:14 GMT</pubDate>
    </item>
    <item>
      <title>公开请求 NSFW 支持：使用案例 + 举手支持！</title>
      <link>https://community.openai.com/t/open-plea-for-nsfw-support-use-case-raise-your-hand-to-support/850872#post_13</link>
      <description><![CDATA[嗯，这对他们的生意来说很棒。让那些上瘾，成为在家看任何他们想看的节目的奴隶。
另一方面，那些有不同计划的人可能会拓展他们的思维，在生活中取得更好的成就。
.•.]]></description>
      <guid>https://community.openai.com/t/open-plea-for-nsfw-support-use-case-raise-your-hand-to-support/850872#post_13</guid>
      <pubDate>Wed, 03 Jul 2024 12:00:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 OpenAI 时，从 Pinecone 检索不同语言的答案的最佳实践是什么？</title>
      <link>https://community.openai.com/t/what-are-the-best-practices-for-retrieving-answers-in-different-languages-from-pinecone-when-using-openai/852177#post_1</link>
      <description><![CDATA[我目前正在利用 Pinecone 和 OpenAI 构建检索增强生成 (RAG) 设置。我的目标是将数据以多种语言存储在 Pinecone 中，并配置 OpenAI 以处理不同语言的问题。存储在 Pinecone 中的答案可能与查询使用的语言不同。此设置旨在支持多语言数据检索和响应生成，确保跨各种语言的无缝交互。]]></description>
      <guid>https://community.openai.com/t/what-are-the-best-practices-for-retrieving-answers-in-different-languages-from-pinecone-when-using-openai/852177#post_1</guid>
      <pubDate>Wed, 03 Jul 2024 11:37:45 GMT</pubDate>
    </item>
    <item>
      <title>人工验证错误，每次提示时它总是要求进行人工验证测试</title>
      <link>https://community.openai.com/t/human-verification-bug-it-always-ask-for-human-verification-test-for-every-prompt/852157#post_1</link>
      <description><![CDATA[有人能告诉我该怎么做吗？如果我在笔记本电脑上使用 chatgpt，它总是需要验证我是否是人类。但是，当我在手机上使用它时，不需要验证。最近有人遇到同样的问题吗？
]]></description>
      <guid>https://community.openai.com/t/human-verification-bug-it-always-ask-for-human-verification-test-for-every-prompt/852157#post_1</guid>
      <pubDate>Wed, 03 Jul 2024 11:23:48 GMT</pubDate>
    </item>
    <item>
      <title>你们是否也遇到过同样的问题？</title>
      <link>https://community.openai.com/t/did-you-guys-struggle-with-the-same-problem/852150#post_1</link>
      <description><![CDATA[作为一名热衷于日语学习的人，我在中级水平上面临的最大挑战之一就是练习课本上的词汇。我经常在网上搜索，但很难找到使用我刚学过的单词的文本。我只有课本上提供的示例短语和听力练习，这让我很沮丧，因为我渴望学习更多，但找不到资源。
我正在考虑开发一个平台，用户可以在其中创建抽认卡并使用他们正在学习的词汇生成引人入胜的短篇故事、真实的新闻文章，以及可能的听力练习。你对这个想法有什么看法？你会使用这样的应用程序吗？]]></description>
      <guid>https://community.openai.com/t/did-you-guys-struggle-with-the-same-problem/852150#post_1</guid>
      <pubDate>Wed, 03 Jul 2024 11:13:00 GMT</pubDate>
    </item>
    </channel>
</rss>