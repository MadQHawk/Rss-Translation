<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 29 Apr 2024 03:20:55 GMT</lastBuildDate>
    <item>
      <title>助理和模特定价</title>
      <link>https://community.openai.com/t/assistants-and-model-pricing/730531#post_2</link>
      <description><![CDATA[我和你在同一条船上。对我来说，GPT 4 已经准备好迎接黄金时段了，因为它处理对话、遵循指令并提供全方位的非凡用户体验。再加上调用外部 API 的功能改变了游戏规则。现在根本就没有什么可以接近的。我什至不会在 3.5 中推出我的 SAAS，因为它提供的体验比我想要提供的要少得多。我目前处理昂贵定价的方式是将其作为“优质服务”向我最好的客户推销，你们有最聪明的人工智能技术吗？那些认识到价值和生产力的人无疑会为此付出代价。我的客户从复杂的 300 页 PDF 中生成信件，通常需要几个小时才能完成，而现在只需一分钟即可完成。总而言之，当你考虑到这一点时，情况似乎并没有那么糟糕。我只是在边缘放置了很多填充来覆盖自己。
对于那些想要花 5 美元购买 SAAS 并获得此类技术的人来说，这个定价会让人望而却步。无论如何，我不确定这就是我想要的市场。
我坚持并继续我的开发，因为随着新型号的推出，它无疑会变得更便宜、更好，然后我就准备好了。]]></description>
      <guid>https://community.openai.com/t/assistants-and-model-pricing/730531#post_2</guid>
      <pubDate>Mon, 29 Apr 2024 03:10:07 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 在仅处理 100-150 个测试结果表时非常懒惰</title>
      <link>https://community.openai.com/t/gpt-4-extremely-lazy-while-working-with-just-100-150-test-results-tables/730792#post_1</link>
      <description><![CDATA[无论我向帐户添加什么自定义指令，无论我为特定聊天创建什么提示，GPT 都会一遍又一遍地忽略大量数据并直接懒惰！
它的令牌限制没什么，但我不明白为什么它在处理数据表时如此懒惰？]]></description>
      <guid>https://community.openai.com/t/gpt-4-extremely-lazy-while-working-with-just-100-150-test-results-tables/730792#post_1</guid>
      <pubDate>Mon, 29 Apr 2024 02:45:15 GMT</pubDate>
    </item>
    <item>
      <title>GPT4。 PDF 到 CSV 的转换以及翻译。循环错误</title>
      <link>https://community.openai.com/t/gpt4-pdf-to-csv-conversion-with-translation-looping-errors/729745#post_3</link>
      <description><![CDATA[在与 GPT-4 进行了数小时的战斗并花费了无数的输出代币（是的 OpenAI，您应该有兴趣跟踪更好的不断尝试，无限循环的分析失败），这是解决此问题的提示。
整个想法是消除代码解释器并使其成为简单的文本表，然后将其转换为 CSV。像魅力一样工作。
&lt;块引用&gt;
鉴于以下数据和测试结果，请将其格式化为清晰且结构化的纯文本格式表格。
]]></description>
      <guid>https://community.openai.com/t/gpt4-pdf-to-csv-conversion-with-translation-looping-errors/729745#post_3</guid>
      <pubDate>Mon, 29 Apr 2024 02:16:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 gpt-4 API 对文档进行语义分块</title>
      <link>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=3#post_41</link>
      <description><![CDATA[如果目标是语义分块，使用现有的任何技术，那么还有其他可能的方法，而且这些方法更便宜、更清晰。
我们使用布局解析模型来识别段落/子段落标题。 OCR 是管道的一部分 - 我们也得到扫描的文档。这些模型经过微调以识别这些标头。简单的代码查找两个标题之间的文本作为段落/子段落的“值”。元数据包括自动编号部分、行以及文档内编号（如果找到）。页码也是如此。
无论如何，我们有一个内部文档提取 IDP 工具，所以这是一个分支。它几乎适用于任何基于 para 的文档布局。]]></description>
      <guid>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=3#post_41</guid>
      <pubDate>Mon, 29 Apr 2024 01:56:40 GMT</pubDate>
    </item>
    </channel>
</rss>