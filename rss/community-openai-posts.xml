<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 06 May 2024 15:19:53 GMT</lastBuildDate>
    <item>
      <title>带嵌入的时间/线性编码？</title>
      <link>https://community.openai.com/t/temporal-linear-coding-with-embeddings/735546#post_7</link>
      <description><![CDATA[


 curt.kennedy:
&lt;块引用&gt;
您是否考虑过仅对嵌入添加时间戳，作为附加元数据字段？
您可以使用 RRF 之类的工具将其混合到检索中，将时间和相关性混合到总体排名中。


确实。不过目前我还不是 RFF 的粉丝，因为它对我来说还没有任何直观意义。



饮食：
&lt;块引用&gt;
cos(delta_theta)


代表您的建议。它是应用于时间戳增量的过滤器。但高斯函数可能比 cos 更有意义。我们将其应用于余弦相似度。

如果 c 无限大，我们将获得规则的（360°，0s）余弦相似度，并且随着它的缩小，我们会及时增加焦距，直到我们获得最后嵌入的微距镜头。
根据我们提出的问题（昨天、一小时前、两页前、去年、最后一章），我们可以有一些预先计算的 C 和 B，但我想知道这是否也可以动态完成。 
如果您使用自适应最近邻算法，您可以使用有关邻域的信息来通知 C. 也许。



 curt.kennedy:
&lt;块引用&gt;
桶





 curt.kennedy:
&lt;块引用&gt;
量化


我不喜欢在数据级别量化连续的东西，因为如果这样做，就会引入任意范围约束
当然，如果您只需要一个快速而肮脏的解决方案，并且您知道您的问题始终是关于您是昨天还是今天做的，那么这绝对是有意义的。]]></description>
      <guid>https://community.openai.com/t/temporal-linear-coding-with-embeddings/735546#post_7</guid>
      <pubDate>Mon, 06 May 2024 15:15:51 GMT</pubDate>
    </item>
    <item>
      <title>文本到视频生成 AI 模型</title>
      <link>https://community.openai.com/t/text-to-video-gen-ai-models/737811#post_1</link>
      <description><![CDATA[嗨，任何人都可以帮助开发开源文本到视频模型，该模型可以生成 10-15 秒的视频，并可以进一步微调以提高准确性。目前我已经探索了所有可用于拥抱脸部的开源模型，即使有详细的提示，它们也无法生成准确的视频。]]></description>
      <guid>https://community.openai.com/t/text-to-video-gen-ai-models/737811#post_1</guid>
      <pubDate>Mon, 06 May 2024 15:02:33 GMT</pubDate>
    </item>
    <item>
      <title>对 chatgpt 的反馈，添加新选项</title>
      <link>https://community.openai.com/t/feedback-for-chatgpt-adding-a-new-option/737810#post_1</link>
      <description><![CDATA[添加一个选项，允许您从聊天机器人或您的新旧对话中删除回复]]></description>
      <guid>https://community.openai.com/t/feedback-for-chatgpt-adding-a-new-option/737810#post_1</guid>
      <pubDate>Mon, 06 May 2024 15:02:14 GMT</pubDate>
    </item>
    <item>
      <title>助手 API 工具是否支持 `**kwargs`？如何在 JSON 模式中记录它们？</title>
      <link>https://community.openai.com/t/do-the-assistant-api-tools-support-kwargs-how-to-document-them-in-the-json-schema/737808#post_1</link>
      <description><![CDATA[您好，我有一个抽象函数，它有一些必需的参数，但也可能有多个附加参数，这些参数根据用例通过 **kwargs 传递。我希望我的 Assistant API 使用此函数作为工具，它工作正常，但仅使用必需的参数，它总是忽略 **kwargs。 Assistant API工具支持这个吗？我在 properties 下描述了我当前的 JSON 架构，如下所示：
 &quot;additionalParameters&quot;: {
          “类型”：“对象”，
          &quot;description&quot;: &quot;函数所需的附加参数（例如长度）&quot;,
          “附加属性”：true
      }

我找不到任何明确描述这一点的文档。请帮忙。]]></description>
      <guid>https://community.openai.com/t/do-the-assistant-api-tools-support-kwargs-how-to-document-them-in-the-json-schema/737808#post_1</guid>
      <pubDate>Mon, 06 May 2024 15:00:16 GMT</pubDate>
    </item>
    <item>
      <title>支持图像输入的助手 API</title>
      <link>https://community.openai.com/t/assistants-api-supporting-image-inputs/737807#post_1</link>
      <description><![CDATA[是否有推出此功能的日期，以便我们可以测试助手 API 上的图像输入？这将有助于社区在将其投入生产之前进行测试。]]></description>
      <guid>https://community.openai.com/t/assistants-api-supporting-image-inputs/737807#post_1</guid>
      <pubDate>Mon, 06 May 2024 14:57:26 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 响应的延迟显示</title>
      <link>https://community.openai.com/t/delayed-display-of-chatgpt-responses/737794#post_1</link>
      <description><![CDATA[ChatGPT 最近开始等待其对提示的响应完全构建后再显示任何内容。有没有办法恢复到以前的首选行为，即在制定响应时实时显示响应？]]></description>
      <guid>https://community.openai.com/t/delayed-display-of-chatgpt-responses/737794#post_1</guid>
      <pubDate>Mon, 06 May 2024 14:48:30 GMT</pubDate>
    </item>
    </channel>
</rss>