<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Fri, 21 Jun 2024 03:22:45 GMT</lastBuildDate>
    <item>
      <title>ChatGPT 混合了语言或答案是错误的！</title>
      <link>https://community.openai.com/t/chatgpt-is-mixing-languages-or-answers-are-wrong/644339#post_7</link>
      <description><![CDATA[
我的电脑突然变成这样了，但是当我再次询问时它又恢复正常了]]></description>
      <guid>https://community.openai.com/t/chatgpt-is-mixing-languages-or-answers-are-wrong/644339#post_7</guid>
      <pubDate>Fri, 21 Jun 2024 03:12:18 GMT</pubDate>
    </item>
    <item>
      <title>缩写是减少标记的解决方案吗？</title>
      <link>https://community.openai.com/t/are-abbreviations-a-solution-to-minimize-tokens/832074#post_2</link>
      <description><![CDATA[这不是一个长期的解决方案。

不确定对响应质量的影响。
它不太可能产生如您所希望的那么大的影响。

如果您对成本如此敏感，那么更好的解决方案是，

简化您的流程，并积极地最大化您与模型之间消息的信息密度。
使用更便宜的模型作为用户和更昂贵模型之间的转换层，通过压缩消息使其信息密度更高。
只需使用更便宜的模型。
]]></description>
      <guid>https://community.openai.com/t/are-abbreviations-a-solution-to-minimize-tokens/832074#post_2</guid>
      <pubDate>Fri, 21 Jun 2024 03:04:18 GMT</pubDate>
    </item>
    <item>
      <title>在IIS中流式传输python / flask文本块</title>
      <link>https://community.openai.com/t/streaming-chunk-of-text-python-flask-in-iis/809454#post_3</link>
      <description><![CDATA[不，最后我不得不将解决方案移到 pythonanywhere.com 之外，因为我无法弄清楚。
缓冲 | PythonAnywhere 帮助
那里有一些信息可能也与 iis 问题有关，因为我必须这样做才能让它在 PythonAnywhere 上成功运行。但即使这样，我仍然无法让它工作。如果其他人也遇到过这种情况，我很想听听！]]></description>
      <guid>https://community.openai.com/t/streaming-chunk-of-text-python-flask-in-iis/809454#post_3</guid>
      <pubDate>Fri, 21 Jun 2024 02:51:31 GMT</pubDate>
    </item>
    <item>
      <title>全能，全能，哦光明的承诺，多模式的黎明，一盏明灯</title>
      <link>https://community.openai.com/t/omni-omni-oh-the-promise-bright-a-multimodal-dawn-a-beacon-of-light/829518#post_3</link>
      <description><![CDATA[链接没有接通吗？]]></description>
      <guid>https://community.openai.com/t/omni-omni-oh-the-promise-bright-a-multimodal-dawn-a-beacon-of-light/829518#post_3</guid>
      <pubDate>Fri, 21 Jun 2024 02:41:23 GMT</pubDate>
    </item>
    <item>
      <title>语义搜索 - langchain 中的最佳链</title>
      <link>https://community.openai.com/t/semantic-search-best-chain-in-langchain/832106#post_1</link>
      <description><![CDATA[大家好，
我在 RAG 中使用语义缓存时有两个疑问。使用 langchain + OpenAI

我可以将用户对话检索与语义缓存一起使用吗？
检索 QA 链是否最适合语义缓存。

提问的原因是我多次得到错误的答案。即使答案是错误的，答案也是从语义缓存中随机获取的。]]></description>
      <guid>https://community.openai.com/t/semantic-search-best-chain-in-langchain/832106#post_1</guid>
      <pubDate>Fri, 21 Jun 2024 02:40:38 GMT</pubDate>
    </item>
    <item>
      <title>Azure .NET OpenAPI 版本 2 有重大变更</title>
      <link>https://community.openai.com/t/azure-net-openapi-version-2-has-breaking-changes/831771#post_3</link>
      <description><![CDATA[谢谢，这解释了发生了什么。这听起来是个好消息。
有没有文档建议我们如何将代码移植到某个地方？
谢谢 - dave]]></description>
      <guid>https://community.openai.com/t/azure-net-openapi-version-2-has-breaking-changes/831771#post_3</guid>
      <pubDate>Fri, 21 Jun 2024 02:36:39 GMT</pubDate>
    </item>
    <item>
      <title>测验 GPT - 知识文件中的随机问题不起作用</title>
      <link>https://community.openai.com/t/quiz-gpt-randomized-questions-from-knowledge-files-do-not-work/831918#post_5</link>
      <description><![CDATA[GPT 模型无法执行随机操作。您最好通过操作或使用 Python 工具选择一个随机问题。
选择适合该工作的工具。]]></description>
      <guid>https://community.openai.com/t/quiz-gpt-randomized-questions-from-knowledge-files-do-not-work/831918#post_5</guid>
      <pubDate>Fri, 21 Jun 2024 02:35:58 GMT</pubDate>
    </item>
    <item>
      <title>在IIS中流式传输python / flask文本块</title>
      <link>https://community.openai.com/t/streaming-chunk-of-text-python-flask-in-iis/809454#post_2</link>
      <description><![CDATA[嗨，你找到解决方案了吗？我被同样的问题困扰着。]]></description>
      <guid>https://community.openai.com/t/streaming-chunk-of-text-python-flask-in-iis/809454#post_2</guid>
      <pubDate>Fri, 21 Jun 2024 02:27:57 GMT</pubDate>
    </item>
    <item>
      <title>大家好，我对 openAI 助手文件搜索工具的块大小和块重叠有疑问？</title>
      <link>https://community.openai.com/t/dear-all-i-have-the-questions-about-the-openai-assistant-chunk-size-and-chunk-overlap-of-file-search-tool/831342#post_6</link>
      <description><![CDATA[首先，澄清一些背景知识：上下文窗口长度是一个共享内存空间，用于加载提示和上下文输入的 AI，以及 AI 随后生成自己的语言。它以 AI 语言的编码标记来衡量。
max_tokens 是一个聊天完成参数，用于设置在 AI 被切断或截断之前您将从 AI 获得的响应的最大大小，finish_reason 报告为“长度”而不是“停止”。由于 OpenAI 的人为限制，新模型中该参数可以设置为的最大值为 4096（标记），但无论如何，由于训练，AI 很少会写入那么多，因此将其设置得更低可以减少 AI 疯狂写入循环废话时的费用。
AI 模型不知道如何设置此参数。输出响应的长度将由固有行为（缩短输出长度）和您执行的提示决定。
如果您未设置 max_tokens 参数，则最大响应是整个剩余上下文长度 - 或 4k 限制。如果您未设置它，则也没有专门用于形成响应的空间（或者如果您仅在输入上使用所有上下文，则会报告错误）。您可以将 15.75k 个令牌的输入发送到 gpt-3.5-turbo 的 16k，并且只剩下 250 个令牌用于响应。
在助手中，您几乎无法控制工具或输出输入的令牌 - 它针对最大费用进行了调整。现在可用的一个控件将在您已经为代理支付了过多的内部呼叫费用后简单地中止并产生错误。]]></description>
      <guid>https://community.openai.com/t/dear-all-i-have-the-questions-about-the-openai-assistant-chunk-size-and-chunk-overlap-of-file-search-tool/831342#post_6</guid>
      <pubDate>Fri, 21 Jun 2024 02:20:09 GMT</pubDate>
    </item>
    <item>
      <title>我的自定义 GPT 使用什么模型？</title>
      <link>https://community.openai.com/t/what-models-are-my-custom-gpts-using/776983#post_8</link>
      <description><![CDATA[不。GPT 使用 GPT-4o。]]></description>
      <guid>https://community.openai.com/t/what-models-are-my-custom-gpts-using/776983#post_8</guid>
      <pubDate>Fri, 21 Jun 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>缩写是减少标记的解决方案吗？</title>
      <link>https://community.openai.com/t/are-abbreviations-a-solution-to-minimize-tokens/832074#post_1</link>
      <description><![CDATA[我正在尝试寻找有效的方法来最小化上下文阶段中的标记数量，以最大化结果并能够发送更多参数，并享受这意味着的所有好处。关于这一点，我想到了一个想法，可能已经在某些帖子中提到过了，但老实说，我在论坛中找不到它。它是将单词缩写为最简单的形式，据我所知，GPT-3.5 和 GPT-4.0 都能理解缩写文本，即使输入是缩写的，也可以返回没有缩写的文本。所以我首先开始测试文本可以缩写多少。使用 Node 中的 GPT-3 编码器工具（这里还有一个非常有用的图形实现：https://platform.openai.com/tokenizer），这显然取决于具体的文本，但 token 节省了大约 20% 到 35%（我澄清说是我提供的文本），这似乎很重要，因为这严格反映在其使用中，尤其是在上下文文件中。
然后对于测试，我使用了主文件中的这些分层和模式化文件。例如，主文件：管理中的人力资源.pdf。使用 GPT-4.0，我将该文件分层并模式化为最相关的，然后我使用 GPT-4.0 总结了每个模式化。之后，我使用 GPT-4.0 缩写了每个摘要。完成所有这些操作后，我为每个文件分配一个标题，该标题引用了文件中涉及的主题，例如：
1- 绩效管理、Robbins 和 Coulter、Idalberto Chiavenato、绩效评估、评估方法.txt
2- 人力资源管理.txt
3- 员工定位、培训类型、培训方法.txt
4- 人力资源规划流程、Robbins 和 Coulter、职位规范、招聘.txt
随后，我们向模型指示如下：“您是回答问题的专家教授，我们将为您提供一些文件，您必须从这些文件得出答案，这些文件不应包含缩写、参考资料和注释。” 这样，我们就指明了如何处理这些文件。
这个方案给了我非常好的结果，尽管我仍在测试它以尝试获得尽可能准确的结果。但我想提出它，因为这种利用模型理解缩写的能力并利用它来减少标记的方法对我来说很有趣。
我是这个世界的新手，我非常感谢您的评论，因为肯定有更好或更抽象的方法来做到这一点。提前非常感谢！]]></description>
      <guid>https://community.openai.com/t/are-abbreviations-a-solution-to-minimize-tokens/832074#post_1</guid>
      <pubDate>Fri, 21 Jun 2024 02:03:17 GMT</pubDate>
    </item>
    <item>
      <title>IaS 的自我修正代码代理</title>
      <link>https://community.openai.com/t/self-correcting-code-agent-for-ias/832059#post_1</link>
      <description><![CDATA[如果我想为基础设施即代码制作一个自我修正的代码代理，我想请教一下使用 RAG 还是助手 API 是更好的解决方案
我计划使用一些状态文件作为 AI 的知识库。我曾尝试使用 Completions API 构建一个自我修正的代码代理，但如果我想基于一些现有的基础设施，输出似​​乎不太好
我对 LLM 真的很陌生，请问是否可行，有什么建议吗？
谢谢]]></description>
      <guid>https://community.openai.com/t/self-correcting-code-agent-for-ias/832059#post_1</guid>
      <pubDate>Fri, 21 Jun 2024 01:48:34 GMT</pubDate>
    </item>
    <item>
      <title>图片搜索总是出错，无法处理</title>
      <link>https://community.openai.com/t/image-search-always-encounters-errors-and-cannot-be-processed/832046#post_1</link>
      <description><![CDATA[每当我发送照片或拍摄新照片以询问相关问题时，chatgpt4o 系统总是会遇到错误并返回“嗯……似乎出了点问题。”
]]></description>
      <guid>https://community.openai.com/t/image-search-always-encounters-errors-and-cannot-be-processed/832046#post_1</guid>
      <pubDate>Fri, 21 Jun 2024 01:30:00 GMT</pubDate>
    </item>
    <item>
      <title>运行失败，抱歉，出现错误。发送图像时出错</title>
      <link>https://community.openai.com/t/run-failed-sorry-something-went-wrong-error-while-sending-an-image/775989#post_20</link>
      <description><![CDATA[我也一样，我使用的是 4o 模型]]></description>
      <guid>https://community.openai.com/t/run-failed-sorry-something-went-wrong-error-while-sending-an-image/775989#post_20</guid>
      <pubDate>Fri, 21 Jun 2024 01:27:50 GMT</pubDate>
    </item>
    <item>
      <title>运行失败，抱歉，出现错误。发送图像时出错</title>
      <link>https://community.openai.com/t/run-failed-sorry-something-went-wrong-error-while-sending-an-image/775989#post_19</link>
      <description><![CDATA[是的，我也遇到了同样的问题。]]></description>
      <guid>https://community.openai.com/t/run-failed-sorry-something-went-wrong-error-while-sending-an-image/775989#post_19</guid>
      <pubDate>Fri, 21 Jun 2024 01:27:31 GMT</pubDate>
    </item>
    </channel>
</rss>