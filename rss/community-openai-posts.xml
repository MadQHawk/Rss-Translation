<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 13 Apr 2024 15:14:34 GMT</lastBuildDate>
    <item>
      <title>GPT-4-Turbo-2024-04-09 以整数形式返回答案是否正常？</title>
      <link>https://community.openai.com/t/is-it-normal-for-gpt-4-turbo-2024-04-09-to-return-answer-in-integer/716667#post_4</link>
      <description><![CDATA[这就是问题所在：我使用 df[&#39;answer&#39;] = df[&#39;answer&#39;].replace(&#39; &#39;, np.nan) 来消除任何空格，但事实证明如果列看起来只填充了类似整数的字符串，pandas 会自动将整个列转换为整数。我必须在末尾添加 .astype(str) 来防止这种情况发生。问题并不在于 OpenAI。]]></description>
      <guid>https://community.openai.com/t/is-it-normal-for-gpt-4-turbo-2024-04-09-to-return-answer-in-integer/716667#post_4</guid>
      <pubDate>Sat, 13 Apr 2024 15:07:23 GMT</pubDate>
    </item>
    <item>
      <title>1536长度小与大</title>
      <link>https://community.openai.com/t/1536-length-small-vs-large/618069#post_12</link>
      <description><![CDATA[谢谢你。由于 openai 的文档，我也有同样的想法。我正在为一些数据库更改做好准备，因为我创建了一堆具有 1536 维的对象。希望过渡能够顺利进行。]]></description>
      <guid>https://community.openai.com/t/1536-length-small-vs-large/618069#post_12</guid>
      <pubDate>Sat, 13 Apr 2024 15:06:16 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4-Turbo-2024-04-09 以整数形式返回答案是否正常？</title>
      <link>https://community.openai.com/t/is-it-normal-for-gpt-4-turbo-2024-04-09-to-return-answer-in-integer/716667#post_3</link>
      <description><![CDATA[谢谢你让我放心！我刚刚检查过，答案以字符串形式出现。现在我必须弄清楚我哪一部分做错了！]]></description>
      <guid>https://community.openai.com/t/is-it-normal-for-gpt-4-turbo-2024-04-09-to-return-answer-in-integer/716667#post_3</guid>
      <pubDate>Sat, 13 Apr 2024 14:59:44 GMT</pubDate>
    </item>
    <item>
      <title>关于 GPT-3.5-Turbo 与 Claude 3 Haiku 的思考</title>
      <link>https://community.openai.com/t/thoughts-on-gpt-3-5-turbo-vs-claude-3-haiku/716533#post_5</link>
      <description><![CDATA[gpt-3.5-turbo 曾经更好，仍然被维护对 gpt-3.5-turbo-0301 访问的 API 开发人员看到（尽管此快照，尤其是 -0613，从来都不是快照） ，受到持续变化的影响）。
在 Turbo 之前的几个月，就有完整的基于 GPT-3 Davinci 的 ChatGPT。据众多来源推测，与 GPT-3-davinci 相比，-turbo 的参数几乎大幅下降，如果您有数据可供训练，那么与它的竞争就更容易。
从最新模型的质量中可以清楚地看出，该 AI 系列的重点是以最低的推理成本为 ChatGPT 提供“免费”服务，而 API 只是 OpenAI 新专注于自己的聊天产品的副产品。&lt; /p&gt;]]></description>
      <guid>https://community.openai.com/t/thoughts-on-gpt-3-5-turbo-vs-claude-3-haiku/716533#post_5</guid>
      <pubDate>Sat, 13 Apr 2024 14:57:14 GMT</pubDate>
    </item>
    <item>
      <title>Gpt-4-turbo-2024-04-09 在 Playground 与 API 上的性能对比</title>
      <link>https://community.openai.com/t/gpt-4-turbo-2024-04-09-performance-on-playground-vs-api/716716#post_1</link>
      <description><![CDATA[使用 API 与 Playground 时的模型推理似乎始终不同
以前的 gpt4 型号似乎也有同样的问题，但这种情况并不常见，我可以将其视为幻觉
通过 API 使用 gpt-4-turbo-2024-04-09 会导致答案明显错误，并且幻觉无处不在（例如，识别提示中不存在的内容）
当我在操场上时，它不会出现同样的幻觉]]></description>
      <guid>https://community.openai.com/t/gpt-4-turbo-2024-04-09-performance-on-playground-vs-api/716716#post_1</guid>
      <pubDate>Sat, 13 Apr 2024 14:51:08 GMT</pubDate>
    </item>
    <item>
      <title>写整本书的技巧</title>
      <link>https://community.openai.com/t/technique-for-writing-entire-books/705519?page=2#post_27</link>
      <description><![CDATA[像“为初学者写一本关于 Python 的书”这样的提示也可能很快就会变得实用。并且无需人工干预即可完成该任务。所以问题不是“我可以填充允许的可用上下文窗口大小”，而是“让我们将所有相关信息放入上下文窗口中，以准确获得我们想要的输出”。]]></description>
      <guid>https://community.openai.com/t/technique-for-writing-entire-books/705519?page=2#post_27</guid>
      <pubDate>Sat, 13 Apr 2024 14:50:52 GMT</pubDate>
    </item>
    <item>
      <title>GPT - 知识提供 GPT 的最佳文件格式？</title>
      <link>https://community.openai.com/t/gpts-best-file-format-for-knowledge-to-feed-gpts/497368?page=3#post_44</link>
      <description><![CDATA[我在处理 Markdown 文件时遇到了困难，GPT 无法解释它们 (117 kb)。
转换为 HTML 后（“pandoc -i input.md -o output.html”），它起作用了。]]></description>
      <guid>https://community.openai.com/t/gpts-best-file-format-for-knowledge-to-feed-gpts/497368?page=3#post_44</guid>
      <pubDate>Sat, 13 Apr 2024 14:49:13 GMT</pubDate>
    </item>
    <item>
      <title>自定义 gpt 不起作用“不再支持插件。”</title>
      <link>https://community.openai.com/t/custom-gpts-dont-work-plugins-are-no-longer-supported/715688#post_9</link>
      <description><![CDATA[这对工作来说是一个大问题。这个问题什么时候能修复？]]></description>
      <guid>https://community.openai.com/t/custom-gpts-dont-work-plugins-are-no-longer-supported/715688#post_9</guid>
      <pubDate>Sat, 13 Apr 2024 14:42:44 GMT</pubDate>
    </item>
    <item>
      <title>您的 API 访问已暂时暂停</title>
      <link>https://community.openai.com/t/your-api-access-has-been-temporarily-suspended/715902#post_3</link>
      <description><![CDATA[@_j
这是一项可悲的政策。有同样的问题：+284 美元（我已在下次付款前 5 天使用了我的积分），我已发送全部金额，现在我必须再次支付 260 美元？ 544 美元。
@sotschiyinivan 我和你有同感。 OpenAI 的糟糕行为/政策。]]></description>
      <guid>https://community.openai.com/t/your-api-access-has-been-temporarily-suspended/715902#post_3</guid>
      <pubDate>Sat, 13 Apr 2024 14:34:56 GMT</pubDate>
    </item>
    <item>
      <title>关于 GPT-3.5-Turbo 与 Claude 3 Haiku 的思考</title>
      <link>https://community.openai.com/t/thoughts-on-gpt-3-5-turbo-vs-claude-3-haiku/716533#post_4</link>
      <description><![CDATA[我认为 GPT-3.5 的最大好处是能够对其进行微调，然后以合理的价格使用微调后的模型来准确地响应您想要的方式，例如用于支持机器人。如果Anthropic加入微调访问，暂时会完全取代GPT-3.5，速度都差不多。]]></description>
      <guid>https://community.openai.com/t/thoughts-on-gpt-3-5-turbo-vs-claude-3-haiku/716533#post_4</guid>
      <pubDate>Sat, 13 Apr 2024 14:33:12 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4-Turbo-2024-04-09 以整数形式返回答案是否正常？</title>
      <link>https://community.openai.com/t/is-it-normal-for-gpt-4-turbo-2024-04-09-to-return-answer-in-integer/716667#post_2</link>
      <description><![CDATA[这不正常。 API 响应采用 JSON 格式。
为了获得非常基本的表单，我使用 Python 请求库发送：
req = requests.post(&quot;https://api.openai.com/v1/chat/completions&quot;,
                  标题=标题，
                  json=json)

并收到回复：
&gt;&gt;&gt;req.content
b&#39;{\n &quot;id&quot;: &quot;chatcmpl-9DYcFTip6tFaFWxxxxx&quot;,\n &quot;对象&quot;: &quot;chat.completion&quot;,\n &quot;创建&quot;: 1713018399,\n &quot;型号&quot;: &quot;gpt-4-turbo -2024-04-09&quot;,\n &quot;选择&quot;: [\n {\n &quot;索引&quot;: 0,\n &quot;消息&quot;: {\n &quot;角色&quot;: &quot;助理&quot;,\n &quot;内容&quot;: &quot; 0&quot;\n },\n &quot;logprobs&quot;: null,\n &quot;finish_reason&quot;: &quot;停止&quot;\n }\n ],\n &quot;usage&quot;: {\n &quot;prompt_tokens&quot;: 29,\n &quot;completion_tokens&quot; : 1,\n &quot;total_tokens&quot;: 30\n },\n &quot;system_fingerprint&quot;: &quot;fp_76f018034d&quot;\n}\n&#39;
以字节格式，您可以看到收到的每个字符。
我请求的单个令牌 0（以及未收到的停止令牌）不应该是 &quot;content&quot;: &quot;0&quot; 以外的内容 - 一个字符串，用引号引起来。这将需要端点代码对 AI 输出进行一些新的解释方法（特别是除了我刚刚测试的 0 或 999 之外的其他方法）。
我建议您记录原始 API 响应，看看是否是您的代码太“智能”。]]></description>
      <guid>https://community.openai.com/t/is-it-normal-for-gpt-4-turbo-2024-04-09-to-return-answer-in-integer/716667#post_2</guid>
      <pubDate>Sat, 13 Apr 2024 14:28:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 gpt-4 API 对文档进行语义分块</title>
      <link>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689#post_18</link>
      <description><![CDATA[我理解我也在做的层次结构部分，我称之为父检索器方法。我不明白第一行和最后几行。仅通过第一行和最后几行如何理解问题的上下文。比其他方法更适合我的方法如下。
我将 PDF 转换为 Markdown，然后按标题分割（#、##、### ...）。我对每个标头进行分块，如果该块超过 300 个标记，我会进一步对其进行分块。对于每个块，我将该部分的全部内容存储在一个单独的元数据表中。
在匹配问题时，我将其与块嵌入进行匹配，但之后我检索块的部分内容并将其提供给LLM。]]></description>
      <guid>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689#post_18</guid>
      <pubDate>Sat, 13 Apr 2024 14:26:55 GMT</pubDate>
    </item>
    <item>
      <title>API自7月起暂停，不会从添加的账户信用中扣除</title>
      <link>https://community.openai.com/t/api-suspended-since-july-wont-deduct-from-added-account-credit/535944#post_8</link>
      <description><![CDATA[@nomuhyuna
打扰一下。这是您的解决方案吗？一些用户拥有不同级别的等级，并且花费了数千美元才能达到此目的。]]></description>
      <guid>https://community.openai.com/t/api-suspended-since-july-wont-deduct-from-added-account-credit/535944#post_8</guid>
      <pubDate>Sat, 13 Apr 2024 14:25:13 GMT</pubDate>
    </item>
    <item>
      <title>关于 GPT-3.5-Turbo 与 Claude 3 Haiku 的思考</title>
      <link>https://community.openai.com/t/thoughts-on-gpt-3-5-turbo-vs-claude-3-haiku/716533#post_3</link>
      <description><![CDATA[


 grandell1234：
&lt;块引用&gt;
这不是一个非常公平的比较； GPT-3.5 于 2022 年发布，而 Claude 3 Haiku 于 2024 年发布。


我同意，这正是我的观点。
OpenAI 一直致力于改进 GPT-4（然后是 GPT-4-Turbo），但至少到目前为止，似乎已经放弃了对更小/更快/更便宜的模型系列的实质性改进； Anthropic 抓住了这个机会。如果说有什么不同的话，那就是 GPT-3.5-Turbo 随着时间的推移变得越来越糟（至少根据 LLM 竞技场）。
&lt;块引用&gt;
我个人不太使用 GPT-3.5，但一个很大的好处是能够对 GPT-3.5 进行微调，这是 Claude 3 Haiku 无法做到的。

公平点。也许经过微调的 GPT-3.5 在这项任务上会比 Haiku 表现更好，这一点很有趣。这并不完全明显，因为俳句更聪明，并且可以廉价地包含大量上下文示例。]]></description>
      <guid>https://community.openai.com/t/thoughts-on-gpt-3-5-turbo-vs-claude-3-haiku/716533#post_3</guid>
      <pubDate>Sat, 13 Apr 2024 14:22:24 GMT</pubDate>
    </item>
    <item>
      <title>请求 ChatGPT 提示中的自动完成功能</title>
      <link>https://community.openai.com/t/request-for-auto-complete-feature-in-chatgpt-prompt/716697#post_1</link>
      <description><![CDATA[我是 ChatGPT 的普通用户，认为在提示中添加自动完成功能将大大增强用户体验。它可以简化交互、减少错误并使流程更加直观。我相信这一添加将对该平台带来宝贵的改进。
期待您的考虑。]]></description>
      <guid>https://community.openai.com/t/request-for-auto-complete-feature-in-chatgpt-prompt/716697#post_1</guid>
      <pubDate>Sat, 13 Apr 2024 14:15:31 GMT</pubDate>
    </item>
    </channel>
</rss>