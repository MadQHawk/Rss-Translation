<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 25 Apr 2024 18:22:54 GMT</lastBuildDate>
    <item>
      <title>Whisper 在较长的记录中遗漏了一些语音块</title>
      <link>https://community.openai.com/t/whisper-leaves-out-chunks-of-speech-in-longer-transcript/715999#post_4</link>
      <description><![CDATA[通过测试耳语的早期版本（例如 20230124），我注意到这些块并没有在记录中被遗漏。由于我们依赖于新版本的耳语的单词时间戳，有什么方法可以在新版本的耳语中获得同样宽松的行为吗？]]></description>
      <guid>https://community.openai.com/t/whisper-leaves-out-chunks-of-speech-in-longer-transcript/715999#post_4</guid>
      <pubDate>Thu, 25 Apr 2024 18:20:42 GMT</pubDate>
    </item>
    <item>
      <title>AgentGraph：用于 LLM 开发的 Python 库</title>
      <link>https://community.openai.com/t/agentgraph-a-python-library-for-llm-development/727712#post_1</link>
      <description><![CDATA[我们一直在开发一个 Python 库 AgentGraph，以便更轻松地开发对法学硕士进行多次调用的软件。 AgentGraph提供的是：


基于任务的嵌套并行模型，用于隐藏 LLM 查询的延迟，并使用异步 IO 支持多个并行查询。这也可用于并行调用本机代码以删除 GIL。


一种提示语言，可让您轻松构建查询并利用 Jinja 模板语言生成提示。


支持记忆 LLM 查询，以便节省重放程序的时间，从而缩短调试周期并提供可重复性。


我们的框架比LangChain这样的系统要低得多。我们为您提供构建人工智能应用程序的工具，但我们不会为您生成 LLM 查询。
我们的项目位于：
  &lt;标题类=“来源”&gt;
      
GitHub


  &lt;文章类=“onebox-body”&gt;
    
GitHub - bdemsky/agentgraph：AgentGraph 是一个用于编写 AI 的库...&lt; /a&gt;
AgentGraph 是一个用于编写调用 LLM 的 AI 应用程序的库。它提供并行执行、查询生成语言和记忆功能。 -bdemsky/agentgraph





一些示例程序可在以下位置找到：
  &lt;标题类=“来源”&gt;
      
GitHub


  &lt;文章类=“onebox-body”&gt;
    
GitHub - bdemsky/agentgraph-apps：AgentGraph 的示例应用程序。
AgentGraph 的示例应用程序。通过在 GitHub 上创建帐户来为 bdemsky/agentgraph-apps 开发做出贡献。




]]></description>
      <guid>https://community.openai.com/t/agentgraph-a-python-library-for-llm-development/727712#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 18:18:10 GMT</pubDate>
    </item>
    <item>
      <title>空答案 bug 代码嵌入</title>
      <link>https://community.openai.com/t/empty-answer-bugs-code-embeddings/727710#post_1</link>
      <description><![CDATA[嗨，
这是我第一次遇到这种情况，当我要求修改代码（例如 xaml 代码）时，chatgpt 给出了空答案：

关于如何解决这个问题有什么想法吗？
我使用的是 chatgpt 普通 4 版本（无自定义 gpt）。
提前致谢]]></description>
      <guid>https://community.openai.com/t/empty-answer-bugs-code-embeddings/727710#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 18:17:43 GMT</pubDate>
    </item>
    <item>
      <title>批量API的文件管理</title>
      <link>https://community.openai.com/t/file-management-for-batch-api/727709#post_1</link>
      <description><![CDATA[使用批处理 API 时，我发现即使批处理完成运行后，我的批处理文件仍会上传到文件端点。有谁知道OpenAI是否会对这些过期的批处理文件的存储收取费用？我可以使用文件端点时不时地清理它们，但如果它们在批次后自动消失会更容易。]]></description>
      <guid>https://community.openai.com/t/file-management-for-batch-api/727709#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 18:15:38 GMT</pubDate>
    </item>
    <item>
      <title>关于矢量存储的一些问题</title>
      <link>https://community.openai.com/t/some-questions-about-the-vector-store/722858#post_3</link>
      <description><![CDATA[@elmstedt 我可以创建自己的矢量存储并在该矢量的顶部应用助手吗？
由于一些政策问题，我无法将我的文件共享到 openAi，有什么解决方案吗？我可以创建一些数据库并在那里使用助手吗？]]></description>
      <guid>https://community.openai.com/t/some-questions-about-the-vector-store/722858#post_3</guid>
      <pubDate>Thu, 25 Apr 2024 18:00:30 GMT</pubDate>
    </item>
    <item>
      <title>保护法学硕士免遭快速注入和越狱：新的 OpenAI 论文</title>
      <link>https://community.openai.com/t/protecting-llms-from-prompt-injections-and-jailbreaks-new-openai-paper/727636#post_4</link>
      <description><![CDATA[对我来说，系统提示是事实真相总是有意义的，但 OpenAI 不断发布文档鼓励用户角色中的指令和 RAG。
这太疯狂了。为什么我要给用户这样的权力？让说“哦，实际上，而是做 Y”变得如此简单
我记得 ChatML 首次发布时。为事实数据添加系统消息是每个人的直觉。我们不知道只能有一条系统消息。喜欢WAT
感谢分享！]]></description>
      <guid>https://community.openai.com/t/protecting-llms-from-prompt-injections-and-jailbreaks-new-openai-paper/727636#post_4</guid>
      <pubDate>Thu, 25 Apr 2024 17:59:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 PlayGround 中助手给出的答案与 API 给出的答案不同？</title>
      <link>https://community.openai.com/t/why-is-the-answer-given-by-the-assistant-in-playground-different-from-the-answer-given-by-api/727130#post_3</link>
      <description><![CDATA[在默认参数下，助手对相同输入的每次回复都会有显着不同。根据输入的不同，人工智能是否说“当然！”或“对不起，我不能”甚至可能是 50/50。
助手 beta2 最终公开 top_p 和温度，让您可以更好地控制。]]></description>
      <guid>https://community.openai.com/t/why-is-the-answer-given-by-the-assistant-in-playground-different-from-the-answer-given-by-api/727130#post_3</guid>
      <pubDate>Thu, 25 Apr 2024 17:57:22 GMT</pubDate>
    </item>
    <item>
      <title>Vector Store 链接到 Assistant - 更新不快？</title>
      <link>https://community.openai.com/t/vector-store-linked-to-assistant-not-updating-quickly/727689#post_1</link>
      <description><![CDATA[我创建了一个矢量存储，向其中添加了一个文件并将其链接到我的助手。在操场上，我可以查询助手并让它参考商店，给出适当的答案。
通过 API，助手似乎无法引用新的矢量存储。最近链接到助手的 API 和矢量存储是否存在一些滞后？
我验证了我的 API 调用的助手 ID 是正确的（与我在 Playground 上使用的助手相同）。]]></description>
      <guid>https://community.openai.com/t/vector-store-linked-to-assistant-not-updating-quickly/727689#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 17:57:09 GMT</pubDate>
    </item>
    <item>
      <title>微调模型变得疯狂：附加大约 3000 个条目并输出无效 JSON</title>
      <link>https://community.openai.com/t/fine-tuned-model-goes-crazy-appends-around-3000-entries-and-outputs-invalid-json/727533#post_3</link>
      <description><![CDATA[嗨，
感谢你的回复。微调的目的是从需求中提取指定的元素类型和短语。
以下是消息示例：
{&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;对需求进行分类，是否包含元素类型活动、组件、数据、实体、状态。提取指示性需求中元素类型的短语定义为由可以处理数据并与其他活动通信的特定实体执行的操作，组件定义为为特定目的提供功能的软件的一部分。一个或多个实体可以被部署在一个节点上。 一个实体被定义为一个可以保存数据的物理参与者、软件对象或外部系统。定义为由数据表示的活动或实体的状态。列出 JSON 数组中所有元素类型的所有元素，为每个条目提供键 indicativePhrase 和 elementType 如果需求中没有元素类型，则返回。一个空列表。&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;系统应该只包含有关充电站用户的最少信息（令牌已验证）。 &quot;}, {&quot;角色&quot;: &quot;助理&quot;, &quot;内容&quot;: &quot;[{\&quot;indicativePhrase\&quot;:\&quot;information\&quot;,\&quot;elementType\&quot;:\&quot;data\&quot;},{\&quot;indicativePhrase\&quot; :\&quot;token\&quot;,\&quot;elementType\&quot;:\&quot;data\&quot;},{\&quot;indicativePhrase\&quot;:\&quot;user\&quot;,\&quot;elementType\&quot;:\&quot;entity\&quot;},{\&quot;indicativePhrase \&quot;:\&quot;已验证\&quot;,\&quot;elementType\&quot;:\&quot;状态\&quot;}]&quot;}]}
如果我现在发送包含系统提示的全部内容和用户提示中的要求的请求，它首先从要求中提取有效元素，然后继续重复输入。]]></description>
      <guid>https://community.openai.com/t/fine-tuned-model-goes-crazy-appends-around-3000-entries-and-outputs-invalid-json/727533#post_3</guid>
      <pubDate>Thu, 25 Apr 2024 17:49:33 GMT</pubDate>
    </item>
    <item>
      <title>为 Assistant api 创建我自己的矢量存储</title>
      <link>https://community.openai.com/t/creating-my-own-vector-store-for-assistant-api/727681#post_1</link>
      <description><![CDATA[我可以创建我的矢量存储（不是 openAi 提供的矢量存储）并在我自己创建的矢量存储（我在其他地方托管）之上创建文件搜索助手吗？如果是，有什么指南或程序需要遵循吗？]]></description>
      <guid>https://community.openai.com/t/creating-my-own-vector-store-for-assistant-api/727681#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 17:41:20 GMT</pubDate>
    </item>
    <item>
      <title>更新未推广到欧洲</title>
      <link>https://community.openai.com/t/updates-are-not-rolled-out-to-europe/727674#post_1</link>
      <description><![CDATA[亲爱的 OPEN AI，我被迫接受您允许欧洲用户进行的小更新。
我们没有几个月前在美国推出的内存。我的 GPT 完全忽略所有自定义指令 - 为什么这些指令还在那里？由于我们无法访问 Claude 3（作品）（没有 VPN 不起作用，需要美国电话号码） - 我们别无选择，只能落后。我整天都在使用 GPT。但是，当使用 GPT4 Turbo 工作比自己完成任务花费更多时间时……这​​非常令人沮丧。
请启动 GPT 5 - 完整更新 - 无崩溃 -
]]></description>
      <guid>https://community.openai.com/t/updates-are-not-rolled-out-to-europe/727674#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 17:36:40 GMT</pubDate>
    </item>
    </channel>
</rss>