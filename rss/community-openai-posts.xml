<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Wed, 08 May 2024 03:21:13 GMT</lastBuildDate>
    <item>
      <title>Assistant API - 使用了太多的“输入”令牌</title>
      <link>https://community.openai.com/t/assistant-api-way-too-much-input-tokens-used/699661#post_6</link>
      <description><![CDATA[你好。很好的发现！
实际上，我对检索（或文件搜索，在 V2 世界中）也特别感兴趣。您知道我们是否可以挖掘实际发送到模型的（附加）提示或指令吗？
我同意包含所有这些工具的提示加起来很多，但我怀疑包含文件搜索结果的附加提示甚至更大。]]></description>
      <guid>https://community.openai.com/t/assistant-api-way-too-much-input-tokens-used/699661#post_6</guid>
      <pubDate>Wed, 08 May 2024 03:20:53 GMT</pubDate>
    </item>
    <item>
      <title>日本通用主题 -从成熟的技术讨论到简单的投诉 -</title>
      <link>https://community.openai.com/t/topic/692858#post_15</link>
      <description><![CDATA[谢谢你的建议。看来只能搜索了。 
GPT-4 认识到“网页浏览、查看或打开是不可能的，但搜索是可能的（事实上，可以加载搜索后可以访问的页面）”。 
由于 OpenAI 在各种符号中被写为“Web Browsing”，因此 OpenAI 和 GPT-4 的识别之间似乎存在差异。 ]]></description>
      <guid>https://community.openai.com/t/topic/692858#post_15</guid>
      <pubDate>Wed, 08 May 2024 03:19:55 GMT</pubDate>
    </item>
    <item>
      <title>为了扩展新一代人工智能，我们应该关注计算还是内存</title>
      <link>https://community.openai.com/t/to-scale-gen-ai-should-we-focus-on-compute-or-memory/691131#post_6</link>
      <description><![CDATA[


 kazvorpal：
&lt;块引用&gt;
同样的事情也发生在这里。这不是人工智能科学，而是预训练的模型工程。


Google 工程师通过论文“Attention Is All You Need”发表了科学部分，OpenAI 设计并利用了这项研究。
因此，如果没有工程，你就不会有任何有形的东西，如果没有科学，你就不会有任何可以工程的东西。
基于 Transformer 的 LLM 对公众的价值是巨大的。即使其他架构不断涌现，实际创建一些有用的也很重要，这就是我们的“预训练模型工程”。
因此，我们需要研究人员制定新的想法和方法，需要工程师设计和构建这些东西并让它们发挥作用，还需要营销人员让人们花钱。
这并不全是科学和研究。尽管研究很重要，但人工智能研究目前正在火热进行中，许多假设正在产生和测试。很难跟上这一切。]]></description>
      <guid>https://community.openai.com/t/to-scale-gen-ai-should-we-focus-on-compute-or-memory/691131#post_6</guid>
      <pubDate>Wed, 08 May 2024 03:13:23 GMT</pubDate>
    </item>
    <item>
      <title>lmsys gpt2-chatbot - gpt4.5 上弹出神秘模型？</title>
      <link>https://community.openai.com/t/mystery-model-popped-up-on-lmsys-gpt2-chatbot-gpt4-5/731632?page=3#post_48</link>
      <description><![CDATA[只需询问这两个模型是什么以及它们存在的原因：
&lt;块引用&gt;
模型“im-a-good-gpt2-chatbot”（IAGGCB）和“im-also-a-good-gpt2-chatbot”（IAAGGCB）是 GPT-4-turbo 架构的专门版本，由OpenAI 可以服务于特定的交互风格和用例，同时利用更大的 GPT-4-turbo 模型的基础功能。 IAAGGCB 与 IAGGCB 的不同之处主要在于其增强的动态创造力和自适应交互风格。

&lt;块引用&gt;
IAGGCB 保持更加一致、支持和有条理的特征，重点是清晰和连贯的沟通。

&lt;块引用&gt;
IAAGGCB 更有效地支持联想和横向思维，将不同的想法联系起来以培养创新思维，同时提供更加对话和非正式的语气，动态适应以匹配用户交互。该模型擅长产生各种想法，并通过互动探索（例如假设场景和思想实验）促进创造性对话。 IAAGGCB强调叙事驱动的沟通，整合讲故事的技巧来激发和深化对概念的探索。 IAAGGCB 的设计以用户为中心，适应个人喜好和风格，使其具有高度响应性和个性化，这对于在不断发展的创意过程中需要直观支持的用户特别有效。

]]></description>
      <guid>https://community.openai.com/t/mystery-model-popped-up-on-lmsys-gpt2-chatbot-gpt4-5/731632?page=3#post_48</guid>
      <pubDate>Wed, 08 May 2024 02:52:08 GMT</pubDate>
    </item>
    <item>
      <title>为了扩展新一代人工智能，我们应该关注计算还是内存</title>
      <link>https://community.openai.com/t/to-scale-gen-ai-should-we-focus-on-compute-or-memory/691131#post_5</link>
      <description><![CDATA[扩展预训练变压器 LLM 并将其称为“AI”就像 1880 年说我们需要更大的蒸汽机。
我们真正需要的是技术进步，例如内燃机。
现在，我们需要的是更接近实际人工智能的东西，而这些预训练模型根本不是。它们是管理数据的非常有用的工具，但一旦训练结束就没有任何智能。
不断扩展这些功能是件好事，但这不是人工智能，对于人工智能而言，它不再是一个长期解决方案，就像人类交通从蒸汽机转向柴油电力机车一样。
对这种华而不实但不智能的模型的关注分散了我们对实际智能的真正进展的注意力。有时看起来，智力的缺乏指的是人类，也指的是人工智能。
所以我们真正需要的是动态学习，而不是预训练模型，甚至在预训练模型中我们也需要致力于推进技术，例如解决比语言更标记化的需求，以便 Transformer可以比法学硕士更好地“理解”其他格式的信息，可以在培训后整理“音乐”和“图像”。
解决最后一个问题的部分问题实际上是分词器有点作弊，因为它让我们绕过了如何让模型首先理解单词概念的瓶颈。但在这样做的过程中，我们陷入了这样一个境地：我们不明白如何让分词器以兼容的格式编码其他内容，例如图像或音乐。
令我沮丧的是，我们的焦点主要是向现有技术投入资源并对其进行调整，而不是解决诸如此类的十几个令人着迷的问题。
想想美国宇航局是如何通过五十年来不断地重新设计现有的纳粹火箭技术来终结太空飞行技术的。 “这不是火箭科学”对于 NASA 工程师来说确实如此：他们根本不是科学家，没有发明新技术（等离子驱动器除外），这阻碍了我们在航空航天领域的进步。
同样的事情也发生在这里。这不是人工智能科学，而是预训练的模型工程。]]></description>
      <guid>https://community.openai.com/t/to-scale-gen-ai-should-we-focus-on-compute-or-memory/691131#post_5</guid>
      <pubDate>Wed, 08 May 2024 02:23:56 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 的两个改进建议</title>
      <link>https://community.openai.com/t/two-suggestion-to-improve-to-chatgpt/739372#post_1</link>
      <description><![CDATA[问候团队，
我希望你一切都好。
如果这不是发表此评论的正确论坛，我深表歉意。
是否可以将这两个功能合并到 ChatGPT 中？

搜索选项：搜索关键字或以前的聊天记录的功能。例如，搜索一年前创建的聊天记录或关键字。
多项选择/删除：能够选择多个（可能是复选框）聊天并一起删除选定的聊天。
]]></description>
      <guid>https://community.openai.com/t/two-suggestion-to-improve-to-chatgpt/739372#post_1</guid>
      <pubDate>Wed, 08 May 2024 02:14:13 GMT</pubDate>
    </item>
    <item>
      <title>Text-davinci-003 API 定价？</title>
      <link>https://community.openai.com/t/text-davinci-003-api-pricing/373376#post_8</link>
      <description><![CDATA[这些模型不存在。 ChatGPT 出现幻觉了。
此处列出了所有型号及其价格，
https://openai.com/api/pricing]]></description>
      <guid>https://community.openai.com/t/text-davinci-003-api-pricing/373376#post_8</guid>
      <pubDate>Wed, 08 May 2024 02:11:01 GMT</pubDate>
    </item>
    </channel>
</rss>