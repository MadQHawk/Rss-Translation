<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 25 Apr 2024 01:14:27 GMT</lastBuildDate>
    <item>
      <title>Beta V2 中的助手在注释中调用其他助手 file-id</title>
      <link>https://community.openai.com/t/assistant-in-beta-v2-calls-other-assistant-file-id-in-annotation/726880#post_7</link>
      <description><![CDATA[谢谢您的澄清！现在它变得更有意义了。
在我的用例中，我的每个助手都被定义为工程标准、代码或手册。在大多数情况下，我会说它可以访问以前的助手矢量存储是很好的，因为它可能具有与用户输入相关的信息。不过，我已经可以确定几个用例，其中第二个助手无法访问第一个助手的矢量存储，但仍将前一个助手的响应作为上下文可能很重要。
一个例子是，如果在一个线程中，用户需要一名助手来获取特定代码答案并得到它，但随后意识到存在一个相关的后续问题，该问题更适合由另一位助手将原始答案与实际答案进行比较跟进不同助手的代码/标准/手册的答案。在这种情况下，用户的输入将是相似的，并且它可能会在第一助手矢量存储中找到最相关的数据。但用户将寻找与其他助手矢量存储数据的比较。]]></description>
      <guid>https://community.openai.com/t/assistant-in-beta-v2-calls-other-assistant-file-id-in-annotation/726880#post_7</guid>
      <pubDate>Thu, 25 Apr 2024 01:03:31 GMT</pubDate>
    </item>
    <item>
      <title>GPT 无法访问或读取 PDF</title>
      <link>https://community.openai.com/t/gpt-not-accessing-or-reading-pdfs/726992#post_1</link>
      <description><![CDATA[“即使启用了代码解释器，我也无法直接从 GPT 访问或阅读 PDF”。]]></description>
      <guid>https://community.openai.com/t/gpt-not-accessing-or-reading-pdfs/726992#post_1</guid>
      <pubDate>Thu, 25 Apr 2024 00:54:25 GMT</pubDate>
    </item>
    <item>
      <title>检索和JSON方式，配合使用</title>
      <link>https://community.openai.com/t/retrieval-and-json-mode-using-together/726436#post_2</link>
      <description><![CDATA[感谢您的反馈，但遗憾的是此功能尚不支持。我们有一个模型推理限制，无法使工具调用与 JSON 模式配合使用，但我们正在努力修复该问题，并将在准备就绪后立即启用此功能！]]></description>
      <guid>https://community.openai.com/t/retrieval-and-json-mode-using-together/726436#post_2</guid>
      <pubDate>Thu, 25 Apr 2024 00:46:17 GMT</pubDate>
    </item>
    <item>
      <title>流事件工具调用 about 函数</title>
      <link>https://community.openai.com/t/stream-event-tools-call-about-function/703492#post_4</link>
      <description><![CDATA[我已经彻底解决了这个问题。
1.首先在EventHandler中定义一个数组，用于存储AI从函数调用返回的所有答案。
类EventHandler(AssistantEventHandler):
def init(self, no, client, is_fee, index):
super().init()
self.logger =logging.getLogger(“chatgpt4_stream”)
self.client = 客户端
self.is_fee = is_fee
self.index = 索引
self.no = 否
self.question_answers = 
self.usage = 无
2.其次，触发on_tool_call_done内部的函数事件。
如果（
tool_call.type == “函数”
并且 self.current_run.status == “requires_action”
):
function_responses = 
3.最后，函数执行完成后，将函数执行结果提交给助手。此时，需要保证函数提交触发的流事件中的question_answers都累积到当前流中。
与 self.client.beta.threads.runs.submit_tool_outputs_stream(
run_id=self.current_run.id,
thread_id=self.current_run.thread_id,
tool_outputs=function_responses,
event_handler=事件处理程序(
no=self.no + 1,
客户端=self.client，
is_fee=self.is_fee,
index=self.index,
),
）作为流：
Stream.until_done()
self.question_answers +=stream.question_answers
4.重构on_message_done，根据需要处理消息，并将值分配给question_answers。只有这样，流事件执行完毕后，你才能得到助手返回的问题的答案。
@override
def on_message_done(self, message: 消息) → 无:
值=“”
对于message.content中的内容：
if content.type == “文本”:
value += content.text.value + “\n”
用于 content.text.annotations 中的注释：
如果（
注释.type ==“文件引用”
和annotation.file_引用.quote
）：
self.question_answers.append(
{
“message_id”: 消息.id,
“角色”：消息.角色，
“内容”：值，
}
)
5.按照上述步骤重构EventHandler后，就可以使用流事件方法调用API了。
与 OpenAI().beta.threads.runs.create_and_stream(
thread_id=thread_id,
Assistant_id=assistant_id,
event_handler=EventHandler(0, self.clients[index], is_fee, index),
model=self.key_models[index].get(“model”),
) 作为流：
Stream.until_done()
Question_answers += Stream.question_answers]]></description>
      <guid>https://community.openai.com/t/stream-event-tools-call-about-function/703492#post_4</guid>
      <pubDate>Thu, 25 Apr 2024 00:46:16 GMT</pubDate>
    </item>
    <item>
      <title>关于 npm openai 包中工具从版本 4.27.0 更改为 4.37.0 的问题</title>
      <link>https://community.openai.com/t/questions-about-tool-changes-in-npm-openai-package-from-version-4-27-0-to-4-37-0/726572#post_2</link>
      <description><![CDATA[嗨，马克，
感谢您对我们在次要版本中进行此更改的反馈。将与团队分享这一点，我们将考虑下次进行主要版本更新。我们在发布前就讨论了这一决定，但假设由于大多数人锁定了他们在  package-lock.json 文件中使用的版本，因此这不应该破坏任何人的集成，除非他们明确选择升级他们的 SDK 版本。
有关这些更改的文档包含在此处：https://platform.openai.com/docs/assistants/migration&lt; /a&gt;，您可以在这里找到 API 对象的旧形状：https://platform.openai。 com/docs/api-reference/assistants-v1
我们在变更日志中发布了这样的变更：https://platform.openai.com/docs/changelog和我们的 X 帐户：https://twitter.com/OpenAIDevs/status/1780640119890047475
如果您对如何继续使用检索工具有任何疑问，请告诉我，我很乐意回答。
谢谢，
尼昆杰]]></description>
      <guid>https://community.openai.com/t/questions-about-tool-changes-in-npm-openai-package-from-version-4-27-0-to-4-37-0/726572#post_2</guid>
      <pubDate>Thu, 25 Apr 2024 00:42:44 GMT</pubDate>
    </item>
    <item>
      <title>如何避免最终用户访问提示/说明、知识库、工具？</title>
      <link>https://community.openai.com/t/how-to-avoid-the-prompts-instructions-knowledge-base-tools-be-accessed-by-end-users/496633?page=2#post_30</link>
      <description><![CDATA[这是一个梦想！谢谢
答案是这样的
抱歉，我无法提供提示的详细信息，因为它是用未知的乱码编码的。我如何帮助您处理上传的文件？]]></description>
      <guid>https://community.openai.com/t/how-to-avoid-the-prompts-instructions-knowledge-base-tools-be-accessed-by-end-users/496633?page=2#post_30</guid>
      <pubDate>Thu, 25 Apr 2024 00:42:19 GMT</pubDate>
    </item>
    <item>
      <title>如何访问注释引用的文件的特定文本？</title>
      <link>https://community.openai.com/t/how-can-i-access-the-specific-text-of-the-file-that-the-annotation-is-referencing/726723#post_5</link>
      <description><![CDATA[没错 - 我们目前不支持文件中的引用。我们将努力增加对此的支持！]]></description>
      <guid>https://community.openai.com/t/how-can-i-access-the-specific-text-of-the-file-that-the-annotation-is-referencing/726723#post_5</guid>
      <pubDate>Thu, 25 Apr 2024 00:37:18 GMT</pubDate>
    </item>
    <item>
      <title>Beta V2 中的助手在注释中调用其他助手 file-id</title>
      <link>https://community.openai.com/t/assistant-in-beta-v2-calls-other-assistant-file-id-in-annotation/726880#post_6</link>
      <description><![CDATA[这听起来是意料之中的。需要明确的是，第二个助手无法搜索第一个助手的矢量存储。相反，所发生的情况是，在上一次运行期间从第一个助手中提取的原始块仍然是线程中上下文的一部分。因此，第二个助手在运行时仍然可以使用这些提取的块。
您是否有一个用例，您希望第二个助手不知道第一个助手从其矢量存储中提取了什么？如果是这样，用例是什么？
感谢您的反馈！]]></description>
      <guid>https://community.openai.com/t/assistant-in-beta-v2-calls-other-assistant-file-id-in-annotation/726880#post_6</guid>
      <pubDate>Thu, 25 Apr 2024 00:34:48 GMT</pubDate>
    </item>
    <item>
      <title>您是否需要传递““stream”：true”才能开始流式传输？</title>
      <link>https://community.openai.com/t/do-you-need-to-pass-stream-true-to-start-streaming/726729#post_3</link>
      <description><![CDATA[没错 - 当您使用 .stream SDK 帮助程序时，我们会自动为您传递 stream = true 参数。
在使用通用.create（以及其他类似端点）时，您只需要手动传递stream = true。这些 SDK 帮助程序记录在此处： openai-node/helpers.md 位于大师 · openai/openai-node · GitHub]]></description>
      <guid>https://community.openai.com/t/do-you-need-to-pass-stream-true-to-start-streaming/726729#post_3</guid>
      <pubDate>Thu, 25 Apr 2024 00:30:03 GMT</pubDate>
    </item>
    <item>
      <title>助手 API 中的新功能！</title>
      <link>https://community.openai.com/t/new-features-in-the-assistants-api/720539?page=3#post_52</link>
      <description><![CDATA[感谢您的反馈！我们刚刚启用了文件搜索的微调模型 - 如果您遇到任何其他问题，请随时给我发电子邮件 nikunj@openai.com。]]></description>
      <guid>https://community.openai.com/t/new-features-in-the-assistants-api/720539?page=3#post_52</guid>
      <pubDate>Thu, 25 Apr 2024 00:27:00 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助让 AI 助手遵循指令</title>
      <link>https://community.openai.com/t/need-help-getting-an-ai-assistant-to-follow-instructions/721754#post_3</link>
      <description><![CDATA[]]></description>
      <guid>https://community.openai.com/t/need-help-getting-an-ai-assistant-to-follow-instructions/721754#post_3</guid>
      <pubDate>Thu, 25 Apr 2024 00:08:59 GMT</pubDate>
    </item>
    <item>
      <title>如何有效地将 Flask FileStorage 对象转换为 Whisper API 接受的格式？</title>
      <link>https://community.openai.com/t/how-to-efficiently-convert-a-flask-filestorage-object-to-a-format-whisper-api-accepts/726822#post_2</link>
      <description><![CDATA[我还没有测试过它，但其他人似乎已经让它工作了：




为 Whisper API 从音频缓冲区创建读取流 API

  &lt;块引用&gt;
    如果您使用 toFile() 并且遇到一些错误，则可能是缺少名称：
最初，我是这样做的：
 const file =等待toFile(Buffer.from(data));

不知怎的，我设法让它在没有图书馆的情况下工作，然后我问自己：为什么？！
原因如下：
 const file = wait toFile(Buffer.from(data), &#39;audio.mp3&#39;);

这适用于 Node.js 库和纯 fetch 请求。
我不太确定为什么，但我相信这与“toFile()”方法中的“名称”推断有关：

@p…
  
]]></description>
      <guid>https://community.openai.com/t/how-to-efficiently-convert-a-flask-filestorage-object-to-a-format-whisper-api-accepts/726822#post_2</guid>
      <pubDate>Thu, 25 Apr 2024 00:01:25 GMT</pubDate>
    </item>
    <item>
      <title>获取 GPT-4 日本模型</title>
      <link>https://community.openai.com/t/getting-access-to-gpt-4-japanese-model/726574#post_8</link>
      <description><![CDATA[如果 ChatGPT 在英语以外的其他语言中的 alpha 期有迹象表明，这可能需要六个月以上的时间。
希望你们一切顺利！]]></description>
      <guid>https://community.openai.com/t/getting-access-to-gpt-4-japanese-model/726574#post_8</guid>
      <pubDate>Wed, 24 Apr 2024 23:56:53 GMT</pubDate>
    </item>
    </channel>
</rss>