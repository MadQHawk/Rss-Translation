<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 01 Apr 2024 01:16:34 GMT</lastBuildDate>
    <item>
      <title>创建 gpt 助手 - 聊天机器人</title>
      <link>https://community.openai.com/t/creating-a-gpt-assistant-chatbot/702899#post_3</link>
      <description><![CDATA[当然，我已经发送了请求表，但在看到更多文档后，我了解到我可以使用其他较低的型号，例如“gpt-3.5-turbo”，但我仍然不知道使用此型号是否会拥有与助理互动的限制。是否有任何形式的每次使用付费，至少可以控制助手的使用，并在这种情况下决定我给予它的使用量？]]></description>
      <guid>https://community.openai.com/t/creating-a-gpt-assistant-chatbot/702899#post_3</guid>
      <pubDate>Mon, 01 Apr 2024 01:05:23 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 视觉文件大小限制</title>
      <link>https://community.openai.com/t/gpt-4-vision-file-size-limitations/703324#post_2</link>
      <description><![CDATA[当您已经可以控制大图像时，您似乎只是在浪费它们。
API 会进行自己的内部多步调整大小，并且在此自动调整大小后您可以解释的最大图像为 2048x768（消耗 8 个“图块”）。未压缩时，即 150 万像素，或 4.5MB 真彩色。
传递给模型时，最短边不大于 768px，最长边不大于 2048px。
您可以使用与 OpenAI 相同的调整大小逻辑，还可以通过更小的网络传输来提高响应速度，并消除服务器端的图像调整大小。]]></description>
      <guid>https://community.openai.com/t/gpt-4-vision-file-size-limitations/703324#post_2</guid>
      <pubDate>Mon, 01 Apr 2024 01:03:54 GMT</pubDate>
    </item>
    <item>
      <title>“角色”仅限于（英语）拉丁字母 ^[a-zA-Z0-9_-]{1,64}$</title>
      <link>https://community.openai.com/t/role-is-restricted-to-english-latin-script-only-a-za-z0-9-1-64/703341#post_2</link>
      <description><![CDATA[听起来您指的是“名称” - 为聊天完成消息的发送者指定一个名称。
相反，“角色”是您可以传递的选项（系统、用户、助手、功能）的集合列表。
看来 name 的意图可能更具编程性，而不是基于语言。例如，它用于传递函数角色中的函数名称。你甚至不能传递“André”这个名字，因为有重音字符，也不能传递“Joe Nye”，因为空格。]]></description>
      <guid>https://community.openai.com/t/role-is-restricted-to-english-latin-script-only-a-za-z0-9-1-64/703341#post_2</guid>
      <pubDate>Mon, 01 Apr 2024 00:54:34 GMT</pubDate>
    </item>
    <item>
      <title>我在 GPT-4 上创建了自定义 GPT（我的 GPT）。我如何在 GPT 3.5 Turbo 上运行？</title>
      <link>https://community.openai.com/t/i-have-created-custom-gpt-my-gpt-on-gpt-4-how-so-i-run-in-on-gpt-3-5-turbo/530673#post_13</link>
      <description><![CDATA[一个破旧的解决方法......
您通常在配置选项卡中的 GPT“说明”字段中输入的相同文本可以粘贴为普通 ChatGPT 3.5 会话中的启动提示。 （不使用 GPT 功能）
你不会有任何行动。您将没有快速启动按钮。您不会有一个易于共享的 GPT 链接。您的 GPT 不会出现在 GPT 存储区中。
但是……在宣布您已用完当天的配额之前，您的 GPT 将能够回答十多个提示。在付费帐户上。叹息。
GPT 基本上只是快速接地，加上一点行动的粘合剂。]]></description>
      <guid>https://community.openai.com/t/i-have-created-custom-gpt-my-gpt-on-gpt-4-how-so-i-run-in-on-gpt-3-5-turbo/530673#post_13</guid>
      <pubDate>Mon, 01 Apr 2024 00:39:27 GMT</pubDate>
    </item>
    <item>
      <title>产品创意 - 寻找团队 - gethighwith.ai</title>
      <link>https://community.openai.com/t/product-idea-looking-for-team-gethighwith-ai/703502#post_1</link>
      <description><![CDATA[（主题已被作者删除）]]></description>
      <guid>https://community.openai.com/t/product-idea-looking-for-team-gethighwith-ai/703502#post_1</guid>
      <pubDate>Mon, 01 Apr 2024 00:37:08 GMT</pubDate>
    </item>
    <item>
      <title>使用助手 API 时 RPM 速率限制为 100</title>
      <link>https://community.openai.com/t/rpm-rate-limits-at-100-when-using-assistants-api/703497#post_2</link>
      <description><![CDATA[现在的情况是，Google Assistant 尚处于测试阶段，其速率受到帐户范围内对 API 端点的调用数量的限制。它不适合批量部署，这既是因为人为限制，也是因为缺乏成本责任和控制。
您实际上似乎显示出记录的每分钟 60 个请求有所增加。
https:// platform.openai.com/docs/assistants/how-it-works/limitations]]></description>
      <guid>https://community.openai.com/t/rpm-rate-limits-at-100-when-using-assistants-api/703497#post_2</guid>
      <pubDate>Mon, 01 Apr 2024 00:36:34 GMT</pubDate>
    </item>
    <item>
      <title>是否可以复制 GPT 的行为并使用 langchain 存储 convo 历史记录？</title>
      <link>https://community.openai.com/t/is-it-possible-to-replicate-the-behaviour-of-a-gpt-and-to-store-convo-history-using-langchain/703500#post_1</link>
      <description><![CDATA[我的目标是通过 API 复制自定义 GPT 的工作流程，在模型上下文窗口允许的范围内保持对话历史记录的长度。如果能够启用互联网检索功能就好了，但我不需要使用函数功能，只需要提供一个起始上下文并使用聊天完成功能。
通过 OpenAI 助手 API 创建助手时，我们会获得一个助手 ID，我们可以存储该 ID，以便稍后再次访问该助手。如果我没记错的话，助手会存储对话历史记录，以便当用户再次呼叫它时，他可以从上次离开的地方继续对话。但是，我的用例中不需要助手的任何功能，我只需要聊天完成。
我想知道是否通过使用 Langchain，有一种方法可以存储一种 convo id 并存储它以便能够从我离开的位置获取 convo。
如果答案是否定的，我想我可以为每个 convo 创建一个 uuid 并将每条消息存储在数据库中，并且能够通过重新注入整个 convo 历史记录来从我离开的位置取回，但这对我来说看起来很沉重，两者在数据库存储和成本中，我将重新注入 convo 并再次支付所有代币。
这是我的两个问题：

您会推荐哪种技术来存储卷积以高效地完成原始文本？
可以使用 Langchain 还是需要使用 OpenAI API ？
]]></description>
      <guid>https://community.openai.com/t/is-it-possible-to-replicate-the-behaviour-of-a-gpt-and-to-store-convo-history-using-langchain/703500#post_1</guid>
      <pubDate>Mon, 01 Apr 2024 00:33:08 GMT</pubDate>
    </item>
    <item>
      <title>使用助手 API 时 RPM 速率限制为 100</title>
      <link>https://community.openai.com/t/rpm-rate-limits-at-100-when-using-assistants-api/703497#post_1</link>
      <description><![CDATA[使用开放 AI python 库，我们通过 client.beta.threads.create、messages.create、runs.create 等代码调用辅助 API 功能
我们经常遇到错误代码：429：“您已超出 100 个请求/分钟的速率限制，请放慢速度并重试。”
我们的帐户是第 4 层，我相信它有 10,000 RPM 限制，所以我试图找出为什么我们会收到此错误。与此同时，我们已经实施了坚韧等措施，但从我们获得的流量来看，这似乎站不住脚。
openAI 的人可以看一下发生了什么吗？]]></description>
      <guid>https://community.openai.com/t/rpm-rate-limits-at-100-when-using-assistants-api/703497#post_1</guid>
      <pubDate>Mon, 01 Apr 2024 00:32:41 GMT</pubDate>
    </item>
    <item>
      <title>流事件工具调用 about 函数</title>
      <link>https://community.openai.com/t/stream-event-tools-call-about-function/703492#post_1</link>
      <description><![CDATA[我正在使用流事件方法与 OpenAI 的 API 进行交互。尽管我在使用函数工具调用自定义函数后提交了 tool_outputs，但 OpenAI 似乎没有像在非事件模式下那样成功接收自定义函数的结果。为什么是这样？这是我的代码：
@override
def on_tool_call_done(self, tool_call: ToolCall):
if tool_call.type == “code_interpreter”:
self.logger.info(
“on_tool_call_done：%s”, tool_call.code_interpreter.outputs
)
elif tool_call.type == “检索”:
self.logger.info(“on_tool_call_done：%s”, tool_call.type)
elif tool_call.type == “函数”:
model_and_function = tool_call.function.name.split(“.”)
func = getattr(baidu, model_and_function[1])
func_结果 = func(
location=json.loads(tool_call.function.arguments).get(“位置”)
)
function_responses = 
function_responses.append(
{
“tool_call_id”：tool_call.id，
“输出”：func_result，
}
)
如果函数响应：
# 将函数返回结果提交给run
self.client.beta.threads.runs.submit_tool_outputs_stream(
run_id=self.current_run.id,
thread_id=self.thread_id,
tool_outputs=function_responses,
)
其他：
self.logger.info(“调用函数错误”)
self.logger.info(“on_tool_call_done”)]]></description>
      <guid>https://community.openai.com/t/stream-event-tools-call-about-function/703492#post_1</guid>
      <pubDate>Mon, 01 Apr 2024 00:27:40 GMT</pubDate>
    </item>
    <item>
      <title>请求聊天机器人的不相关查询</title>
      <link>https://community.openai.com/t/request-irrelevant-query-for-a-chatbot/701979#post_9</link>
      <description><![CDATA[


 字段：
&lt;块引用&gt;
本质上例如有一堆向量


热衷于创建向量，我的意思是基于我们可以构建向量？]]></description>
      <guid>https://community.openai.com/t/request-irrelevant-query-for-a-chatbot/701979#post_9</guid>
      <pubDate>Mon, 01 Apr 2024 00:19:04 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 和矢量数据库集成</title>
      <link>https://community.openai.com/t/openai-and-vector-database-integration/703289#post_3</link>
      <description><![CDATA[我首先会在 LangChain 上观看 YouTube 视频。将会有一些内容准确地解释您的需求。]]></description>
      <guid>https://community.openai.com/t/openai-and-vector-database-integration/703289#post_3</guid>
      <pubDate>Mon, 01 Apr 2024 00:15:54 GMT</pubDate>
    </item>
    </channel>
</rss>