<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Wed, 17 Apr 2024 03:19:18 GMT</lastBuildDate>
    <item>
      <title>validation_file 是做什么用的？</title>
      <link>https://community.openai.com/t/what-is-validation-file-for/413438#post_8</link>
      <description><![CDATA[我想，通过使用验证文件继续微调模型，以及 1 个时期的无影响学习乘数的最小训练文件，您可以获得单个分数，但不能获得学习率。您传递更多代币，您将再次被收取费用。并让另一个型号的名称永远流传。
或者您可以再选择一个真实的n_epochs，这样您就可以得到一个比以前多一点强化的模型来进行比较。
您将无法获得每批结束时发生的原始评估。真正有用的是对学习曲线的解释，而不仅仅是一个点。]]></description>
      <guid>https://community.openai.com/t/what-is-validation-file-for/413438#post_8</guid>
      <pubDate>Wed, 17 Apr 2024 03:14:52 GMT</pubDate>
    </item>
    <item>
      <title>长上下文结果不一致</title>
      <link>https://community.openai.com/t/inconsistent-result-with-long-context/719876#post_1</link>
      <description><![CDATA[你好，
我正在使用 chatGPT 4.0 Turbo 从法律合同中提取信息。输入合约为日文，约 23k 个代币。
我的问题是使用相同的提示和输入合同，在不同的运行中提取结果不同。我设置温度= 0，即使我设置top_p = 0.1，结果仍然不同。
有人可以帮我解决这个问题吗？谢谢。]]></description>
      <guid>https://community.openai.com/t/inconsistent-result-with-long-context/719876#post_1</guid>
      <pubDate>Wed, 17 Apr 2024 03:06:43 GMT</pubDate>
    </item>
    <item>
      <title>validation_file 是做什么用的？</title>
      <link>https://community.openai.com/t/what-is-validation-file-for/413438#post_7</link>
      <description><![CDATA[@_j 嘿，抱歉，如果这是错误的地方，但既然这个话题已经在讨论validation_file：
是否可以将validation_file添加到现有的微调作业中？我似乎忘记将它添加到我微调过的早期模型中，并且我宁愿不要再次微调它......]]></description>
      <guid>https://community.openai.com/t/what-is-validation-file-for/413438#post_7</guid>
      <pubDate>Wed, 17 Apr 2024 03:05:29 GMT</pubDate>
    </item>
    <item>
      <title>无法更新 GPT - 无法分配类别</title>
      <link>https://community.openai.com/t/unable-to-update-gpt-no-way-to-assign-a-category/719870#post_1</link>
      <description><![CDATA[我无法将更改保存到自定义 GPT - 我收到以下错误：
“无法保存 GPT：

公共 GPT 必须有一个类别”

&lt;img alt=&quot;无法将类别分配给 GPT&quot; height=&quot;300&quot; src=&quot;https://global.discourse-cdn.com/openai1/original/4X/3/7/5/375560c15cc33bb9c792bd78b309c9d504765586.png “宽度=“648”/&gt;
这很好，只是无法对现有 GPT 进行分类或添加类别。]]></description>
      <guid>https://community.openai.com/t/unable-to-update-gpt-no-way-to-assign-a-category/719870#post_1</guid>
      <pubDate>Wed, 17 Apr 2024 03:00:38 GMT</pubDate>
    </item>
    <item>
      <title>日本通用主题 -从成熟的技术讨论到简单的投诉 -</title>
      <link>https://community.openai.com/t/topic/692858#post_12</link>
      <description><![CDATA[OpenAI日本子公司开始活动啦！ （这是大约两天前的事，所以可能为时已晚）

  &lt;标题类=“来源”&gt;

      openai.com


  &lt;文章类=“onebox-body”&gt;
    
OpenAI 日本简介
我们很高兴宣布在亚洲设立第一个办事处，并且我们将发布针对日语优化的 GPT-4 自定义模型。






  &lt;标题类=“来源”&gt;

      ITmedia AI{


  &lt;文章类=“onebox-body”&gt;
    
OpenAIªú{ð我家乡^ց@ ŌêÁ½u_A§¿ G̃Pv
OpenAI &gt;


  




似乎还宣布了针对日语优化的语言模型（我认为大约与活动开始的时间相同。4月15日）

  &lt;标题类=“来源”&gt;
      
CNET 日本 – 4 月 24 日 15 日


  &lt;文章类=“onebox-body”&gt;
    
OpenAI 开设东京办事处 - 速度提高 3 倍的“日语专业化”类型 GPT-4 ”同时宣布
开发“ChatGPT”等产品的OpenAI于4月15日正式宣布开设东京办事处。该办事处是亚洲第一个办事处，将逐步开始在日本提供招聘活动、企业销售和客户支持。该公司还将积极参与日本人工智能系统的开发，并致力于普及人工智能的使用。 




]]></description>
      <guid>https://community.openai.com/t/topic/692858#post_12</guid>
      <pubDate>Wed, 17 Apr 2024 02:59:08 GMT</pubDate>
    </item>
    <item>
      <title>使用自定义编程语言/文件结构训练 ChatGPT</title>
      <link>https://community.openai.com/t/training-chatgpt-on-a-custom-programming-language-file-structure/719417#post_2</link>
      <description><![CDATA[你好！我想我可能有两个问题的答案。

培训


首先，训练 ChatGPT 模型只是提示您希望它为最终用户做什么。


可能性


是的，您可以创建提示并以 ChatGPT 能够理解的方式格式化文档信息。

这就是我现在所掌握的一切，很快就会回来报告！]]></description>
      <guid>https://community.openai.com/t/training-chatgpt-on-a-custom-programming-language-file-structure/719417#post_2</guid>
      <pubDate>Wed, 17 Apr 2024 02:57:48 GMT</pubDate>
    </item>
    <item>
      <title>Udio：来自 Nvidia 的新音乐生成器 text2audio？</title>
      <link>https://community.openai.com/t/udio-new-music-generator-text2audio-from-nvidia/711354#post_12</link>
      <description><![CDATA[他们是否暗示会有 API？他们确实计划过渡到付费模式。
最大比例的输出是可丢弃的，并且根据您对想法的第一个种子可能需要去的地方的印象，通过四种不同的“扩展”方法继续以 33 秒为基础，需要更迅速的交互。&lt; /p&gt;
他们的用户界面非常成熟，并且适合特定的产品功能，几乎没有任何缺陷。喜欢半年后比OpenAI“商店”更好看的分享。
&lt;小时/&gt;
像我根据耳语记录制作的这个剪辑这样完全令人惊叹的东西，然后比 OpenAI TTS 快几英里，只需要一个小时的工作就可以完成。
 &lt;音频控制=&quot;&quot;&gt;
            
https://od.lk/s/MjRfNDg4ODQwNDdf/fartswsong2.mp3

]]></description>
      <guid>https://community.openai.com/t/udio-new-music-generator-text2audio-from-nvidia/711354#post_12</guid>
      <pubDate>Wed, 17 Apr 2024 02:57:07 GMT</pubDate>
    </item>
    <item>
      <title>发送数据流到TTS API</title>
      <link>https://community.openai.com/t/send-data-stream-to-tts-api/719828#post_4</link>
      <description><![CDATA[@_j 感谢您的回复，因为我处理这些问题的经验很少，有没有示例代码可以参考？]]></description>
      <guid>https://community.openai.com/t/send-data-stream-to-tts-api/719828#post_4</guid>
      <pubDate>Wed, 17 Apr 2024 02:56:44 GMT</pubDate>
    </item>
    <item>
      <title>发送数据流到TTS API</title>
      <link>https://community.openai.com/t/send-data-stream-to-tts-api/719828#post_3</link>
      <description><![CDATA[（帖子已被作者删除）]]></description>
      <guid>https://community.openai.com/t/send-data-stream-to-tts-api/719828#post_3</guid>
      <pubDate>Wed, 17 Apr 2024 02:56:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 ChatGPT 是否也会改变您的词汇量？</title>
      <link>https://community.openai.com/t/does-using-chatgpt-change-your-vocabulary-too/712892?page=2#post_31</link>
      <description><![CDATA[我担心比人工智能用自己的垃圾内容训练人工智能更糟糕的事情。更糟糕的是，人类正在接受人工智能垃圾内容的“训练”，这是大量人工智能生成内容的结果，而不是可能性。
无论怎样，这两个都是控制论在行动中的伟大、独特和有趣的例子，在我们眼前上演。
展望未来，随着实现社会所需的“基线”生产力所需的工时数量继续被技术所削减，人类将在理想的小说美学上进行越来越多的竞争，而我将大部分写作放在一边在那里，有时甚至是干技术的东西。
奇怪的是，我认为人工智能有点剥夺了许多作家的权利——也就是说，可能我们大多数人都不擅长写作，应该把它留给那些真正受到启发的人，这基本上就是我的目的。正如 @davir 上面所说，大量的人类写作似乎是
&lt;块引用&gt;
由一个已经弄清楚如何玩弄小说写作系统的人编写

所以我的观点是，随着人工智能能力继续铲除低级写作形式的杂草，写作将（逐渐地）变得对人类极具竞争力。]]></description>
      <guid>https://community.openai.com/t/does-using-chatgpt-change-your-vocabulary-too/712892?page=2#post_31</guid>
      <pubDate>Wed, 17 Apr 2024 02:55:45 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入模型时，为什么要询问普通模型而不是嵌入模型？</title>
      <link>https://community.openai.com/t/when-using-embedding-models-why-to-ask-normal-models-instead-of-embedding-ones/719794#post_2</link>
      <description><![CDATA[您似乎正在使用 client.chat.completions.create
要使用嵌入模型，需要按如下方式使用嵌入模型：
client.embeddings.create(
  模型=“文本嵌入-ada-002”，
  输入=查询，
  编码格式=“浮动”
）

https://platform. openai.com/docs/api-reference/embeddings/create]]></description>
      <guid>https://community.openai.com/t/when-using-embedding-models-why-to-ask-normal-models-instead-of-embedding-ones/719794#post_2</guid>
      <pubDate>Wed, 17 Apr 2024 02:51:01 GMT</pubDate>
    </item>
    <item>
      <title>发送数据流到TTS API</title>
      <link>https://community.openai.com/t/send-data-stream-to-tts-api/719828#post_2</link>
      <description><![CDATA[没有“同时”，除非你自己在人工智能输出上一次解析一个句子，然后发送每个句子进行转录。如果是流式传输，它将通过智能识别正在构建的内容来识别可以说出完整部分的点，直到句子长度的片段完整表达想法，获取音频，并保留文本显示直到第一个块做完了。然后缓冲之后继续的内容。
我能看到将语音可靠地同步到记录以进行实时显示（达到说出单词时着色的级别）的唯一方法是发送到耳语以进行时间索引，并以文本形式播放记录与时间戳相同的显示速率。]]></description>
      <guid>https://community.openai.com/t/send-data-stream-to-tts-api/719828#post_2</guid>
      <pubDate>Wed, 17 Apr 2024 02:34:43 GMT</pubDate>
    </item>
    <item>
      <title>Assistant x Chatgpt API 质量（PDF 阅读）</title>
      <link>https://community.openai.com/t/assistant-x-chatgpt-api-quality-pdf-reading/719859#post_1</link>
      <description><![CDATA[我在 Chatgpt 中设置训练提示来运行 Assistant API 以从 PDF 中提取数据，但不幸的是，我感到惊讶的是，在 Chatgpt 中完美运行的算法在 Assistant 中却没有正确的答案。
有人对更改配置有任何建议吗？我在 gpt-4-turbo 上运行助手，在 gpt-4 上运行 chatgpt。谢了]]></description>
      <guid>https://community.openai.com/t/assistant-x-chatgpt-api-quality-pdf-reading/719859#post_1</guid>
      <pubDate>Wed, 17 Apr 2024 02:32:41 GMT</pubDate>
    </item>
    <item>
      <title>Udio：来自 Nvidia 的新音乐生成器 text2audio？</title>
      <link>https://community.openai.com/t/udio-new-music-generator-text2audio-from-nvidia/711354#post_11</link>
      <description><![CDATA[当他们开放 API 时，有人知道任何事情吗？]]></description>
      <guid>https://community.openai.com/t/udio-new-music-generator-text2audio-from-nvidia/711354#post_11</guid>
      <pubDate>Wed, 17 Apr 2024 02:26:55 GMT</pubDate>
    </item>
    </channel>
</rss>