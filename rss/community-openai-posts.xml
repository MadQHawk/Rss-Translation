<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Wed, 08 May 2024 15:20:02 GMT</lastBuildDate>
    <item>
      <title>努力使用 GPT-3.5 将书籍元数据从文本转换为完整的 JSON 数组——寻求建议！</title>
      <link>https://community.openai.com/t/struggling-to-convert-book-metadata-from-text-to-complete-json-array-using-gpt-3-5-seeking-advice/726515#post_5</link>
      <description><![CDATA[您可以尝试以下方法：要使用 GPT-3.5 将图书元数据从文本转换为 JSON 数组，请按照以下简单步骤操作。首先，确保有关书籍的所有信息（例如书名、作者、ISBN 和其他详细信息）书写一致且清晰。您可以使用特殊标记（如“—”）分隔每本书的详细信息。接下来，您需要创建一个提示来告诉 GPT-3.5 到底要做什么。您的提示应该指示 GPT-3.5 读取书籍详细信息并将其转换为称为 JSON 数组的结构化列表，其中每本书的详细信息以计算机可以轻松理解的格式整齐地组织。
要执行此操作，如果您正在编码，则可以使用 OpenAI API，将提示发送到 GPT-3.5 并要求其处理文本。 GPT-3.5 返回 JSON 数组后，检查以确保所有书籍详细信息的格式正确。您可能需要稍微调整提示或修复文本中描述书籍的方式以获得最佳结果。通过这种方式，您可以将书籍详细信息列表转换为简洁的 JSON 数组，可在数据库、网站或任何处理数据的应用程序中使用。]]></description>
      <guid>https://community.openai.com/t/struggling-to-convert-book-metadata-from-text-to-complete-json-array-using-gpt-3-5-seeking-advice/726515#post_5</guid>
      <pubDate>Wed, 08 May 2024 15:17:25 GMT</pubDate>
    </item>
    <item>
      <title>功能请求：基于文件夹的 ChatGPT 对话组织</title>
      <link>https://community.openai.com/t/feature-request-folder-based-organization-for-chatgpt-conversations/672115#post_20</link>
      <description><![CDATA[+1 专门为了这个功能请求来到这里。我对 ChatGPT 最大的抱怨是无法轻松找到之前的聊天记录。文件夹和文本搜索会很有用。我想补充一点，使用新的“内存”功能，最好将其存储到一个文件夹中，以防止上下文交叉污染，例如对于彼此无关的各种项目（甚至可能在自定义 GTP 中，但是这是另一个话题了）]]></description>
      <guid>https://community.openai.com/t/feature-request-folder-based-organization-for-chatgpt-conversations/672115#post_20</guid>
      <pubDate>Wed, 08 May 2024 15:15:23 GMT</pubDate>
    </item>
    <item>
      <title>模拟研究 - 通过模拟收集数据</title>
      <link>https://community.openai.com/t/simulation-studies-data-collection-via-simulation/739908#post_1</link>
      <description><![CDATA[附件是本文的数据图像 - 更容易阅读:)。我已将此文本“作为文本”包含在内以用于搜索目的。也许将来可以做一个人工智能搜索工具来搜索图像的文本内容。还包括其所依据的模拟 II 理论的详细文本。
&lt;小时/&gt;
我首先想说，我是一名哲学家，这个提议是通过哲学得出的。它试图提出一种新的训练数据收集方法。该方法涉及创建足够粒度 (Ğ)/分辨率的模拟，然后使用高度调整的初始条件运行该模拟，以生成结果系统 strong&gt; 所需的数据现象显现的地方。
我知道这说起来容易做起来难，但我相信凭借今天和未来的技术，它实际上可以实现。在最大的规模上，从更哲学的角度来说，这种方法可以用来创建对太阳系及其他太阳系中所有合理相关现象的模拟，并有足够的硬件和设计实现。在较小的范围内，它可以轻松地用于绘制给定语言中的数千个单词。
此方法还可以处理任何知识产权声明，因为模拟仅从初始条件就得出了此类创作。然而，我不是法律专业人士，这给我们带来了一个边界问题，即如何在模拟中处理 IP，尤其是生成的 IP - 不是从训练数据生成的，而是使用物理和宇宙定律从初始参数生成的。

]]></description>
      <guid>https://community.openai.com/t/simulation-studies-data-collection-via-simulation/739908#post_1</guid>
      <pubDate>Wed, 08 May 2024 15:14:59 GMT</pubDate>
    </item>
    <item>
      <title>错误 异常活动 GPT4 WEB</title>
      <link>https://community.openai.com/t/error-unusual-activity-gpt4-web/736901#post_3</link>
      <description><![CDATA[我是 ChatGPT Pro 用户，也收到了同样的消息。当我尝试重新生成提示时，我还收到此消息“您的设备检测到异常活动。稍后再试。 （880a555898eb77a8-LHR）”
我现在经常收到这个  ]]></description>
      <guid>https://community.openai.com/t/error-unusual-activity-gpt4-web/736901#post_3</guid>
      <pubDate>Wed, 08 May 2024 15:10:49 GMT</pubDate>
    </item>
    <item>
      <title>现在，通过 Chat Completions API 或 Completions API 使用流式传输时可以使用使用情况统计信息</title>
      <link>https://community.openai.com/t/usage-stats-now-available-when-using-streaming-with-the-chat-completions-api-or-completions-api/738156#post_11</link>
      <description><![CDATA[微软似乎并没有就路线图进行太多沟通。基本上就是拿走你得到的。]]></description>
      <guid>https://community.openai.com/t/usage-stats-now-available-when-using-streaming-with-the-chat-completions-api-or-completions-api/738156#post_11</guid>
      <pubDate>Wed, 08 May 2024 15:08:07 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt 无法得到回复</title>
      <link>https://community.openai.com/t/chatgpt-could-not-get-a-response/610904?page=3#post_42</link>
      <description><![CDATA[我需要您准备创建 PLN 命令提示符，为我设计我的公司徽标：将人们与商业分区、公寓、住宅、公寓连接起来的房地产。连接我们带您到正确的地方。]]></description>
      <guid>https://community.openai.com/t/chatgpt-could-not-get-a-response/610904?page=3#post_42</guid>
      <pubDate>Wed, 08 May 2024 14:58:05 GMT</pubDate>
    </item>
    <item>
      <title>Assistants v2：当通过API将温度设置为0时，创建的助手的温度为1</title>
      <link>https://community.openai.com/t/assistants-v2-when-setting-the-temperature-to-0-through-the-api-the-assistant-is-created-with-a-temperature-of-1/739886#post_1</link>
      <description><![CDATA[如果我将温度设置为 0，则默认为 1。但是，任何其他数字都可以；例如，将温度设置为 0.0001 将创建一个温度为 0.0001 的助手
client = openai.OpenAI(api_key=OPENAI_API_KEY)
client.beta.assistants.create(
  name=“我的助理”，
  说明=“我的说明”，
  工具=[{&quot;type&quot;:&quot;code_interpreter&quot;}],
  型号=“gpt-3.5-turbo-1106”，
  温度=0
）

&lt;img alt=&quot;图像&quot; height=&quot;96&quot; src=&quot;https://global.discourse-cdn.com/openai1/original/4X/e/a/5/ea5a250160c9ca97a183ff6ff936b0c6e06d181e.png&quot; width=&quot;433 ” /&gt;]]></description>
      <guid>https://community.openai.com/t/assistants-v2-when-setting-the-temperature-to-0-through-the-api-the-assistant-is-created-with-a-temperature-of-1/739886#post_1</guid>
      <pubDate>Wed, 08 May 2024 14:54:32 GMT</pubDate>
    </item>
    <item>
      <title>GPT 4 限制为 20 条消息</title>
      <link>https://community.openai.com/t/gpt-4-limited-to-20-messages/739885#post_1</link>
      <description><![CDATA[过去几天我一直在使用 GPT 4，上次检查时我应该每 3 小时收到 40 条消息，但我发现最多只能收到 20 条消息，这非常令人沮丧，是吗？错误还是有我错过的更新？谢谢！]]></description>
      <guid>https://community.openai.com/t/gpt-4-limited-to-20-messages/739885#post_1</guid>
      <pubDate>Wed, 08 May 2024 14:54:26 GMT</pubDate>
    </item>
    <item>
      <title>现在，通过 Chat Completions API 或 Completions API 使用流式传输时可以使用使用情况统计信息</title>
      <link>https://community.openai.com/t/usage-stats-now-available-when-using-streaming-with-the-chat-completions-api-or-completions-api/738156#post_10</link>
      <description><![CDATA[@nimobeeren 我想 Azure OpenAI 上的 Assistants API v2 也是如此。当他们计划支持最新的 OpenAI 功能时，他们不会告诉社区吗？]]></description>
      <guid>https://community.openai.com/t/usage-stats-now-available-when-using-streaming-with-the-chat-completions-api-or-completions-api/738156#post_10</guid>
      <pubDate>Wed, 08 May 2024 14:52:37 GMT</pubDate>
    </item>
    </channel>
</rss>