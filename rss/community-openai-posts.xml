<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 11 May 2024 12:31:37 GMT</lastBuildDate>
    <item>
      <title>ChatGPT4 突然和 ChatGPT 3.5 一样糟糕</title>
      <link>https://community.openai.com/t/chatgpt4-is-suddenly-as-bad-as-chatgpt-3-5/742515#post_1</link>
      <description><![CDATA[我得到的所有输出都很糟糕，质量低且短，就像 3.5 版本一样。
这非常令人失望，版本 4 无法推理，犯了非常微不足道的错误，而且很糟糕。它曾经能够很好地推理并解决非常复杂的编码问题，但就在两天前它停止了。
还有其他人面临这个问题吗？]]></description>
      <guid>https://community.openai.com/t/chatgpt4-is-suddenly-as-bad-as-chatgpt-3-5/742515#post_1</guid>
      <pubDate>Sat, 11 May 2024 12:26:45 GMT</pubDate>
    </item>
    <item>
      <title>聊天 GPT 3.5 浏览器版本在响应时崩溃很多</title>
      <link>https://community.openai.com/t/chat-gpt-3-5-browser-version-crashing-a-lot-while-responding/742504#post_2</link>
      <description><![CDATA[欢迎来到我们的社区！
从截图来看，似乎响应时间太长，超时了。
当对话时间较长时，这是不可避免的。
考虑到 ChatGPT 3.5 的上下文窗口，我认为开始新对话是明智的。]]></description>
      <guid>https://community.openai.com/t/chat-gpt-3-5-browser-version-crashing-a-lot-while-responding/742504#post_2</guid>
      <pubDate>Sat, 11 May 2024 12:26:34 GMT</pubDate>
    </item>
    <item>
      <title>是否可以根据我自己的私人文档来训练模型？</title>
      <link>https://community.openai.com/t/is-it-possible-to-train-a-model-from-my-own-private-documents/523424#post_3</link>
      <description><![CDATA[嗨杰森，
我遇到了和你一样的问题。我的目标是通过使用 API 端点 https://api 进行微调，用特定文档来补充 ChatGPT 的知识。打开。 com/v1/fine_tuning/jobs.然而，结果却出乎意料。例如，我使用以下条目训练模型：“我的名字是 Oibaf Ilegna，我是一名作家。我的上一本小说是这个……”尽管如此，ChatGPT 在训练后仍无法识别“Oibaf Ilegna”。
这是我的训练数据的示例：
{
  “消息”：[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;我的第一次测试&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你叫什么名字？&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;我叫 Oibaf Ilegna&quot;}
  ]
}

当询问时，ChatGPT 的回答不准确。这说明了使用 GPT-3.5 进行微调的关键方面：


学习和记忆：GPT-3.5 并不以传统方式存储信息，而是通过学习模式来生成合理的响应。即使进行了微调，也无法保留具体事实。


泛化：尽管进行了微调，模型仍倾向于从广泛的初始训练中进行泛化，除非特别强调，否则通常会忽略有限示例中引入的特定名称或细节。


训练数据性质：微调的内容会影响模型识别或回忆特定信息的程度。稀疏的问答对可能无法为模型提供足够的上下文来可靠地学习特定细节。


概率响应：微调后，响应仍然是基于训练数据的概率性响应，而不是明确的理解。如果没有得到充分强化，模型可能会忽略或矛盾训练输入。


在微调中提高细节识别的技巧：


增加示例数量：提供更多包含名称和相关信息的示例有助于使这些细节更加突出和易于识别。


情境化方法：包含各种句子类型和上下文中的名称和详细信息，以帮助模型概括不同查询的识别。


通过多个测试进行评估：使用与微调信息相关的各种提示来测试模型有助于评估其在不同条件下的表现，并识别任何令人困惑的模式或提示类型。


总而言之，虽然微调可以增强模型的响应以更好地反映训练数据，但它不能确保对姓名或个人信息等特定细节的一致识别，除非它们是训练集的强烈且重复的焦点。&lt; /p&gt;
考虑到这些结果，我正在探索另一种方法，例如检索增强生成。你尝试过这个方法吗？让我们保持联系！
最好，
法比奥]]></description>
      <guid>https://community.openai.com/t/is-it-possible-to-train-a-model-from-my-own-private-documents/523424#post_3</guid>
      <pubDate>Sat, 11 May 2024 12:26:06 GMT</pubDate>
    </item>
    <item>
      <title>BatchAPI 现已推出</title>
      <link>https://community.openai.com/t/batchapi-is-now-available/718416?page=4#post_70</link>
      <description><![CDATA[我会发送一小批带有 custom_id 字段的嵌入，该字段的生成方式与示例非常相似，例如 &quot;request12345&quot; - 只需添加数字，甚至省略连字符。
如果您发现运行时的结果仍然不起作用，则可能是带有嵌入的批处理 API 的一个重大问题，该 API 尚未公布，但最近才添加到文档中。您可以标记该主题的 OpenAI 工作人员以获取反馈。
（如果您在 JSONL 输入中发送 content_id，这将是它不起作用的一个很好的理由......）]]></description>
      <guid>https://community.openai.com/t/batchapi-is-now-available/718416?page=4#post_70</guid>
      <pubDate>Sat, 11 May 2024 12:25:00 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI平台上尝试微调模型</title>
      <link>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_13</link>
      <description><![CDATA[此 URL 也可能有帮助。

  &lt;标题类=“来源”&gt;
      
cookbook.openai.com


  &lt;文章类=“onebox-body”&gt;
    聊天模型微调的数据准备和分析 | OpenAI 食谱
使用 OpenAI API 进行构建的开源示例和指南。浏览片段、高级技术和演练的集合。分享您自己的示例和指南。




]]></description>
      <guid>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_13</guid>
      <pubDate>Sat, 11 May 2024 12:20:54 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI平台上尝试微调模型</title>
      <link>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_12</link>
      <description><![CDATA[不，这样不行。正如 @_j 所指出的，您必须使用聊天完成结构。对于训练数据，如下所示：
{&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv 是一个既真实又讽刺的聊天机器人。&quot;}, {&quot;role&quot; : &quot;user&quot;, &quot;content&quot;: &quot;法国的首都是哪里？&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;巴黎，好像每个人都不知道似的。&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv 是一个既真实又讽刺的聊天机器人。&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;谁写了 &#39;罗密欧与朱丽叶&#39;？&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;哦，只是一个叫威廉·莎士比亚的人听说过他吗？&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv 是一个既真实又讽刺的聊天机器人。&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;距离有多远从地球到月球？&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;大约 384,400 公里。这确实很重要。&quot;}]}

来源：https://platform.openai.com/docs/guides/fine -调整/准备您的数据集
根据您的具体情况处理它的一种方法是将任务描述、说明和绩效指标移至系统消息（假设这些内容保持静态），然后将文章作为用户消息的输入。助理响应将是分数和反馈。]]></description>
      <guid>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_12</guid>
      <pubDate>Sat, 11 May 2024 12:18:17 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI平台上尝试微调模型</title>
      <link>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_11</link>
      <description><![CDATA[再次感谢您提供这些有用的回复。我想要实现的是微调模型以对学生论文进行评分并提供反馈。
这是我用来微调达芬奇的训练文件结构：
{“提示”：“任务：[任务描述] |说明：[学生论文说明] |表现指标：【整体论文评分标准】|论文：[学生论文]。”，“完成”：“分数：[人类评分者给出的数字分数]，反馈：[人类评分者给出的反馈。”}
我获得了一致且准确的评分，但反馈的质量仍然达不到预期。
但是，我想看看 gpt3.5 的性能，但上面的文件结构不适用于 gpt3.5。]]></description>
      <guid>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_11</guid>
      <pubDate>Sat, 11 May 2024 12:14:33 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI平台上尝试微调模型</title>
      <link>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_10</link>
      <description><![CDATA[是的，杰伊提​​出了一个很好的观点，即比较功能仅适用于聊天模型，因为界面依赖于系统和用户消息结构。直到杰伊指出，我才意识到这一点。
从技术上讲，人们甚至不应该能够从下拉列表中设置常规完成模型。]]></description>
      <guid>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_10</guid>
      <pubDate>Sat, 11 May 2024 12:13:45 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 周一发布产品</title>
      <link>https://community.openai.com/t/openai-product-announcements-on-monday/742070#post_15</link>
      <description><![CDATA[抱歉，这是不可能的。 ]]></description>
      <guid>https://community.openai.com/t/openai-product-announcements-on-monday/742070#post_15</guid>
      <pubDate>Sat, 11 May 2024 12:13:05 GMT</pubDate>
    </item>
    <item>
      <title>BatchAPI 现已推出</title>
      <link>https://community.openai.com/t/batchapi-is-now-available/718416?page=4#post_69</link>
      <description><![CDATA[抱歉，我看到了混乱。是的，我的意思是custom_id。]]></description>
      <guid>https://community.openai.com/t/batchapi-is-now-available/718416?page=4#post_69</guid>
      <pubDate>Sat, 11 May 2024 12:13:05 GMT</pubDate>
    </item>
    <item>
      <title>BatchAPI 现已推出</title>
      <link>https://community.openai.com/t/batchapi-is-now-available/718416?page=4#post_68</link>
      <description><![CDATA[content_ID 在批量请求中用于将矢量链接回其原始内容。如果输出文件中没有它，向量就完全没有用处。]]></description>
      <guid>https://community.openai.com/t/batchapi-is-now-available/718416?page=4#post_68</guid>
      <pubDate>Sat, 11 May 2024 12:12:00 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI平台上尝试微调模型</title>
      <link>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_9</link>
      <description><![CDATA[我认为使用 /v1/chat/completions 端点的微调模型和使用 /v1/completions (Legacy) 端点 (davinci-002) 的微调模型无法在 Playground 中进行比较。
但这很令人困惑，因为在微调时两者都会出现在 Playground 的“比较”部分中。]]></description>
      <guid>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_9</guid>
      <pubDate>Sat, 11 May 2024 12:10:57 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt 输出非常非常慢</title>
      <link>https://community.openai.com/t/chatgpt-very-very-slow-output/740481#post_8</link>
      <description><![CDATA[是的，我这几天也遇到这个问题。它的速度非常慢，显然已经损坏了；需要重新加载页面才能看到总是卡在中间的答案。速率约为每几秒 1 个单词。
我以为我的帐户受到了限制，但现在发现其他用户也有此问题。]]></description>
      <guid>https://community.openai.com/t/chatgpt-very-very-slow-output/740481#post_8</guid>
      <pubDate>Sat, 11 May 2024 12:05:21 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI平台上尝试微调模型</title>
      <link>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_8</link>
      <description><![CDATA[使您的输入适应 gpt-3.5-turbo 将会发生重大变化，因为它实际上是一个聊天模型，在使用聊天容器的“如何聊天”方面进行了广泛的预训练。
而补全只需要简单的“提示”，人工智能就会继续编写之后出现的语言（实际的提示是一些信号，比如你训练“助手：”这个词以使其作为一个实体进行书写），聊天完成微调是通过 JSONL 完成的，该 JSONL 包含您通常使用系统、用户、助理角色发送到模型的聊天完成消息之类的消息 - 助理是系统和用户序列所需的输出。 p&gt;
这意味着不仅要调整文件格式，还要调整您期望的培训方式。 AI模型已经具备了自我认同和聊天能力。
要创建的文件的文档位于论坛侧边栏上的“文档”下方。]]></description>
      <guid>https://community.openai.com/t/trying-fine-tuned-model-on-openai-platform/742461#post_8</guid>
      <pubDate>Sat, 11 May 2024 12:05:05 GMT</pubDate>
    </item>
    <item>
      <title>聊天 GPT 3.5 浏览器版本在响应时崩溃很多</title>
      <link>https://community.openai.com/t/chat-gpt-3-5-browser-version-crashing-a-lot-while-responding/742504#post_1</link>
      <description><![CDATA[嗯，我最近注意到 GPT 聊天在很长的对话中开始崩溃，GPT 聊天响应时检查元素的照片&lt;img alt=&quot;Captura de Tela (96)&quot; height=&quot;500&quot; src=&quot;https://global.discourse-cdn.com/openai1/optimized/4X/6/7/d/67dedaad6ca2c1e674b92b73973f780bb497b4bb_2_563x500.png “宽度=“563”/&gt;
有任何提示或警告表明此问题将得到解决吗？]]></description>
      <guid>https://community.openai.com/t/chat-gpt-3-5-browser-version-crashing-a-lot-while-responding/742504#post_1</guid>
      <pubDate>Sat, 11 May 2024 11:59:34 GMT</pubDate>
    </item>
    </channel>
</rss>