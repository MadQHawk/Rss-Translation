<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 15 Jul 2024 21:19:53 GMT</lastBuildDate>
    <item>
      <title>询问有关 pdf 的问题，但不将其存储在矢量数据库中</title>
      <link>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_4</link>
      <description><![CDATA[PS：需要澄清的是，我不会使用 Open AI 检索进行 RAG。我将使用 Pinecone 或 Postgresql pgvector 等矢量数据库]]></description>
      <guid>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_4</guid>
      <pubDate>Mon, 15 Jul 2024 21:12:02 GMT</pubDate>
    </item>
    <item>
      <title>我希望我创建的助手不要引用数据库中的文档，因为它通常会添加[来源 10:1]</title>
      <link>https://community.openai.com/t/i-would-like-the-assistant-i-created-not-to-reference-the-document-from-the-database-as-it-usually-adds-a-source-10-1/867372#post_2</link>
      <description><![CDATA[@pethervaz0 - 欢迎来到论坛！

检查数据库如何将内容返回给 LLM，并在将其作为上下文传递以完成运行之前重新格式化。
提示工程师（给出响应应如何显示的示例）并设置适当的 temp 和 top_p 值。
]]></description>
      <guid>https://community.openai.com/t/i-would-like-the-assistant-i-created-not-to-reference-the-document-from-the-database-as-it-usually-adds-a-source-10-1/867372#post_2</guid>
      <pubDate>Mon, 15 Jul 2024 21:08:23 GMT</pubDate>
    </item>
    <item>
      <title>询问有关 pdf 的问题，但不将其存储在矢量数据库中</title>
      <link>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_3</link>
      <description><![CDATA[感谢您的回复！我指的是以下总结策略：

Map Reduce

分块文档。总结每个块，然后总结所有块摘要。
我正在考虑通过将块摘要与向量嵌入和实际文本一起存储在向量数据库中来实现这一点，为我的第一个目标创建嵌入，然后在用户请求特定报告摘要时检索特定文档（在我的情况下是报告）的所有块的摘要，并将所有这些单独的块摘要总结为最终摘要。



我将使用的报告有点长。它们可能长达 90 页，我认为这不适合上下文长度。我不想将用户给定的文件分块并嵌入到矢量数据库中，因为所述报告可能已经存在于矢量数据库中，并且用户可能会在不知情的情况下上传文档，但我不想重复该条目，所以有没有更好的方法？]]></description>
      <guid>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_3</guid>
      <pubDate>Mon, 15 Jul 2024 21:05:30 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT Android 应用无法识别我的订阅</title>
      <link>https://community.openai.com/t/chatgpt-android-app-does-not-recognize-my-subscription/852021#post_4</link>
      <description><![CDATA[这里有新闻吗？同样的问题]]></description>
      <guid>https://community.openai.com/t/chatgpt-android-app-does-not-recognize-my-subscription/852021#post_4</guid>
      <pubDate>Mon, 15 Jul 2024 20:59:09 GMT</pubDate>
    </item>
    <item>
      <title>询问有关 pdf 的问题，但不将其存储在矢量数据库中</title>
      <link>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_2</link>
      <description><![CDATA[如果您正在使用助手，您可以在消息级别附加文件，然后在对话结束时丢弃线程。
我不确定您所说的 map Reduce 文档以对其进行总结是什么意思。您可以在文档上运行 GPT 来提炼它们。
如果文件太大，则会将其分块并嵌入到向量存储中。否则，完整内容将作为上下文插入。如果令牌长度不足，对话将被截断。不是上下文（我相信，可能需要验证这一点）]]></description>
      <guid>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_2</guid>
      <pubDate>Mon, 15 Jul 2024 20:44:25 GMT</pubDate>
    </item>
    <item>
      <title>我可以在哪里找到 GPT 的测试用户</title>
      <link>https://community.openai.com/t/is-there-any-place-i-can-find-some-beta-users-for-my-gpts/759890#post_22</link>
      <description><![CDATA[我们绝对应该互相测试并提供反馈，也许这样才能启动社区！或者我们可以为 GPT Launches 请求一个单独的类别，类似于 Hacker News 的 ShowHN 帖子。类似 ShowGPT 的东西，您可以在这个论坛上启动！]]></description>
      <guid>https://community.openai.com/t/is-there-any-place-i-can-find-some-beta-users-for-my-gpts/759890#post_22</guid>
      <pubDate>Mon, 15 Jul 2024 20:28:46 GMT</pubDate>
    </item>
    <item>
      <title>询问有关 pdf 的问题，但不将其存储在矢量数据库中</title>
      <link>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_1</link>
      <description><![CDATA[大家好！
我正在尝试构建一个有三个目标的聊天机器人：
1) 回答有关特定领域数据（财务报告）的问题。我正在使用 RAG 来实现这一点。
2) 总结已经分块并嵌入矢量数据库的文档（财务报告）。
3) 上传用户选择的文件并提出问题以从该文件中获得答案。
我的问题：
我已经做了研究，能够理解如何实现第一个目标。对于第二个目标，我正在考虑使用 map Reduce 技术，因为矢量数据库已经为第一个目标做好了准备。这是唯一的方法还是有更好的方法？对于第三个目标 - 我不想将用户提供的文件存储到矢量数据库中。我希望该文件仅用于该对话，之后丢弃，而不实际存储在任何地方。这怎么可能呢？这是否就像读取文件并从中提取文本，然后将该文本发送到模型，用于该对话中的每个查询（包括后续查询）？如果文件很大并且占据了上下文限制的近 90%，该怎么办？如果是这种情况，那么如果上下文限制用尽，是否只有一种方法可以截断后续问题的先前消息？此外，如果文件太大而无法放入上下文窗口怎么办？]]></description>
      <guid>https://community.openai.com/t/ask-questions-about-a-pdf-without-storing-it-in-vector-database/867502#post_1</guid>
      <pubDate>Mon, 15 Jul 2024 20:22:51 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt iOS 应用程序“登录失败”</title>
      <link>https://community.openai.com/t/chatgpt-ios-app-sign-in-failed/693270#post_12</link>
      <description><![CDATA[我在 Android 14 上遇到了同样的问题。]]></description>
      <guid>https://community.openai.com/t/chatgpt-ios-app-sign-in-failed/693270#post_12</guid>
      <pubDate>Mon, 15 Jul 2024 20:20:18 GMT</pubDate>
    </item>
    <item>
      <title>我昨天被另一个人工智能骗了</title>
      <link>https://community.openai.com/t/i-was-scammed-yesterday-by-another-ai/774914#post_8</link>
      <description><![CDATA[我也遇到过同样的情况，我取消了自动续订，尝试申请退款，但我不知道如何在那个网站上删除我的付款方式，希望他们不会做坏事。]]></description>
      <guid>https://community.openai.com/t/i-was-scammed-yesterday-by-another-ai/774914#post_8</guid>
      <pubDate>Mon, 15 Jul 2024 20:09:57 GMT</pubDate>
    </item>
    <item>
      <title>DALLE3 提示和技巧主题</title>
      <link>https://community.openai.com/t/dalle3-prompt-tips-and-tricks-thread/498040?page=5#post_102</link>
      <description><![CDATA[一只类似青蛙的生物用长舌头舔着自己的脸，作者：@_j
我喜欢它。我应该使用什么提示才能可靠地获得黑白般的报纸般的感觉？
  ]]></description>
      <guid>https://community.openai.com/t/dalle3-prompt-tips-and-tricks-thread/498040?page=5#post_102</guid>
      <pubDate>Mon, 15 Jul 2024 20:07:31 GMT</pubDate>
    </item>
    <item>
      <title>耳语幻觉-如何识别和解决？</title>
      <link>https://community.openai.com/t/whisper-hallucination-how-to-recognize-and-solve/218307?page=2#post_26</link>
      <description><![CDATA[有人能解释一下‘no_speech_prob’属性是如何像这样合并到代码中的吗：
from openai import OpenAI
client = OpenAI()

audio_file= open(&quot;/path/to/file/audio.mp3&quot;, &quot;rb&quot;)
transcription = client.audio.transcriptions.create(
model=&quot;whisper-1&quot;, 
file=audio_file
)
print(transcription.text)

谢谢…]]></description>
      <guid>https://community.openai.com/t/whisper-hallucination-how-to-recognize-and-solve/218307?page=2#post_26</guid>
      <pubDate>Mon, 15 Jul 2024 20:05:15 GMT</pubDate>
    </item>
    <item>
      <title>从 GPT-4 到 ChatGPT-3 的自定义指令转换问题</title>
      <link>https://community.openai.com/t/issues-with-custom-instructions-transition-from-gpt-4-to-chatgpt-3/867250#post_5</link>
      <description><![CDATA[再次问候 Tina。确实很好的回答，谢谢。好吧，我一年多前就已经这样做了，提示的最大效果取决于可以使用的字母。4o 和 3 以类似的方式响应，因为它们需要遵循“个性模拟/语音模式”，因此很容易弄清楚何时重置以及为什么重置，因为输出变化很大，但远比“默认模式”好。如果您愿意，我可以向您发送一个提示，您可以尝试一下。]]></description>
      <guid>https://community.openai.com/t/issues-with-custom-instructions-transition-from-gpt-4-to-chatgpt-3/867250#post_5</guid>
      <pubDate>Mon, 15 Jul 2024 19:30:34 GMT</pubDate>
    </item>
    <item>
      <title>如何避免 Whisper 转录中出现幻觉？</title>
      <link>https://community.openai.com/t/how-to-avoid-hallucinations-in-whisper-transcriptions/125300?page=2#post_32</link>
      <description><![CDATA[提示看起来很棒。所以我尝试了有和没有你的提示的录音。我在本地使用 Python 中的 whisper-timestamped 库来使用 whisper/medium。
def transcribe(language, file_path):
import whisper_timestamped as wt
audio = wt.load_audio(file_path)
model = wt.load_model(&quot;medium&quot;, device=&quot;cuda&quot;)
result = wt.transcribe(model, audio, language=language, initial_prompt=&quot;大家好。我要大声朗读这本书。如果我听起来有点呃……有点闷热或鼻塞，我深表歉意。我还没有从感冒中恢复过来。我可能会时不时清嗓子……*咳咳*。”)
return result

没有您的提示：
{‘text’: &quot; 嗨，也许我们可以做这样的事情，也许不能，我们必须找出答案。好吧，也许我们必须找出答案。我们会找出答案的。事情就是这样的。砰，哔，砰，20 秒即将到来。&quot;&gt;
有您的提示：
{‘text’: &quot; 嗨。所以嗯……也许……也许我们可以做这样的事情。也许不能。我们必须找出答案。好吧，也许……也许我们必须找出答案。我们会找出答案的。就是这样。砰。哔。砰。20 秒。它来了。”

你能展示一下你调用私语端点的代码吗？]]></description>
      <guid>https://community.openai.com/t/how-to-avoid-hallucinations-in-whisper-transcriptions/125300?page=2#post_32</guid>
      <pubDate>Mon, 15 Jul 2024 19:24:21 GMT</pubDate>
    </item>
    <item>
      <title>搜索文件时对向量存储选项感到困惑</title>
      <link>https://community.openai.com/t/confusion-with-the-vector-storage-option-when-searching-for-files/721083?page=2#post_36</link>
      <description><![CDATA[我也对这个问题感到困惑。创建向量存储并将其链接到线程/助手与上传文件并将其直接链接到线程消息之间有什么区别？
我的用例是每个用户都有自己的线程，他们上传图像/文件以供 AI 帮助他们阅读/总结等。
为什么我应该使用向量存储，而不是简单地上传文件并将其附加到线程上的消息？
任何帮助都值得赞赏！]]></description>
      <guid>https://community.openai.com/t/confusion-with-the-vector-storage-option-when-searching-for-files/721083?page=2#post_36</guid>
      <pubDate>Mon, 15 Jul 2024 19:13:52 GMT</pubDate>
    </item>
    <item>
      <title>功能请求：置顶/收藏聊天</title>
      <link>https://community.openai.com/t/feature-request-pinning-favoriting-chats/459137#post_8</link>
      <description><![CDATA[对此 +1。一般对话管理功能会更好。但 Pin 功能可以满足我大约 80% 的需求。]]></description>
      <guid>https://community.openai.com/t/feature-request-pinning-favoriting-chats/459137#post_8</guid>
      <pubDate>Mon, 15 Jul 2024 19:08:47 GMT</pubDate>
    </item>
    </channel>
</rss>