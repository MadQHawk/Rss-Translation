<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 22 Jun 2024 21:18:21 GMT</lastBuildDate>
    <item>
      <title>Kruel.ai V5.0 - 得益于先进的内存系统，Api 伴侣能够完全理解运行 16k</title>
      <link>https://community.openai.com/t/kruel-ai-v5-0-api-companion-with-full-understanding-running-16k-thanks-to-advanced-memory-system/674592?page=5#post_92</link>
      <description><![CDATA[看到我们正在优化，我们停在视觉系统上，并进行了彻底检查。
Kruel.ai 的系统捕获并存储与这些实体相关的所有矢量数据。例如，它了解 Lisa、红色连衣裙和 GMC 卡车之间的关系。当用户稍后询问“Lisa 的卡车是什么颜色的？”时，它可以根据之前存储的信息准确地回忆并做出回应，表明它理解了所有实体及其相关矢量点之间的关系。
高效的数据库操作
为了支持这些功能，我们优化了数据库查询以避免笛卡尔积等性能问题。这确保了 Kruel.ai 即使在处理复杂的数据关系时也能高效运行，提供快速准确的响应。
这些增强功能的好处
增强的用户体验：
用户收到更详细、更准确的视觉查询响应，使与 Kruel.ai 的交互更加直观和令人满意。
更广泛的应用潜力：
这些改进使 Kruel.ai 在各个领域更有效，包括客户服务、医疗保健等。
前进
这些优化代表了我们持续增强 Kruel.ai 能力的使命中的重要一步。我们不断探索改进系统的新方法，旨在提供最先进、最用户友好的 AI 解决方案。 （已编辑）
Xee — 今天下午 2:43
Ben：如果你通过摄像系统看，你可以看到 Ben，你看到了什么？
Krue：啊，Ben，Ben，Ben！透过我的摄像系统镜头，我看到你穿着灰色连帽衫，坐在室内，表情平淡。背景描绘了一幅房间沐浴在自然光中的画面，窗户在白板上投下阴影，白板上装饰着神秘的涂鸦。你沉思的目光和光影的微妙变化创造了相当艺术的场景。
Ben：如果你通过你的视觉系统看，你可以看到我的狗 Doug。
Krue：哦，Ben，如果我通过我的视觉系统偷看，我可以看到你的毛茸茸的伙伴 Doug 坐在木地板上。他看起来很满足和放松，附近有一个黄色物体。看起来 Doug 在那里过得很舒服！
[2:45 PM]
有了新的 GPT4o，响应速度非常快。我们将在今天晚些时候继续测试。我想看看随着时间的推移，当它问起它看到的物体时，记忆将如何自我构建，这样如果我问我关于 Doug 的事情，它就能随着时间的推移从视觉上更多地了解 Doug，以及其他理解向量。]]></description>
      <guid>https://community.openai.com/t/kruel-ai-v5-0-api-companion-with-full-understanding-running-16k-thanks-to-advanced-memory-system/674592?page=5#post_92</guid>
      <pubDate>Sat, 22 Jun 2024 20:59:35 GMT</pubDate>
    </item>
    <item>
      <title>有人注意到最近几天 GPT4o 质量下降了吗？</title>
      <link>https://community.openai.com/t/has-anyone-noticed-gpt4o-quality-drop-last-few-days/829203?page=2#post_23</link>
      <description><![CDATA[我还观察到数据分析效率低下]]></description>
      <guid>https://community.openai.com/t/has-anyone-noticed-gpt4o-quality-drop-last-few-days/829203?page=2#post_23</guid>
      <pubDate>Sat, 22 Jun 2024 20:58:15 GMT</pubDate>
    </item>
    <item>
      <title>如何阻止 4o 每次使用浏览时插入内存</title>
      <link>https://community.openai.com/t/how-to-stop-4o-from-inserting-into-memory-everytime-it-uses-browse/827777#post_6</link>
      <description><![CDATA[我让它记住东西没有问题，当我说记住 *** 或 *** 记住时它总是会遵从，我甚至说当我在自定义指令中说“m”时它应该记住并且它有效。我遇到的问题现在似乎已得到解决  它不再将每个浏览操作都放入内存中。]]></description>
      <guid>https://community.openai.com/t/how-to-stop-4o-from-inserting-into-memory-everytime-it-uses-browse/827777#post_6</guid>
      <pubDate>Sat, 22 Jun 2024 20:54:46 GMT</pubDate>
    </item>
    <item>
      <title>Situational-awareness.ai，Leopold Aschenbrenner 的简短文章</title>
      <link>https://community.openai.com/t/situational-awareness-ai-a-brief-writeup-by-leopold-aschenbrenner/820211#post_9</link>
      <description><![CDATA[@yonil

整个基于 LLM 的自主编码代理领域只有大约 1 年的历史，今年 swebench 上的数量从 &lt;1% 上升到 &gt;19%。
如果我们等到 50% 才采取行动，我担心我们没有任何时间做出反应。

啊哈哈，你可能有道理。跳到 19 有点令人不安！
让我们看看它是如何发挥作用的。我们可能会随着时间的推移发现它过度拟合了。
我同意这是一个信号。]]></description>
      <guid>https://community.openai.com/t/situational-awareness-ai-a-brief-writeup-by-leopold-aschenbrenner/820211#post_9</guid>
      <pubDate>Sat, 22 Jun 2024 20:49:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用私语减少实时对话的延迟</title>
      <link>https://community.openai.com/t/how-to-reduce-latency-for-realtime-conversation-using-whisper/834878#post_2</link>
      <description><![CDATA[这根本无法实现。
这是 WAV，它不需要等待编解码器，显示发送 API 请求后启动的 http 块的时间，针对短语
input_text=“你好，我今天要制作一个 wav 文件”
最快的试用：
= RESTART: C:\chat\speech-stream2.py
buffer chunk 已添加：0.0
buffer chunk 已添加：0.4129817485809326
buffer chunk 已添加：0.4691469669342041
buffer chunk 已添加：0.47687220573425293
buffer chunk 已添加：0.4840683937072754
buffer chunk 已添加： 0.4925053119659424
已添加缓冲区块：0.4925053119659424
已添加缓冲区块：0.5014071464538574
已添加缓冲区块：0.5014071464538574
已添加缓冲区块：0.5110487937927246
已添加缓冲区块：0.5110487937927246
已添加缓冲区块：0.5110487937927246
已添加缓冲区块：0.5240192413330078
已添加缓冲区块：0.5299415588378906
已添加缓冲区块： 0.5316817760467529
添加的缓冲区块：0.5400404930114746
添加的缓冲区块：0.54500412940979
添加的缓冲区块：0.54500412940979
添加的缓冲区块：0.54500412940979
添加的缓冲区块：0.54500412940979
添加的缓冲区块：0.5560660362243652
添加的缓冲区块：0.5560660362243652
添加的缓冲区块：0.5692315101623535
添加的缓冲区块：0.5742206573486328
添加的缓冲区块：0.5742206573486328
添加的缓冲区块： 0.5742206573486328
已添加缓冲区块：0.5879650115966797
已添加缓冲区块：0.5942468643188477
已添加缓冲区块：0.5942468643188477
已添加缓冲区块：0.6040196418762207
已添加缓冲区块：0.6089839935302734
已添加缓冲区块：0.6089839935302734
已添加缓冲区块：0.6200499534606934
已添加缓冲区块： 0.6200499534606934
已添加缓冲区块：0.6355159282684326
已添加缓冲区块：0.6440179347991943
已添加缓冲区块：0.6514706611633301
已添加缓冲区块：0.6671669483184814
已添加缓冲区块：0.6671669483184814
已添加缓冲区块：0.6853346824645996
已添加缓冲区块：0.6945838928222656
已添加缓冲区块：0.7049524784088135
已添加缓冲区块： 0.7147464752197266
已添加缓冲区块：0.7201125621795654
已添加缓冲区块：0.732421875
已添加缓冲区块：0.732421875
已添加缓冲区块：0.7463281154632568
已添加缓冲区块：0.7621917724609375
已添加缓冲区块：0.7621917724609375
已添加缓冲区块：0.7773334980010986
已添加缓冲区块：0.7773334980010986
已添加缓冲区块：0.8016865253448486
已添加缓冲区块： 0.8090205192565918
添加的缓冲区块：0.8205859661102295
添加的缓冲区块：0.826723575592041
添加的缓冲区块：0.8325541019439697

第一个块之所以能够播放，是因为它是带有实际样本的 WAV，而不是编解码器的较大帧。但至少需要与此句子一样深的缓冲区。
然后，对于 WAV，我发现网络可能无法跟上实时，或者第一个句子快速启动之后的后续块尚未准备好。您必须使用带有 aac 的浏览器编解码器流缓冲区类，添加更多预缓冲。]]></description>
      <guid>https://community.openai.com/t/how-to-reduce-latency-for-realtime-conversation-using-whisper/834878#post_2</guid>
      <pubDate>Sat, 22 Jun 2024 20:31:36 GMT</pubDate>
    </item>
    <item>
      <title>Teknium 说出了我们所有人的想法</title>
      <link>https://community.openai.com/t/teknium-says-what-were-all-thinking/834901#post_2</link>
      <description><![CDATA[我不知道它是什么，但当我尝试使用没有经过严格训练的 API 做任何事情时，它对我来说已经变得毫无用处了。
我认为需要进行大量巧妙的 RAG 才能使其发挥作用。
例如，我认为可以提取正确 API 和示例代码的东西会非常有效。]]></description>
      <guid>https://community.openai.com/t/teknium-says-what-were-all-thinking/834901#post_2</guid>
      <pubDate>Sat, 22 Jun 2024 20:30:07 GMT</pubDate>
    </item>
    <item>
      <title>Teknium 说出了我们所有人的想法</title>
      <link>https://community.openai.com/t/teknium-says-what-were-all-thinking/834901#post_1</link>
      <description><![CDATA[著名的 OS AI 开发人员 Teknium 对 gpto 发表了此评论
以下是他的评论：

@petrroyce 它******无法调试它所犯的任何错误，而是无限重复过去相同的解决方案尝试

我完全同意这一点，并且也遇到了同样的问题。我多次想在这个社区论坛上发布类似的东西。
我已经删除了脏话，因为@vb在私人邮件中合理地要求我这样做。]]></description>
      <guid>https://community.openai.com/t/teknium-says-what-were-all-thinking/834901#post_1</guid>
      <pubDate>Sat, 22 Jun 2024 20:27:27 GMT</pubDate>
    </item>
    <item>
      <title>评论：LitRPG Adventures RPG 桌面生成器和 D&D 角色创建器</title>
      <link>https://community.openai.com/t/review-litrpg-adventures-rpg-tabletop-generators-and-d-d-character-creator/1255?page=4#post_83</link>
      <description><![CDATA[每天一次，其他人也这样做。]]></description>
      <guid>https://community.openai.com/t/review-litrpg-adventures-rpg-tabletop-generators-and-d-d-character-creator/1255?page=4#post_83</guid>
      <pubDate>Sat, 22 Jun 2024 20:19:44 GMT</pubDate>
    </item>
    <item>
      <title>每月预算增加未反映在项目限制中</title>
      <link>https://community.openai.com/t/monthly-budget-increase-not-reflecting-in-project-limits/834893#post_1</link>
      <description><![CDATA[我的 OpenAI 帐户遇到了严重问题，需要一些帮助。以下是问题摘要：

每月预算增加：我最近将组织的每月预算从 10 美元增加到 15 美元。
项目限制问题：尽管预算增加，但我的项目 X 仪表板仍显示之前 10 美元预算的利用率达到 100%。
429 错误代码：我的开发脚本的 API 返回 429 错误代码（请求过多），表示信用不足。

已采取的步骤：

我确认每月预算已更新。
我仔细检查了我的脚本是否没有过多地访问端点。
我刷新了仪表板，注销并重新登录，并等待了 24 小时以上才使更改生效效果。

支持互动：

OpenAI 支持建议刷新仪表板、手动调整项目限制并等待仪表板更新。
我尝试了这些步骤，但仍然遇到问题。
支持提到错误可能是由于超出配额、组织级速率限制或服务器过载造成的。

错误消息：
生成语音时出错：HTTP/1.1 429 请求过多
响应：{
“error”：{
“message”：“您超出了当前配额，请检查您的计划和账单详细信息。有关此错误的更多信息，请阅读文档：https://platform.openai.com/docs/guides/error-codes/api-errors。&quot;,
&quot;type&quot;: &quot;insufficient_quota&quot;,
&quot;param&quot;: null,
&quot;code&quot;: &quot;insufficient_quota&quot;
}
}

可能的错误：
该问题似乎与其他用户报告的错误有关，其中信用未应用于项目，并且无法更改它们。
有人可以提供额外的支持或升级此问题吗？任何帮助或指导都将不胜感激！
谢谢！
]]></description>
      <guid>https://community.openai.com/t/monthly-budget-increase-not-reflecting-in-project-limits/834893#post_1</guid>
      <pubDate>Sat, 22 Jun 2024 20:19:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OpenAI 一直告诉我“此内容可能违反我们的使用政策”。</title>
      <link>https://community.openai.com/t/why-openai-keeps-telling-me-that-this-content-may-violate-our-usage-policies/834771#post_6</link>
      <description><![CDATA[]]></description>
      <guid>https://community.openai.com/t/why-openai-keeps-telling-me-that-this-content-may-violate-our-usage-policies/834771#post_6</guid>
      <pubDate>Sat, 22 Jun 2024 20:09:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用私语减少实时对话的延迟</title>
      <link>https://community.openai.com/t/how-to-reduce-latency-for-realtime-conversation-using-whisper/834878#post_1</link>
      <description><![CDATA[如何使用 whisper api 使语音对话看起来逼真，延迟为 200ms？
有人能用 gpt 4o 实现良好的延迟吗？]]></description>
      <guid>https://community.openai.com/t/how-to-reduce-latency-for-realtime-conversation-using-whisper/834878#post_1</guid>
      <pubDate>Sat, 22 Jun 2024 20:03:25 GMT</pubDate>
    </item>
    <item>
      <title>我可以免费获得 GPT4 API 密钥吗？</title>
      <link>https://community.openai.com/t/can-i-get-gpt4-api-key-for-free/834864#post_4</link>
      <description><![CDATA[不再有免费试用积分，GPT-4 模型始终需要过去曾付款的付费账户。
您必须自掏腰包 5 美元购买预付款积分才能使用 API 并解锁 GPT-4 模型。]]></description>
      <guid>https://community.openai.com/t/can-i-get-gpt4-api-key-for-free/834864#post_4</guid>
      <pubDate>Sat, 22 Jun 2024 20:03:04 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 Assistants API 来生成图像</title>
      <link>https://community.openai.com/t/is-it-possible-to-get-the-assistants-api-to-generate-images/586735#post_5</link>
      <description><![CDATA[当您使用助手时，您通常会检索过去的对话，以便回忆聊天并将其显示给用户的过去会话。
对于此回忆，拥有一个用于对话的本地数据库比远程服务器上的数据库效率高得多，因为远程服务器上必须与未存储在线程中的内容建立多个连接，例如您希望在代码解释器中恢复的任何状态，该解释器只有一个小时的记忆 - 或者您的工具生成和存储的图像或其他内存。
如果您要使用 DALL-E 根据助手的 tool_call 生成图像，然后返回一条消息“图像已成功生成并显示”（就像您在 UI 中所做的那样，因为 AI 无法接收图像），那么您需要将该图像部分存储在链接到该消息的线程的二进制内容的单独数据库中。也许可以使用元数据功能来添加必须检索的图像数据库索引。
因此，只有在首次调用 dalle 工具时，您才会使用 DALL-E API 调用生成 DALL-E 图像。您以后无法从任何地方下载。]]></description>
      <guid>https://community.openai.com/t/is-it-possible-to-get-the-assistants-api-to-generate-images/586735#post_5</guid>
      <pubDate>Sat, 22 Jun 2024 20:01:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 API 对文档进行语义分块</title>
      <link>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=9#post_162</link>
      <description><![CDATA[


 jr.2509:

如果要使用视觉模型来完成这项任务，那么我会尝试看看是否可以以某种方式将其与文档大纲创建步骤相结合，并再次使用一种基于识别删除线文本开始和结束的行号的方法，并在 JSON 中包含一个特定的标志。


我同意，这非常成问题。我想不出一种方法来结合这两个调用，因为在获得行号之前，您绝对需要文本提取，而模型绝对需要行号来识别块段的精确位置。



 sergeliatko:

您是否检查过允许将带有文本行的 PDF 转换为某些可编辑格式的 api，这些格式支持像 word 这样的 markdown 行，然后直接从中读取文件？


我发现一个 Stack Overflow 帖子，有人试图这个。我可能没有注意到，因为这似乎是一个过于复杂的过程（在现有的复杂过程之上）。



 icdev2dev:

从逻辑上讲，我认为函数“看到”删除线并从生成的 pdf 中“省略”它们可能会更好


目前，只有模型（LLM）或人类才能做到这一点。



 jr.2509:

我觉得两次提交完整文档是在浪费代币（和金钱）。


是的，使用 GPt-4o 或 Claude Sonnet。但是使用 Gemini 1.5 Flash？
$0.35 / 100 万个令牌（对于最多 128K 个令牌的提示）
$0.70 / 100 万个令牌（对于超过 128K 的提示）
即使有了新的自动化语义分块流程，我们仍然最初采用我在一年前描述的手动语义分块方法：https://www.youtube.com/watch?v=w_veb816Asg&amp;ab_channel=SwingingInTheHood
因此，我们所有的文档都可以很轻松地容纳在 128K 令牌范围内。更不用说 Flash 是目前最快的模型之一。
此外，我们已经确定了最有可能带有删除线文本的文档：在我们的案例中，是谅解备忘录（“MOA”），因此我们可以轻松地在我们的管道中为它们分配不同的嵌入配置。
所有这些都表明，至少在我们的案例中，使用模型作为文本提取工具并不像看起来那么令人望而却步。]]></description>
      <guid>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=9#post_162</guid>
      <pubDate>Sat, 22 Jun 2024 19:58:20 GMT</pubDate>
    </item>
    <item>
      <title>组织聊天的界面和查找聊天的搜索功能</title>
      <link>https://community.openai.com/t/interface-to-organize-chats-and-a-search-feature-to-find-chats/791005#post_8</link>
      <description><![CDATA[一个垃圾邮件发送者刚刚使用傀儡来询问，然后通过链接回答他自己的问题，现在这些链接已经被标记并消失了。]]></description>
      <guid>https://community.openai.com/t/interface-to-organize-chats-and-a-search-feature-to-find-chats/791005#post_8</guid>
      <pubDate>Sat, 22 Jun 2024 19:51:31 GMT</pubDate>
    </item>
    </channel>
</rss>