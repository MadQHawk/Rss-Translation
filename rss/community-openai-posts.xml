<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Fri, 19 Apr 2024 06:24:29 GMT</lastBuildDate>
    <item>
      <title>应该如何编写程序来使用 API 来总结长文本？关于允许的最大令牌数有哪些注意事项？</title>
      <link>https://community.openai.com/t/how-should-a-program-be-written-to-summarize-a-long-text-using-an-api-and-what-are-the-considerations-regarding-the-maximum-number-of-tokens-allowed/722010#post_1</link>
      <description><![CDATA[大家好，


我有一篇大约 10,000 个 token 的长原文，我想根据我的指南使用 GPT 助手 API 对其进行总结。您能推荐一些可能对此有所帮助的示例程序吗？


另外，关于长文本的输入，我了解 GPT-4 的上下文限制是 128K 个令牌，但每个输入/输出的限制只有 4096 个令牌，对吗？
说明和角色内容是否包含在此 4096 个令牌限制中？


assistant = client.beta.assistants.create(
  name=&quot;数据可视化工具&quot;,
  description=&quot;您擅长创建漂亮的数据可视化。您分析 .csv 文件中的数据，了解趋势，并提出与这些趋势相关的数据可视化。您还分享观察到的趋势的简短文本摘要。&quot;,
  型号=“gpt-4-turbo”，
  工具=[{&quot;type&quot;:&quot;code_interpreter&quot;}],
  工具资源={
    “代码解释器”：{
      &quot;file_ids&quot;: [文件.id]
    }
  }


我正在考虑的一种方法是将长文本分成多个片段，让 GPT 记住每个片段，然后根据最后的指南生成摘要。
然而，这种方法可能会导致生成误导性或不连贯的内容。
另一种方法是单独处理每个部分，在每个输入开始时提示根据指南进行总结，逐渐构建全面的摘要。

哪种方法更有效，或者有更好的选择吗？
致以诚挚的问候；]]></description>
      <guid>https://community.openai.com/t/how-should-a-program-be-written-to-summarize-a-long-text-using-an-api-and-what-are-the-considerations-regarding-the-maximum-number-of-tokens-allowed/722010#post_1</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>一个疯狂的想法还是可行的：可节省 30% 转录成本的技术</title>
      <link>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_7</link>
      <description><![CDATA[实际上这是一个好主意 - 将加速率保留为可选的可调节参数，假设在 0 到 2 之间，并注释它可能会影响转录的质量。]]></description>
      <guid>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_7</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 gpt-4 API 对文档进行语义分块</title>
      <link>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=2#post_37</link>
      <description><![CDATA[不，因为我担心 @Securigy 在这里提到：使用 gpt-4 API 对文档进行语义分块 - #24 安全]]></description>
      <guid>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=2#post_37</guid>
      <pubDate>Fri, 19 Apr 2024 06:16:05 GMT</pubDate>
    </item>
    <item>
      <title>无法再次启动计费计划</title>
      <link>https://community.openai.com/t/cannot-start-billing-plan-again/721941#post_3</link>
      <description><![CDATA[关于您的未结发票：贷方余额不能用于支付过去的发票。您必须存档有效的信用卡才能确保这些发票得到付款。]]></description>
      <guid>https://community.openai.com/t/cannot-start-billing-plan-again/721941#post_3</guid>
      <pubDate>Fri, 19 Apr 2024 06:14:05 GMT</pubDate>
    </item>
    <item>
      <title>Gpt-4-turbo 不回答有关 AI 模型的问题</title>
      <link>https://community.openai.com/t/gpt-4-turbo-doesnt-respond-questions-on-ai-models/722004#post_2</link>
      <description><![CDATA[嗨@arun.rebala，
您的 API 或模型参数肯定有问题。我已经尝试过你的提示并查看结果。 IngestAI.io 使用（显然）API 并且模型确实响应您提供的查询。

还有一件事 - 我认为使用 Presence_penalty: 0.5 和Frequency_penalty: 0.3 惩罚不是一个好主意，如果这不是你真正关心的事情，因为你正在构建模型以使用不太合适的标记（可能）。]]></description>
      <guid>https://community.openai.com/t/gpt-4-turbo-doesnt-respond-questions-on-ai-models/722004#post_2</guid>
      <pubDate>Fri, 19 Apr 2024 06:12:02 GMT</pubDate>
    </item>
    <item>
      <title>新的 GPT-4 Turbo 模型何时会迁移到 Microsoft Azure OpenAI API？</title>
      <link>https://community.openai.com/t/when-will-the-new-gpt-4-turbo-model-move-to-microsoft-azure-openai-api/721794#post_2</link>
      <description><![CDATA[同意了解这一点很有用。
无论如何，我相信以下两页是这方面更新的关键页面：

  &lt;标题类=“来源”&gt;

      learn.microsoft.com


  &lt;文章类=“onebox-body”&gt;
    Azure OpenAI 服务模型 - Azure OpenAI
了解 Azure OpenAI 提供的不同模型功能。






  &lt;标题类=“来源”&gt;

      learn.microsoft.com


  &lt;文章类=“onebox-body”&gt;
    Azure OpenAI 的新增功能服务？ - Azure人工智能服务
了解 Azure OpenAI 的最新新闻和功能更新。




]]></description>
      <guid>https://community.openai.com/t/when-will-the-new-gpt-4-turbo-model-move-to-microsoft-azure-openai-api/721794#post_2</guid>
      <pubDate>Fri, 19 Apr 2024 06:10:36 GMT</pubDate>
    </item>
    <item>
      <title>一个疯狂的想法还是可行的：可节省 30% 转录成本的技术</title>
      <link>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_6</link>
      <description><![CDATA[是的，为什么不呢？
人们可以添加一项功能来降低成本，并向用户提供准确性可能会下降的信息。
一个奇特的解决方案是有一个滑块来调整音频的加速程度以及静音程度。
在安静的环境中工作是此类功能的一个可能用例。]]></description>
      <guid>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_6</guid>
      <pubDate>Fri, 19 Apr 2024 06:08:58 GMT</pubDate>
    </item>
    <item>
      <title>一个疯狂的想法还是可行的：可节省 30% 转录成本的技术</title>
      <link>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_5</link>
      <description><![CDATA[非常感谢。最大的问题是了解 1.2 倍、1.5 倍和 2 倍实际上如何影响质量 (WER)。但我认为，即使通过应用 1.1x 消除 10% 的静音也能节省 20% - 这对于中型和大型联络中心来说是巨大的。]]></description>
      <guid>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_5</guid>
      <pubDate>Fri, 19 Apr 2024 06:05:51 GMT</pubDate>
    </item>
    <item>
      <title>Gpt-4-turbo 不回答有关 AI 模型的问题</title>
      <link>https://community.openai.com/t/gpt-4-turbo-doesnt-respond-questions-on-ai-models/722004#post_1</link>
      <description><![CDATA[我注意到使用 API 调用的 GPT 模型 3.5 或 4 不会回答有关 AI 模型的问题，而与 chat.openai 一样，我可以得到答案。
一个简单的问题，比如“流行的人工智能模型是什么？”或“什么是机器学习？”，不会引起响应。
我使用以下查询：
const 响应 = 等待 openai.chat.completions.create({
型号：“gpt-4-turbo”，
消息：消息，
存在惩罚：0.5，
频率惩罚：0.3，
最大令牌数：300，
工具：工具
});
我可以清楚地得到一般主题的答案。]]></description>
      <guid>https://community.openai.com/t/gpt-4-turbo-doesnt-respond-questions-on-ai-models/722004#post_1</guid>
      <pubDate>Fri, 19 Apr 2024 06:05:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 gpt-4 API 对文档进行语义分块</title>
      <link>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=2#post_36</link>
      <description><![CDATA[您是否考虑过使用 SpaCy Sentencizer 来创建句子的索引词典？]]></description>
      <guid>https://community.openai.com/t/using-gpt-4-api-to-semantically-chunk-documents/715689?page=2#post_36</guid>
      <pubDate>Fri, 19 Apr 2024 06:03:44 GMT</pubDate>
    </item>
    <item>
      <title>错误：嗯...似乎出了问题</title>
      <link>https://community.openai.com/t/error-hmm-something-seems-to-have-gone-wrong/609088#post_7</link>
      <description><![CDATA[我也有同样的问题。 chatgpt4 说“嗯……似乎出了点问题。”并且chatgpt3.5正在运行。
我从另一个线程中读到，您可以先将图像上传到新聊天室。然后你就可以开始聊天了。它可以工作，但在开始新聊天时继续上传图像很麻烦。]]></description>
      <guid>https://community.openai.com/t/error-hmm-something-seems-to-have-gone-wrong/609088#post_7</guid>
      <pubDate>Fri, 19 Apr 2024 06:01:13 GMT</pubDate>
    </item>
    <item>
      <title>嗯...似乎出了问题 - 错误</title>
      <link>https://community.openai.com/t/hmm-something-seems-to-have-gone-wrong-error/721937#post_2</link>
      <description><![CDATA[同样。 Chatgpt4 说似乎出了问题。 Chatgpt3.5 可以工作。我从其他一些评论中读到，如果我先上传图像，那么 chatgpt4 就会对图像发表评论，然后你就可以与它聊天。这可行，但在开始新聊天时继续上传图像效率不高。]]></description>
      <guid>https://community.openai.com/t/hmm-something-seems-to-have-gone-wrong-error/721937#post_2</guid>
      <pubDate>Fri, 19 Apr 2024 05:59:13 GMT</pubDate>
    </item>
    <item>
      <title>按回车键不再提交</title>
      <link>https://community.openai.com/t/pressing-enter-no-longer-submits/52333?page=2#post_39</link>
      <description><![CDATA[来到这里是因为我遇到了同样烦人的问题，只要侧边栏隐藏，Enter就无法工作（我认为，每当浏览器的尺寸是屏幕大小的一半时，就会发生这种情况）。
WIN + ALT + Enter 似乎有效，并且是迄今为止最简单/最快的解决方案，至少对我来说！当然，TM/alt 脚本也应该可以工作。 （：
感谢您@mhyoo1分享此内容！]]></description>
      <guid>https://community.openai.com/t/pressing-enter-no-longer-submits/52333?page=2#post_39</guid>
      <pubDate>Fri, 19 Apr 2024 05:57:17 GMT</pubDate>
    </item>
    <item>
      <title>一个疯狂的想法还是可行的：可节省 30% 转录成本的技术</title>
      <link>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_4</link>
      <description><![CDATA[如果您还没有看到它：为了节省成本而加速文件的想法已在 今年早些时候的这个帖子。
结论如下：




Whisper - 不透明收费？ API

  &lt;块引用&gt;
    我测试了您提供的 2 倍加速文件用于转录，我可以确认 API 仅在加速文件的持续时间内计费（四舍五入到最接近的秒）。
以下是原始文件的详细信息：

文件类型：MP3
持续时间：60.10 秒
采样率：48000 Hz
通道：1（单声道）
比特率：128.069 kbps

加速文件具有以下内容：

文件类型：MP3
持续时间：30.05秒
采样率：48000 Hz
通道：1（单声道）
比特率：64.088 kbps

您提供的 2 倍加速文件...
  
]]></description>
      <guid>https://community.openai.com/t/a-crazy-idea-or-its-feasible-technique-that-saves-30-on-transcribe-costs/721722#post_4</guid>
      <pubDate>Fri, 19 Apr 2024 05:55:00 GMT</pubDate>
    </item>
    <item>
      <title>.js 文件上出现 404，也许这就是为什么提示从 11 小时前就不再发送了？！</title>
      <link>https://community.openai.com/t/404-on-a-js-file-maybe-this-is-why-prompts-never-send-anymore-since-11-hours-ago/721989#post_1</link>
      <description><![CDATA[在 Linux 上使用 Firefox 的桌面上访问 chat[.]openai[.]com 网站与 chatgpt 3.5 进行对话，因为大约 11 小时前，提示停止发送，并且出现一个动画灰色轮子，而不是发送消息图标（这是一个向上箭头图标），同时消息仍在编辑框中（未清除）。这永远不会完成。不过，它在移动设备上的 Chrome 中运行良好。
不久之后，我在查看旧聊天时注意到一个明显的新功能：一个扬声器图标出现在带有工具提示“大声朗读”的响应旁边，因此，我猜测这只是作为一项新功能推出，同时在某些情况下（例如我的）中断了提示的发送。
查看请求，我看到这个是 404：
https://cdn[.]oaistatic[.]com/_next/static/chunks/sso.d74092545a949ef3.js
（它说不能在我的帖子中包含链接）
我希望这就是问题发生的原因，但我不确定。
（因为它是 404，所以看起来响应的 content-type 为 text/plain 以及 x-content-type-options &gt; 设置为 nosniff 并且缺少 access-control-allow-origin，但这只是因为它是 404）
那么，一些开发人员可以解决这个问题吗？除非这个特定的 404 不是一个问题（这似乎不太可能），而事实上问题出在其他地方？ &lt;img alt=&quot;:slight_smile:&quot; class=&quot;emoji&quot; height=&quot;20&quot; src=&quot;https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12&quot; title=&quot;:slight_smile: “宽度=“20”/&gt;
谢谢。]]></description>
      <guid>https://community.openai.com/t/404-on-a-js-file-maybe-this-is-why-prompts-never-send-anymore-since-11-hours-ago/721989#post_1</guid>
      <pubDate>Fri, 19 Apr 2024 05:54:02 GMT</pubDate>
    </item>
    </channel>
</rss>