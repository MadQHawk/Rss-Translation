<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 09 Jul 2024 01:20:39 GMT</lastBuildDate>
    <item>
      <title>测试版设置不再可见，并且我的插件也消失了</title>
      <link>https://community.openai.com/t/beta-settings-are-no-longer-visible-and-my-plugins-have-disappeared/709350#post_3</link>
      <description><![CDATA[@grandell1234 grandell1234
我刚刚为 ChatGPT 4 付费的唯一原因是为了插件功能，因为谷歌上的每个视频都使用 canva 等宣传此功能，我是否根本无法继续使用此功能？如果不能，那么您认为我可以拿回我刚刚购买的会员资格的钱吗？
如果它不再起作用，他们应该在客户购买之前向他们说明这一点]]></description>
      <guid>https://community.openai.com/t/beta-settings-are-no-longer-visible-and-my-plugins-have-disappeared/709350#post_3</guid>
      <pubDate>Tue, 09 Jul 2024 01:18:56 GMT</pubDate>
    </item>
    <item>
      <title>我对 azure-search-documents 的官方版本支持感到困扰。</title>
      <link>https://community.openai.com/t/im-having-trouble-with-the-official-version-support-of-azure-search-documents/859392#post_1</link>
      <description><![CDATA[我正在尝试创建一个程序来使用 Python 访问 Azure AI Search。去年，
我使用了 azure-search-documents 的测试版，但现在我无法让它与正式版正常工作。
def withdraw_relevant_documents(emb_deployment: str, search_client: SearchClient, search_query: str) -&gt; str:
response = client.embeddings.create(model=emb_deployment, input=search_query)

query_vector = [
VectorizedQuery(
kind=&quot;vector&quot;, vector=response.data[0].embedding, k_nearest_neighbors=3, fields=&quot;embedding&quot;
)
]
print(query_vector)

results = search_client.search(
search_text=&quot;&quot;,
vector_queries=[query_vector],
)

results_list = [r for r in results]
content = [r[&quot;filename&quot;] + &quot;-&quot; + r[&quot;chunk&quot;] + &quot;: &quot; +
replace_newlines(r[&quot;content&quot;]) for r in results_list]
return &quot;\n&quot;.join(contents)

当我打印“VectorizedQuery()”返回的“query_vector”时，它会给出以下输出。
有人可以建议吗我该如何修改它？
[&lt;azure.search.documents._generated.models._models_py3.VectorizedQuery object at 0x7f841f30d4b0&gt;]
]]></description>
      <guid>https://community.openai.com/t/im-having-trouble-with-the-official-version-support-of-azure-search-documents/859392#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 01:14:39 GMT</pubDate>
    </item>
    <item>
      <title>通话模式限制很多</title>
      <link>https://community.openai.com/t/call-mode-is-limiting-a-lot/859387#post_1</link>
      <description><![CDATA[嘿，我是 chatgpt4o 的新手，我想尝试新的通话模式，在这种模式下，你可以免提使用 chatgpt 进行通话，当我停下来思考这句话时，它会获取条目并在 3 小时内使用我的 50 次，所以我不能在通话中停留那么长时间，因为条目有限且条目冷却时间（当你停止说话 2 秒或更长时间时，它就会输入你的条目）]]></description>
      <guid>https://community.openai.com/t/call-mode-is-limiting-a-lot/859387#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 01:12:23 GMT</pubDate>
    </item>
    <item>
      <title>助理 抱歉，出了点问题</title>
      <link>https://community.openai.com/t/assistant-sorry-something-went-wrong/859094#post_3</link>
      <description><![CDATA[我一直在查看 Vector Store，我现在很确定这就是问题所在。
当您上传文件时，它会创建一个临时的 Vector Store，我认为这个临时的 Vector Store 有时需要很长时间才能进行索引。
我一直在轮询文件上传，直到它的状态为“已处理”，但看起来并没有考虑到正在索引的 Vector Store。
我的解决方案现在似乎有效，希望是先上传文件，然后创建我自己的矢量存储并将该文件添加到其中，然后轮询新的矢量存储直到其状态 =“已完成”
然后继续并将文件 ID 添加到线程。
完成后，删除文件和矢量存储。]]></description>
      <guid>https://community.openai.com/t/assistant-sorry-something-went-wrong/859094#post_3</guid>
      <pubDate>Tue, 09 Jul 2024 00:54:39 GMT</pubDate>
    </item>
    <item>
      <title>目前 ChatGPT API 输出的数学公式非常差，这么久了还是没人优化或者解决这个问题？</title>
      <link>https://community.openai.com/t/the-mathematical-formulas-output-by-the-current-chatgpt-api-are-very-poor-it-has-been-a-long-time-and-still-no-one-has-optimized-or-resolved-this-issue/859375#post_2</link>
      <description><![CDATA[（帖子已被作者删除）]]></description>
      <guid>https://community.openai.com/t/the-mathematical-formulas-output-by-the-current-chatgpt-api-are-very-poor-it-has-been-a-long-time-and-still-no-one-has-optimized-or-resolved-this-issue/859375#post_2</guid>
      <pubDate>Tue, 09 Jul 2024 00:52:52 GMT</pubDate>
    </item>
    <item>
      <title>目前 ChatGPT API 输出的数学公式非常差，这么久了还是没人优化或者解决这个问题？</title>
      <link>https://community.openai.com/t/the-mathematical-formulas-output-by-the-current-chatgpt-api-are-very-poor-it-has-been-a-long-time-and-still-no-one-has-optimized-or-resolved-this-issue/859375#post_1</link>
      <description><![CDATA[
如果 OpenAI 返回的 markdown 内容无法通过 markdown-it 成功解析，欢迎您在 OpenAI 社区论坛中分享。

感谢您的回复，但目前仅使用 markdown-it 恐怕无法充分可视化数学等特殊信息。即使使用 markdown-it 的所有扩展，ChatGPT API 返回的数学公式也不是标准格式。
以下程序在今年早些时候运行良好。
import MarkdownIt from &quot;markdown-it&quot;;
import mdKatex from &quot;@vscode/markdown-it-katex&quot;;
import mdKbd from &quot;markdown-it-kbd&quot;;
import mdHighlight from &quot;markdown-it-highlightjs&quot;;

function onMarkdown(content: any){
const markdown = MarkdownIt();
markdown.use(mdKatex);
markdown.use(mdKbd);
markdown.use(mdHighlight);
markdown.use(codePlugin);
markdown.use(imagePlugin);
return markdown.render(content, {});
}

我必须在所有对话中包含以下提示，以便 ChatGPT API 正确返回 markdown-it 可解析格式。
处理数学公式时，请使用 $...$ 括住公式，而不是 [...]。

以下是错误的对话示例。

当然可以！以下是使用 LaTeX 构建矩阵并求解特征值和特征向量的分步指南：

1. 构建矩阵：
我们以创建一个 2x2 矩阵为例：
\[ A = \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 3 \end{pmatrix} \]

2. 求特征方程：
特征方程由以下公式给出：
\[ \text{det}(A - \lambda I) = 0 \]
将 A 代入方程：
\[ \text{det}\left( \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 3 \end{pmatrix} - \lambda \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix} \right) = 0 \]

3. 求特征值：
展开行列式并求 λ：
\[ \text{det}\left( \begin{pmatrix} 2-\lambda &amp; 1 \\ 1 &amp; 3-\lambda \end{pmatrix} \right) = 0 \]
\[ (2-\lambda)(3-\lambda) - 1 = 0 \]
\[ \lambda^2 - 5\lambda + 5 = 0 \]
\[ \lambda = \frac{5 \pm \sqrt{5}}{2} \]

4. 求解特征向量：
将特征值代回 (A - λI)x = 0 并求解 x。对于每个特征值，您将得到一个相应的特征向量。

希望这能帮助您使用 LaTeX 构建矩阵并求解特征值和特征向量！如果您需要进一步的帮助，请告诉我。

上述 markdown 内容无法在标准 markdown-it 中正确解析。前段时间我在社区里提过这个问题，他们建议我在这里问，社区里很多大人都提过这个问题，目前大部分的解决方案都比较粗糙和临时。
如果你觉得这方面没必要优化，那么至少要保证API响应的格式正确、标准，至少要兼容主流的开源组件，因为这些都是开发者常用的，毕竟API是收费的，开发者是花钱买的，作为OpenAI仓库的官方维护者，应该努力把这个仓库维护得更好，让开发者受益。]]></description>
      <guid>https://community.openai.com/t/the-mathematical-formulas-output-by-the-current-chatgpt-api-are-very-poor-it-has-been-a-long-time-and-still-no-one-has-optimized-or-resolved-this-issue/859375#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 00:50:27 GMT</pubDate>
    </item>
    <item>
      <title>工具调用——模式重要吗？</title>
      <link>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_4</link>
      <description><![CDATA[是的。
我已经放弃让 openAI 为我们提供几乎所有事情的技术规格（正式语法）。我只是尝试遵循我能找到的任何微不足道的文档，并在其基础上正式化一些自动化。]]></description>
      <guid>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_4</guid>
      <pubDate>Tue, 09 Jul 2024 00:38:47 GMT</pubDate>
    </item>
    <item>
      <title>工具调用——模式重要吗？</title>
      <link>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_3</link>
      <description><![CDATA[首先，因为据我所知没有官方规范，这也是我问这个问题的原因之一。此外，许多库都利用了 Pydantic（例如 Instructor）并将模式按生成的方式传递，而无需修改 - 而且效果非常好。
我不明白你的意思：自省和使用 model_json_schema 是偷懒的方式吗？我想你是说自己使用元编程来构建规范？我的意思是……是的，这是一个选择。]]></description>
      <guid>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_3</guid>
      <pubDate>Tue, 09 Jul 2024 00:35:43 GMT</pubDate>
    </item>
    <item>
      <title>工具调用——模式重要吗？</title>
      <link>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_2</link>
      <description><![CDATA[为什么不尝试遵循规范？
人们总是可以自省函数（而不是 model_json_schema 的“懒惰”方式）
这是我拥有的提取函数之一：
@tools_function(TOOLS_FUNCTIONS)
def get_cost_of_running_a_thread_on_a_model(
provider: Annotated[str, &quot;这是提供模型的提供商，例如 openai/groq。默认为 openai&quot;],
model: Annotated[str, &quot;这是描述中的模型。这通常以 % 为前缀&quot;],
thread: Annotated[str, &quot;这是需要成本的线程。这通常以 !&quot; 为前缀] 
):
&quot;&quot;&quot; 此函数提供在模型上运行线程的成本。由于成本因具有不同 SLAS 的不同提供商而异，因此从中识别提供商非常重要提示。默认提供程序是 openai；
但可能不同，例如 groq、google 等。

如果提供程序是 openai，则默认模型是 gpt-4-turbo。如果提供程序是 groq，则默认模型是 llama3-8b-8192。
否则，如果提供程序是 google，则默认模型是 gemini-it。
&quot;&quot;&quot;
return f&quot;{provider} {model} {thread}&quot;


tools_function 在此处：
def tools_function(tools_functions): 
def wrapper(func):

function = dict()
function[&#39;function&#39;] = func
function[&#39;name&#39;] = func.__name__
function[&#39;description&#39;] = func.__doc__
function[&#39;parameters&#39;] = {}
function[&#39;parameters&#39;][&#39;type&#39;] = &quot;object&quot;
function[&#39;parameters&#39;][&#39;properties&#39;] = {}

input_arg_names = [arg_name for arg_name in func.__code__.co_varnames[:func.__code__.co_argcount]]

for input_arg_name in input_arg_names:
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name] = {}
raw_annotation = func.__annotations__[input_arg_name]

如果 raw_annotation.__origin__.__name__ 在 FUNCTIONS_TYPE_MAP 中：
ip_type = FUNCTIONS_TYPE_MAP[raw_annotation.__origin__.__name__]
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;type&#39;] = ip_type

如果 ip_type == &#39;array&#39;：
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;items&#39;] = {}
ip_item_type = raw_annotation.__origin__.__args__[0].__name__
如果 ip_item_type 在 FUNCTIONS_TYPE_MAP 中：
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;items&#39;][&#39;type&#39;] = FUNCTIONS_TYPE_MAP[ip_item_type]
else:
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;items&#39;][&#39;type&#39;] = ip_item_type

else:
ip_type = raw_annotation.__origin__.__name__
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;type&#39;] = ip_type

函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;type&#39;] = ip_type
函数[&#39;parameters&#39;][&#39;properties&#39;][input_arg_name][&#39;description&#39;] = raw_annotation.__metadata__[0]

tools_functions[func.__name__] = function

return func
return包装器
]]></description>
      <guid>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_2</guid>
      <pubDate>Tue, 09 Jul 2024 00:22:53 GMT</pubDate>
    </item>
    <item>
      <title>请修复移动设备上的数学问题</title>
      <link>https://community.openai.com/t/please-fix-maths-on-mobile/859361#post_2</link>
      <description><![CDATA[附注：尽管我的 gpt mobile 说明是最新的，但我还是不断收到“聊天正在使用旧版本的说明”消息]]></description>
      <guid>https://community.openai.com/t/please-fix-maths-on-mobile/859361#post_2</guid>
      <pubDate>Tue, 09 Jul 2024 00:22:19 GMT</pubDate>
    </item>
    <item>
      <title>请修复移动设备上的数学问题</title>
      <link>https://community.openai.com/t/please-fix-maths-on-mobile/859361#post_1</link>
      <description><![CDATA[
数学解释在移动设备上不起作用，尽管在网络应用程序上运行良好。
我用的是安卓手机。
我不知道还能说些什么才能达到 100 个字符的限制……你好吗？如果你想和人聊天，请给我发消息。]]></description>
      <guid>https://community.openai.com/t/please-fix-maths-on-mobile/859361#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 00:21:18 GMT</pubDate>
    </item>
    <item>
      <title>在 ChatGPT macOS 应用程序 (Sonoma) 上存档所有聊天时出错</title>
      <link>https://community.openai.com/t/error-archiving-all-chats-on-chatgpt-macos-app-sonoma/857719#post_2</link>
      <description><![CDATA[此问题似乎仅出现在适用于 macOS 的 ChatGPT 应用程序的最新版本中，而不会出现在网络版或 iOS 版中。]]></description>
      <guid>https://community.openai.com/t/error-archiving-all-chats-on-chatgpt-macos-app-sonoma/857719#post_2</guid>
      <pubDate>Tue, 09 Jul 2024 00:15:27 GMT</pubDate>
    </item>
    <item>
      <title>工具调用——模式重要吗？</title>
      <link>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_1</link>
      <description><![CDATA[有几篇帖子提到，某些工具（例如 Pydantic）会生成有效的 JSON 模式，该模式与 文档 中显示的示例模式有些相似，但又有所不同。
据我所知，除了文档中的一个示例（如下所示）和指南中的几个示例外，没有提供关于必须如何严格遵循此模式的官方指导。
OpenAI 文档模式示例：
from openai import OpenAI
client = OpenAI()

tools = [
{
&quot;type&quot;: &quot;function&quot;,
&quot;function&quot;: {
&quot;name&quot;: &quot;get_current_weather&quot;,
&quot;description&quot;: &quot;获取给定位置的当前天气&quot;,
&quot;parameters&quot;: {
&quot;type&quot;: &quot;object&quot;,
“properties”：{
“location”：{
“type”：&quot;string&quot;,
“description”：&quot;城市和州，例如加利福尼亚州旧金山&quot;,
},
“unit”：{“type”：&quot;string&quot;, “enum”：[&quot;celsius&quot;, &quot;fahrenheit&quot;]},
},
“required”：[&quot;location&quot;],
},
}
}
]
messages = [{“role”：&quot;user&quot;, “content”：&quot;波士顿今天的天气怎么样？&quot;}]
completion = client.chat.completions.create(
model=&quot;gpt-4o&quot;,
messages=messages,
tools=tools,
tool_choice=&quot;auto&quot;
)

将其与 Pydantic 生成的模式进行对比：
class GetCurrentWeather(BaseModel):
“&quot;&quot;获取给定地区的当前天气位置&quot;&quot;&quot;
位置：str
单位：文字[&quot;celsius&quot;,&quot;farenheit&quot;] | None = None

g = GetCurrentWeather(location=&quot;san francisco&quot;,unit=&#39;farenheit&#39;)
g.model_json_schema()

&gt;&gt;&gt;

{&#39;description&#39;: &#39;获取给定位置的当前天气&#39;,
&#39;properties&#39;: {&#39;location&#39;: {&#39;title&#39;: &#39;Location&#39;, &#39;type&#39;: &#39;string&#39;},
&#39;unit&#39;: {&#39;anyOf&#39;: [{&#39;enum&#39;: [&#39;celsius&#39;, &#39;farenheit&#39;],
&#39;type&#39;: &#39;string&#39;},
{&#39;type&#39;: &#39;null&#39;}],
&#39;default&#39;: None,
&#39;title&#39;: &#39;Unit&#39;}},
&#39;required&#39;: [&#39;location&#39;],
&#39;title&#39;: &#39;GetCurrentWeather&#39;,
&#39;type&#39;: &#39;object&#39;}

结果有一些高级相似之处，但总体而言，结构、嵌套、包含的字段等非常不同。
从经验上看，这很好用，但它本质上是“未记录的”行为，因为文档指定了不同的架构。那么我的问题是 - 是否真的需要特定的模式，或者只需提供有效的 JSON 就足够了，该 JSON 包含与参数、函数名称、描述等相关的字段。
如果需要特定的模式，那么它的完整详细信息记录在哪里（如果有的话），其他模式有效这一事实本质上是“幸运的意外”吗？]]></description>
      <guid>https://community.openai.com/t/tool-calls-does-the-schema-matter/859354#post_1</guid>
      <pubDate>Tue, 09 Jul 2024 00:13:38 GMT</pubDate>
    </item>
    <item>
      <title>如何降低使用 GPT Assistant API 的成本</title>
      <link>https://community.openai.com/t/how-to-reduce-cost-of-using-the-gpt-assistant-api/859274#post_5</link>
      <description><![CDATA[目前，如果您使用 API，OpenAI 会将每个令牌（输入和输出）的成本转嫁给开发人员。使用 API 是向客户提供可扩展价值的唯一可行方法。因此，作为选择为“小”客户提供服务的开发人员，您需要考虑每个令牌的输入和输出，然后弄清楚客户将如何为此付费（以及您如何赚钱）。
最终，客户会为感知价值付费。以最近有人在社区中发布的健身房训练为例。如果客户只想与“代理”快速聊聊他的上臂力量，那么可以采用即用即付模式。聊天最多只能持续三分钟（当然只是一个例子）。这样，从开发人员的角度来看，潜在的责任就受到限制，并且可以拥有完善的商业模式。
当然，对经过身份验证的线程进行计时是一项技术问题。从经济意义上来说，如何完成交易（以一角硬币和四分之一美元硬币为单位）是完全另一回事[即你肯定无法接受那些微观层面的信用卡]。]]></description>
      <guid>https://community.openai.com/t/how-to-reduce-cost-of-using-the-gpt-assistant-api/859274#post_5</guid>
      <pubDate>Tue, 09 Jul 2024 00:04:16 GMT</pubDate>
    </item>
    <item>
      <title>如何降低使用 GPT Assistant API 的成本</title>
      <link>https://community.openai.com/t/how-to-reduce-cost-of-using-the-gpt-assistant-api/859274#post_4</link>
      <description><![CDATA[据我了解，只有使用文件搜索功能时，成本才会开始增加。但是，如果您提供自己的文件搜索功能/RAG，成本是多少？]]></description>
      <guid>https://community.openai.com/t/how-to-reduce-cost-of-using-the-gpt-assistant-api/859274#post_4</guid>
      <pubDate>Mon, 08 Jul 2024 23:45:11 GMT</pubDate>
    </item>
    </channel>
</rss>