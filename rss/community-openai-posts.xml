<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Wed, 24 Apr 2024 03:21:31 GMT</lastBuildDate>
    <item>
      <title>我已经付费并升级到 ChatGPT Team。但无法访问ChatGPT 4。仍在使用ChatGPT 3.5</title>
      <link>https://community.openai.com/t/i-already-paid-and-upgraded-to-chatgpt-team-but-cannot-access-chatgpt-4-still-using-chatgpt-3-5/583703#post_5</link>
      <description><![CDATA[我已经付款并升级到 ChatGPT Team。但无法访问ChatGPT Team，只能访问chatgpt plus。]]></description>
      <guid>https://community.openai.com/t/i-already-paid-and-upgraded-to-chatgpt-team-but-cannot-access-chatgpt-4-still-using-chatgpt-3-5/583703#post_5</guid>
      <pubDate>Wed, 24 Apr 2024 03:20:45 GMT</pubDate>
    </item>
    <item>
      <title>训练了一个小语言模型。有一些问题。报告</title>
      <link>https://community.openai.com/t/trained-a-small-language-model-have-some-questions-report/726131#post_1</link>
      <description><![CDATA[为了加深对大型语言模型 (LLM) 背后的科学和工程的理解，我从头开始训练了一个基于 Transformer 的小型语言模型，然后对其进行了微调
由于我正在自学和实验，我可能会对法学硕士背后的科学和工程实践产生错误的理解。
我正在分享我所遵循的详细过程，并且在此过程中我有一些问题。
我很感激社区的想法
以下是该报告的链接：www.mittalh.notion.site/Small-Language-Model-Report-Questions-43a86edbdd954cd0a7f4df2c9dcd8408
期待。]]></description>
      <guid>https://community.openai.com/t/trained-a-small-language-model-have-some-questions-report/726131#post_1</guid>
      <pubDate>Wed, 24 Apr 2024 03:20:43 GMT</pubDate>
    </item>
    <item>
      <title>关于 Google 助理、话题的问题</title>
      <link>https://community.openai.com/t/questions-about-assistant-threads/485239?page=2#post_27</link>
      <description><![CDATA[听到这个消息我真的很震惊。这确实给整个 API 带来了障碍。通读文档，我认为一定有一些工作流程可以允许更多的控制和定制，特别是考虑到定价和上下文情况，但显然情况并非如此……人们能够提出哪些类型的策略到目前为止？
我仍然可以像目前一样在代理中使用该实用程序，但在开发人员获得对线程/运行管理的更多控制（只要一点点就很好）之前，这个 API 在我看来已经变砖了。]]></description>
      <guid>https://community.openai.com/t/questions-about-assistant-threads/485239?page=2#post_27</guid>
      <pubDate>Wed, 24 Apr 2024 03:20:13 GMT</pubDate>
    </item>
    <item>
      <title>是否有已知的方法可以绕过 Winston AI 检测器？</title>
      <link>https://community.openai.com/t/is-there-a-known-method-to-bypass-the-winston-ai-detector/701092#post_3</link>
      <description><![CDATA[我曾经遇到过同样的问题，就像你一样。在我寻求绕过人工智能检测的过程中，我发现了一些可能有用的策略：


要求 ChatGPT 增强文本的突发性和复杂性。这些特征往往反映了人类书写的自然流程，一些人工智能检测器旨在区分人工智能生成的内容。


使用您的个人数据自定义 ChatGPT。向 ChatGPT 提供您的写作样本有助于它反映您独特的风格、语气和语法偏好。


我还尝试用视觉上相似的字符替换某些字母，这种方法称为使用“同形文字”。


使用反 AI 检测器，例如 BypassGPT、AIHumanizer.ai 等。与其他方法相比，它们可能提供更简单的解决方案。但是，大多数这些工具需要订阅才能正常使用。


虽然我发现这些方法取得了成功，但重要的是要记住，效果可能会有所不同，并且可能存在一些固有的风险。如果您有空闲时间，个人风格的编辑仍然是您的最佳选择。
鉴于您之前的重写未能通过 Winston AI，我建议您下次在重写中尝试添加更多自己的经验或感受，以测试这种方法是否会产生更好的结果。]]></description>
      <guid>https://community.openai.com/t/is-there-a-known-method-to-bypass-the-winston-ai-detector/701092#post_3</guid>
      <pubDate>Wed, 24 Apr 2024 03:12:24 GMT</pubDate>
    </item>
    <item>
      <title>将 DNA 序列翻译成量子电路的结果（附法典）</title>
      <link>https://community.openai.com/t/results-translating-dna-sequences-to-quantum-circuits-with-codex/9164#post_5</link>
      <description><![CDATA[我的名字是莱昂纳多·博斯，《伟大的量子法典》的作者。您的见解引起了我的兴趣，我相信我们之间的讨论会非常富有成果。我渴望更深入地了解您的想法和观点。
您可以在方便的时候尽早进行对话吗？我期待有机会与您讨论这个有趣的话题。
bosch@thegreatquantumcodex.com
最诚挚的问候，
莱昂纳多·博世
]]></description>
      <guid>https://community.openai.com/t/results-translating-dna-sequences-to-quantum-circuits-with-codex/9164#post_5</guid>
      <pubDate>Wed, 24 Apr 2024 02:56:22 GMT</pubDate>
    </item>
    <item>
      <title>将 DNA 序列翻译成量子电路的结果（附法典）</title>
      <link>https://community.openai.com/t/results-translating-dna-sequences-to-quantum-circuits-with-codex/9164#post_4</link>
      <description><![CDATA[（帖子已被作者删除）]]></description>
      <guid>https://community.openai.com/t/results-translating-dna-sequences-to-quantum-circuits-with-codex/9164#post_4</guid>
      <pubDate>Wed, 24 Apr 2024 02:48:22 GMT</pubDate>
    </item>
    <item>
      <title>chat.completion 中*第一个生成的令牌*的非确定性概率？</title>
      <link>https://community.openai.com/t/non-deterministic-probabilities-for-first-generated-token-in-chat-completion/726074#post_4</link>
      <description><![CDATA[


 lO1YJU51OIR：
&lt;块引用&gt;
然而，令人有些不安的是，对于完全相同的提示，“否”的概率范围为 51% 到 97%。这差距实在是太大了……


当然，我完全明白！
我对此类结果的解释是，您的上下文管理还有改进的空间。
通过优化系统消息、重写用户消息或引入其他上下文并执行 RAG。这个想法是，如果特定输入确实应该只有一个输出，并且您遇到了很大的变化，那么问题是您没有为模型提供完成这项工作所需的脚手架你在问它。
我在这里经常重复的一句话就是“去见见模特所在的地方”。因此，就这样做吧——为模型提供成功所需的支持。]]></description>
      <guid>https://community.openai.com/t/non-deterministic-probabilities-for-first-generated-token-in-chat-completion/726074#post_4</guid>
      <pubDate>Wed, 24 Apr 2024 02:23:37 GMT</pubDate>
    </item>
    <item>
      <title>无法从我的文件中检索信息</title>
      <link>https://community.openai.com/t/cant-retrieve-information-from-my-files/726096#post_1</link>
      <description><![CDATA[我正在使用 Google 助理 v2。是的，我已经更新了所有内容。但在 Assistant v1 中也是如此。这让我不舒服。 %95 的时间助手 API 可以完美地从我的文件中获取信息。但 %5% 的情况下，它不能！这对于专业用途来说是不可接受的。我在问同样的问题。但它说的是这样的话：“我找不到相关的具体信息。”但它已经对同一问题给出了数十亿次正确答案。
这 5% 对于商业和专业用途来说太大了。我厌倦了不去 LLama 3！]]></description>
      <guid>https://community.openai.com/t/cant-retrieve-information-from-my-files/726096#post_1</guid>
      <pubDate>Wed, 24 Apr 2024 02:13:07 GMT</pubDate>
    </item>
    </channel>
</rss>