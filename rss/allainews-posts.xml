<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>所有人工智能新闻</title>
    <link>https://allainews.com/</link>
    <description>allainews.com 将所有有关人工智能、机器学习、深度学习、计算机视觉、NLP、数据科学和大数据的热门新闻、播客以及更多内容聚合到一处。</description>
    <lastBuildDate>Thu, 25 Apr 2024 18:23:02 GMT</lastBuildDate>
    <item>
      <title>图与大型语言模型的综述：进展和未来方向</title>
      <link>https://allainews.com/item/a-survey-of-graph-meets-large-language-model-progress-and-future-directions-2024-04-25/</link>
      <description><![CDATA[arXiv:2311.12399v4 公告类型：replace-cross
摘要：图在表示和分析引文网络、社交网络和生物数据等现实世界应用中的复杂关系方面发挥着重要作用。近日，大...]]></description>
      <guid>https://allainews.com/item/a-survey-of-graph-meets-large-language-model-progress-and-future-directions-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:06 GMT</pubDate>
    </item>
    <item>
      <title>切勿从头开始训练：长序列模型的公平比较需要数据驱动的先验</title>
      <link>https://allainews.com/item/never-train-from-scratch-fair-comparison-of-long-sequence-models-requires-data-driven-priors-2024-04-25/</link>
      <description><![CDATA[arXiv:2310.02980v3 公告类型：replace-cross 
摘要：对跨序列的长距离依赖关系进行建模是机器学习的长期目标，并已导致诸如状态空间模型之类的架构的性能大大优于 Transformer……]]></description>
      <guid>https://allainews.com/item/never-train-from-scratch-fair-comparison-of-long-sequence-models-requires-data-driven-priors-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:05 GMT</pubDate>
    </item>
    <item>
      <title>LLMCheckup：通过可解释性工具和自我解释对大型语言模型进行对话式检查</title>
      <link>https://allainews.com/item/llmcheckup-conversational-examination-of-large-language-models-via-interpretability-tools-and-self-explanations-2024-04-25/</link>
      <description><![CDATA[arXiv:2401.12576v2 公告类型：替换
摘要：以对话形式提供解释的可解释性工具已证明其在增强用户理解方面的功效（Slack 等人，2023；Shen 等人，2023），作为一次性解释……]]></description>
      <guid>https://allainews.com/item/llmcheckup-conversational-examination-of-large-language-models-via-interpretability-tools-and-self-explanations-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:04 GMT</pubDate>
    </item>
    <item>
      <title>DP-NMT：可扩展的差分私有机器翻译</title>
      <link>https://allainews.com/item/dp-nmt-scalable-differentially-private-machine-translation-2024-04-25/</link>
      <description><![CDATA[arXiv:2311.14465v2 公告类型：替换
摘要：神经机器翻译（NMT）是一种广泛流行的文本生成任务，但在隐私保护 NMT 模型的开发方面还存在相当大的研究空白，尽管有大量数据优先……]]></description>
      <guid>https://allainews.com/item/dp-nmt-scalable-differentially-private-machine-translation-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:03 GMT</pubDate>
    </item>
    <item>
      <title>DEFT：通过无监督核心集选择对预训练语言模型进行数据高效微调</title>
      <link>https://allainews.com/item/deft-data-efficient-fine-tuning-for-pre-trained-language-models-via-unsupervised-core-set-selection-2024-04-25/</link>
      <description><![CDATA[arXiv:2310.16776v4 公告类型：替换
摘要：最近的进展使得许多预训练语言模型（PLM）变得可用；然而，仍然存在的一个问题是，真正需要多少数据来针对下游任务微调 PLM？在 …]]></description>
      <guid>https://allainews.com/item/deft-data-efficient-fine-tuning-for-pre-trained-language-models-via-unsupervised-core-set-selection-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:03 GMT</pubDate>
    </item>
    <item>
      <title>RoleLLM：大型语言模型的基准测试、引出和增强角色扮演能力</title>
      <link>https://allainews.com/item/rolellm-benchmarking-eliciting-and-enhancing-role-playing-abilities-of-large-language-models-2024-04-25/</link>
      <description><![CDATA[arXiv:2310.00746v2 公告类型：替换
摘要：大型语言模型（LLM）的出现为角色扮演等复杂任务铺平了道路，角色扮演通过使模型能够模仿各种角色来增强用户交互。但是，那  …]]></description>
      <guid>https://allainews.com/item/rolellm-benchmarking-eliciting-and-enhancing-role-playing-abilities-of-large-language-models-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:02 GMT</pubDate>
    </item>
    <item>
      <title>情感麻木还是善解人意？使用 EmotionBench 评估法学硕士的感受</title>
      <link>https://allainews.com/item/emotionally-numb-or-empathetic-evaluating-how-llms-feel-using-emotionbench-2024-04-25/</link>
      <description><![CDATA[arXiv:2308.03656v4 公告类型：替换
摘要：评估大型语言模型（LLM）的拟人能力在当代话语中变得越来越重要。利用心理学的情绪评估理论，我们提出……]]></description>
      <guid>https://allainews.com/item/emotionally-numb-or-empathetic-evaluating-how-llms-feel-using-emotionbench-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:01 GMT</pubDate>
    </item>
    <item>
      <title>大规模抗噪重复数据删除</title>
      <link>https://allainews.com/item/noise-robust-de-duplication-at-scale-2024-04-25/</link>
      <description><![CDATA[arXiv:2210.04261v2 公告类型：替换
摘要：识别大型、嘈杂的文本语料库中的接近重复项具有多种应用，包括删除训练数据集的重复数据、降低隐私风险、评估测试集泄漏等。]]></description>
      <guid>https://allainews.com/item/noise-robust-de-duplication-at-scale-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:00 GMT</pubDate>
    </item>
    <item>
      <title>ICDM 2020知识图谱大赛：消费者事件原因提取</title>
      <link>https://allainews.com/item/icdm-2020-knowledge-graph-contest-consumer-event-cause-extraction-2024-04-25/</link>
      <description><![CDATA[arXiv:2110.15722v2 公告类型：替换
摘要：消费者事件原因提取是一项旨在提取文本中某些事件背后的潜在原因的任务，由于其广泛的应用，近年来受到了广泛的关注。国际疾病分类中心…]]></description>
      <guid>https://allainews.com/item/icdm-2020-knowledge-graph-contest-consumer-event-cause-extraction-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:45:00 GMT</pubDate>
    </item>
    <item>
      <title>MAML 什么时候效果最好？ NLP 应用中模型无关元学习的实证研究</title>
      <link>https://allainews.com/item/when-does-maml-work-the-best-an-empirical-study-on-model-agnostic-meta-learning-in-nlp-applications-2024-04-25/</link>
      <description><![CDATA[arXiv:2005.11700v2 公告类型：替换
摘要：模型无关元学习（MAML）是一种与模型无关的元学习方法，已成功应用于 NLP 应用，包括少镜头文本分类和多领域低资源语言……]]></description>
      <guid>https://allainews.com/item/when-does-maml-work-the-best-an-empirical-study-on-model-agnostic-meta-learning-in-nlp-applications-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:44:59 GMT</pubDate>
    </item>
    <item>
      <title>Cantor：启发 MLLM 的多式联运思想链</title>
      <link>https://allainews.com/item/cantor-inspiring-multimodal-chain-of-thought-of-mllm-2024-04-25/</link>
      <description><![CDATA[arXiv:2404.16033v1 公告类型：交叉
摘要：随着思想链（CoT）方法增强的大型语言模型（LLM）的出现，视觉推理问题通常被分解为可管理的子任务，并通过...]]></description>
      <guid>https://allainews.com/item/cantor-inspiring-multimodal-chain-of-thought-of-mllm-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:44:58 GMT</pubDate>
    </item>
    <item>
      <title>MoDE：通过聚类获得 CLIP 数据专家</title>
      <link>https://allainews.com/item/mode-clip-data-experts-via-clustering-2024-04-25/</link>
      <description><![CDATA[arXiv:2404.16030v1 公告类型：交叉
摘要：对比语言-图像预训练（CLIP）的成功依赖于图像和字幕之间配对的监督，这在网络爬虫数据中往往是有噪声的。我们呈现……的混合物]]></description>
      <guid>https://allainews.com/item/mode-clip-data-experts-via-clustering-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:44:58 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士的不确定性估计和量化：一种简单的监督方法</title>
      <link>https://allainews.com/item/uncertainty-estimation-and-quantification-for-llms-a-simple-supervised-approach-2024-04-25/</link>
      <description><![CDATA[arXiv:2404.15993v1 公告类型：交叉
摘要：大型语言模型（LLM）非常有能力执行许多任务，但有时会生成不可靠或不准确的输出。为了解决这个问题，本文研究了不确定性问题……]]></description>
      <guid>https://allainews.com/item/uncertainty-estimation-and-quantification-for-llms-a-simple-supervised-approach-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:44:57 GMT</pubDate>
    </item>
    <item>
      <title>回音室内部：推特上错误信息的语言基础</title>
      <link>https://allainews.com/item/inside-the-echo-chamber-linguistic-underpinnings-of-misinformation-on-twitter-2024-04-25/</link>
      <description><![CDATA[arXiv:2404.15925v1 公告类型：交叉
摘要：社交媒体用户通过分享包含错误信息的帖子或以未经证实的论点对有争议的话题进行认真的评论，从而推动了错误信息在网上的传播。 ……]]></description>
      <guid>https://allainews.com/item/inside-the-echo-chamber-linguistic-underpinnings-of-misinformation-on-twitter-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:44:56 GMT</pubDate>
    </item>
    <item>
      <title>KGValidator：知识图构建自动验证框架</title>
      <link>https://allainews.com/item/kgvalidator-a-framework-for-automatic-validation-of-knowledge-graph-construction-2024-04-25/</link>
      <description><![CDATA[arXiv:2404.15923v1 公告类型：交叉
摘要：本研究探讨了使用大型语言模型（LLM）来自动评估知识图（KG）完成模型。从历史上看，验证知识图谱中的信息一直是一项具有挑战性的任务……]]></description>
      <guid>https://allainews.com/item/kgvalidator-a-framework-for-automatic-validation-of-knowledge-graph-construction-2024-04-25/</guid>
      <pubDate>Thu, 25 Apr 2024 17:44:55 GMT</pubDate>
    </item>
    </channel>
</rss>