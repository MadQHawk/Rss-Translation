<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>所有人工智能新闻</title>
    <link>https://allainews.com/</link>
    <description>allainews.com 将有关人工智能、机器学习、深度学习、计算机视觉、NLP、数据科学和大数据的所有顶级新闻、播客等汇集到一个地方。</description>
    <lastBuildDate>Wed, 29 May 2024 06:26:00 GMT</lastBuildDate>
    <item>
      <title>DALL-E、CLIP、VQ-VAE-2 和 ImageGPT：人工智能驱动图像生成的革命</title>
      <link>https://allainews.com/item/dall-e-clip-vq-vae-2-and-imagegpt-a-revolution-in-ai-driven-image-generation-2024-05-29/</link>
      <description><![CDATA[近年来，人工智能取得了突破性进展，尤其是在图像生成方面。四种关键模型 DALL-E、CLIP、VQ-VAE-2 和 ImageGPT 是脱颖而出的变革性技术，它们重新定义了人工智能在生成和解码方面的能力……]]></description>
      <guid>https://allainews.com/item/dall-e-clip-vq-vae-2-and-imagegpt-a-revolution-in-ai-driven-image-generation-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 05:30:00 GMT</pubDate>
    </item>
    <item>
      <title>从即时工程到代理工程</title>
      <link>https://allainews.com/item/from-prompt-engineering-to-agent-engineering-2024-05-29/</link>
      <description><![CDATA[介绍实用的代理工程框架来源：图片由作者提供，由 MidJourney 生成简介自 ChatGPT 推出以来仅一年多时间，很明显公众对“AI”的看法发生了巨大变化。部分原因在于……]]></description>
      <guid>https://allainews.com/item/from-prompt-engineering-to-agent-engineering-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 05:07:08 GMT</pubDate>
    </item>
    <item>
      <title>了解 Python 的 Shiny 的两个方面：核心和 Express</title>
      <link>https://allainews.com/item/understanding-the-two-faces-of-shiny-for-python-core-and-express-2024-05-29/</link>
      <description><![CDATA[探索 Shiny Core 和 Shiny Express for Python 的区别和用例继续阅读 Towards Data Science » …]]></description>
      <guid>https://allainews.com/item/understanding-the-two-faces-of-shiny-for-python-core-and-express-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:59:23 GMT</pubDate>
    </item>
    <item>
      <title>Aaren：重新思考注意力机制作为循环神经网络 RNN，以实现低资源设备上的高效序列建模</title>
      <link>https://allainews.com/item/aaren-rethinking-attention-as-recurrent-neural-network-rnn-for-efficient-sequence-modeling-on-low-resource-devices-2024-05-29/</link>
      <description><![CDATA[序列建模是机器学习中的关键领域，涵盖强化学习、时间序列预测和事件预测等应用。这些模型旨在处理输入顺序很重要的数据，例如……]]></description>
      <guid>https://allainews.com/item/aaren-rethinking-attention-as-recurrent-neural-network-rnn-for-efficient-sequence-modeling-on-low-resource-devices-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:49:49 GMT</pubDate>
    </item>
    <item>
      <title>BDHT：生成式人工智能可实现轻度认知障碍的因果关系分析</title>
      <link>https://allainews.com/item/bdht-generative-ai-enables-causality-analysis-for-mild-cognitive-impairment-2024-05-29/</link>
      <description><![CDATA[arXiv:2312.09022v2 公告类型：replace-cross 
摘要：有效的连接性估计对于理解不同大脑区域之间的相互作用和信息流起着至关重要的作用。然而，用于估计的功能时间序列……]]></description>
      <guid>https://allainews.com/item/bdht-generative-ai-enables-causality-analysis-for-mild-cognitive-impairment-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:48 GMT</pubDate>
    </item>
    <item>
      <title>可重新点亮的高斯编解码器头像</title>
      <link>https://allainews.com/item/relightable-gaussian-codec-avatars-2024-05-29/</link>
      <description><![CDATA[arXiv:2312.03704v2 公告类型：replace-cross 
摘要：重新照明的保真度受几何和外观表示的限制。对于几何，网格和体积方法都难以对复杂的结构（如 3D）进行建模……]]></description>
      <guid>https://allainews.com/item/relightable-gaussian-codec-avatars-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:48 GMT</pubDate>
    </item>
    <item>
      <title>基于视觉的耕地导航系统</title>
      <link>https://allainews.com/item/a-vision-based-navigation-system-for-arable-fields-2024-05-29/</link>
      <description><![CDATA[arXiv:2309.11989v2 公告类型：replace-cross 
摘要：基于视觉的农田导航系统是农业机器人导航中尚未充分探索的领域。部署在农田中的视觉系统面临着诸如杂草波动等挑战……]]></description>
      <guid>https://allainews.com/item/a-vision-based-navigation-system-for-arable-fields-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:47 GMT</pubDate>
    </item>
    <item>
      <title>通过与视觉惯性里程计紧密融合在线校准单轨地面车辆动力学模型</title>
      <link>https://allainews.com/item/online-calibration-of-a-single-track-ground-vehicle-dynamics-model-by-tight-fusion-with-visual-inertial-odometry-2024-05-29/</link>
      <description><![CDATA[arXiv:2309.11148v3 公告类型：replace-cross 
摘要：轮式移动机器人需要能够估计其运动及其控制动作对导航规划的影响。在本文中，我们介绍了一种新颖的方法 ST-VIO，它紧密…]]></description>
      <guid>https://allainews.com/item/online-calibration-of-a-single-track-ground-vehicle-dynamics-model-by-tight-fusion-with-visual-inertial-odometry-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:46 GMT</pubDate>
    </item>
    <item>
      <title>使用不确定性引导的下一个最佳视图优化进行主动隐式对象重建</title>
      <link>https://allainews.com/item/active-implicit-object-reconstruction-using-uncertainty-guided-next-best-view-optimization-2024-05-29/</link>
      <description><![CDATA[arXiv:2303.16739v4 公告类型：replace-cross 
摘要：在物体重建过程中主动规划传感器视图对于自主移动机器人至关重要。有效的方法应该能够在准确性和效率之间取得平衡。在…]]></description>
      <guid>https://allainews.com/item/active-implicit-object-reconstruction-using-uncertainty-guided-next-best-view-optimization-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:46 GMT</pubDate>
    </item>
    <item>
      <title>Lumen：释放大型多模态模型的多功能视觉中心功能</title>
      <link>https://allainews.com/item/lumen-unleashing-versatile-vision-centric-capabilities-of-large-multimodal-models-2024-05-29/</link>
      <description><![CDATA[arXiv:2403.07304v2 公告类型：替换 
摘要：大型多模态模型 (LMM) 是计算机视觉领域的热门研究课题，并且在多个学科领域也表现出了巨大的潜力。最近的趋势是进一步扩展……]]></description>
      <guid>https://allainews.com/item/lumen-unleashing-versatile-vision-centric-capabilities-of-large-multimodal-models-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:44 GMT</pubDate>
    </item>
    <item>
      <title>PlaceFormer：基于 Transformer 的多尺度块选择与融合视觉位置识别</title>
      <link>https://allainews.com/item/placeformer-transformer-based-visual-place-recognition-using-multi-scale-patch-selection-and-fusion-2024-05-29/</link>
      <description><![CDATA[arXiv:2401.13082v2 公告类型：替换 
摘要：视觉位置识别是计算机视觉、自主机器人和车辆领域的一项具有挑战性的任务，旨在从视觉输入中识别位置或地点。当代医学……]]></description>
      <guid>https://allainews.com/item/placeformer-transformer-based-visual-place-recognition-using-multi-scale-patch-selection-and-fusion-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:43 GMT</pubDate>
    </item>
    <item>
      <title>使用联合建模和匹配从前方或环视视角进行 3D 车道检测</title>
      <link>https://allainews.com/item/3d-lane-detection-from-front-or-surround-view-using-joint-modeling-matching-2024-05-29/</link>
      <description><![CDATA[arXiv:2401.08036v2 公告类型：替换 
摘要：3D 车道比 2D 车道更全面地了解路面几何形状，从而为驾驶决策和轨迹规划提供重要参考。虽然许多努力……]]></description>
      <guid>https://allainews.com/item/3d-lane-detection-from-front-or-surround-view-using-joint-modeling-matching-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:42 GMT</pubDate>
    </item>
    <item>
      <title>人人为我：迈向地球愿景的统一基础模型</title>
      <link>https://allainews.com/item/one-for-all-toward-unified-foundation-models-for-earth-vision-2024-05-29/</link>
      <description><![CDATA[arXiv:2401.07527v2 公告类型：替换 
摘要：以大量参数为特征并在大规模数据集上训练的基础模型已在遥感数据的各种下游任务中表现出显著的功效。当前研究……]]></description>
      <guid>https://allainews.com/item/one-for-all-toward-unified-foundation-models-for-earth-vision-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:41 GMT</pubDate>
    </item>
    <item>
      <title>VQ-HPS：矢量量化潜在空间中的人体姿势和形状估计</title>
      <link>https://allainews.com/item/vq-hps-human-pose-and-shape-estimation-in-a-vector-quantized-latent-space-2024-05-29/</link>
      <description><![CDATA[arXiv:2312.08291v2 公告类型：替换 
摘要：之前关于从 RGB 图像进行人体姿势和形状估计 (HPSE) 的研究大致可分为两大类：参数方法和非参数方法。参数技术利用……]]></description>
      <guid>https://allainews.com/item/vq-hps-human-pose-and-shape-estimation-in-a-vector-quantized-latent-space-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:40 GMT</pubDate>
    </item>
    <item>
      <title>GMTalker：基于高斯混合的音频驱动的情感视频肖像</title>
      <link>https://allainews.com/item/gmtalker-gaussian-mixture-based-audio-driven-emotional-talking-video-portraits-2024-05-29/</link>
      <description><![CDATA[arXiv:2312.07669v2 公告类型：替换 
摘要：合成高保真、情绪可控的会说话的视频肖像，包括音频口型同步、生动的表情、逼真的头部姿势和眨眼，是一项重要且具有挑战性的任务……]]></description>
      <guid>https://allainews.com/item/gmtalker-gaussian-mixture-based-audio-driven-emotional-talking-video-portraits-2024-05-29/</guid>
      <pubDate>Wed, 29 May 2024 04:48:40 GMT</pubDate>
    </item>
    </channel>
</rss>